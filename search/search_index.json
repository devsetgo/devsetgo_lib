{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p> <p> </p> <p>CI/CD Pipeline:</p> <p> </p> <p>SonarCloud:</p> <p> </p> <p> </p>"},{"location":"#devsetgo-common-library","title":"DevSetGo Common Library","text":"<p>A set of common functions wrapped into a package, so I don't have to write the same code over and over. Oh and it makes the code more reusable.... or something like that.</p>"},{"location":"#testing","title":"Testing","text":"<p>Test on Windows and Linux. Since I work in Windows and Linux I test for issues there. Should work on MacOS, but let me know if there is an issue.</p>"},{"location":"#library-functions","title":"Library Functions","text":"<ul> <li> <p>Common Functions</p> <ul> <li> <p>file_functions</p> <ul> <li>CSV File Functions</li> <li>JSON File Functions</li> <li>Text File Functions</li> </ul> </li> <li> <p>Folder Functions</p> <ul> <li>Make Directory</li> <li>Remove Directory</li> <li>Last File Changed</li> <li>Directory List</li> </ul> </li> <li> <p>Calendar Functions</p> <ul> <li>Get Month</li> <li>Get Month Number</li> </ul> </li> <li> <p>Patterns</p> <ul> <li>Pattern Between Two Characters</li> </ul> </li> <li> <p>Logging</p> <ul> <li>logging configuration and interceptor</li> </ul> </li> </ul> </li> <li> <p>FastAPI Endpoints</p> <ul> <li>Systems Health Endpoints<ul> <li>Status/Health, Heapdump, Uptime</li> </ul> </li> <li>HTTP Codes<ul> <li>Way to generate HTTP response codes</li> </ul> </li> </ul> </li> <li> <p>Aysnc Database</p> <ul> <li>Database Config</li> <li>Async Session</li> <li>Database Operations (CRUD)</li> </ul> </li> </ul>"},{"location":"contribute/","title":"Contributing","text":"<p>Please feel to contribute to this project. Adding common functions is the intent and if you have one to add or improve an existing it is greatly appreciated.</p>"},{"location":"contribute/#ways-to-contribute","title":"Ways to Contribute!","text":"<ul> <li>Add or improve a function</li> <li>Add or improve documentation</li> <li>Add or improve Tests</li> <li>Report or fix a bug</li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#install","title":"Install","text":"<pre><code>pip install devsetgo-lib\n\n# Aysync database setup\npip install devsetgo-lib[sqlite]\npip install devsetgo-lib[postgres]\n\n# Consider these experimental and untested\npip install devsetgo-lib[oracle]\npip install devsetgo-lib[mssql]\npip install devsetgo-lib[mysql]\n\n# For adding FastAPI endpoints\npip install devsetgo-lib[fastapi]\n\n# Install everything\npip install devsetgo-lib[all]\n</code></pre> <p>See documentation for more examples of library use</p>"},{"location":"release-notes/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog</p>"},{"location":"release-notes/#latest-changes","title":"Latest Changes","text":""},{"location":"release-notes/#beta-release-with-fixes-for-multiple-issues-v0110-beta3-fix1","title":"Beta Release with fixes for multiple issues (v0.11.0-beta3-fix1)","text":""},{"location":"release-notes/#whats-changed","title":"What's Changed","text":"<ul> <li>Dev (#362) @devsetgo</li> <li>Fix of issues from Beta release (#361) @devsetgo</li> <li>359 tables are created before create tables is called (#360) @devsetgo</li> <li>Change Log (#358) @devsetgo</li> <li>fixing latest-changes (#357) @devsetgo</li> <li>removing jinja template from Latest Changes Action (#356) @devsetgo</li> <li>Action fixing adding main (#355) @devsetgo</li> <li>Fixing actions (#354) @devsetgo</li> <li>Fixing Beta Publishing issues and Documentation Improvements (#353) @devsetgo</li> <li>Update setup.py for sub packages (#352) @devsetgo</li> <li>Import Bug Fix (#351) @devsetgo</li> <li>Latest Changes Action Fix (#350) @devsetgo</li> <li>Next Release (#349) @devsetgo</li> <li>Dev (#348) @devsetgo</li> <li>pip(deps): bump autopep8 from 2.0.2 to 2.0.4 (#343) @dependabot</li> <li>pip(deps): bump wheel from 0.41.2 to 0.42.0 (#345) @dependabot</li> <li>pip(deps): bump mkdocstrings[python] from 0.21.2 to 0.24.0 (#346) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.3 to 1.5.3 (#347) @dependabot</li> <li>pip(deps): bump flake8 from 6.0.0 to 6.1.0 (#332) @dependabot</li> <li>pip(deps): bump click from 8.1.3 to 8.1.7 (#337) @dependabot</li> <li>pip(deps): bump wheel from 0.40.0 to 0.41.2 (#339) @dependabot</li> <li>github actionts(deps): bump actions/checkout from 2 to 4 (#340) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.17 to 9.4.2 (#341) @dependabot</li> <li>pip(deps): bump black from 23.3.0 to 23.9.1 (#342) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.15 to 9.1.17 (#326) @dependabot</li> <li>pip(deps): bump pytest from 7.3.1 to 7.4.0 (#327) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.2 to 1.4.3 (#328) @dependabot</li> <li>pip(deps): bump autoflake from 2.1.1 to 2.2.0 (#329) @dependabot</li> <li>pip(deps): bump pre-commit from 3.2.2 to 3.3.3 (#330) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.9 to 9.1.15 (#325) @dependabot</li> <li>pip(deps): bump autoflake from 2.0.2 to 2.1.1 (#324) @dependabot</li> <li>pip(deps): bump pytest-xdist from 3.2.1 to 3.3.1 (#323) @dependabot</li> <li>pip(deps): bump tox from 4.4.11 to 4.5.2 (#322) @dependabot</li> <li>pip(deps): bump pytest-cov from 4.0.0 to 4.1.0 (#321) @dependabot</li> <li>pip(deps): bump loguru from 0.6.0 to 0.7.0 (#317) @dependabot</li> <li>pip(deps): bump mkdocs-gen-files from 0.4.0 to 0.5.0 (#314) @dependabot</li> <li>pip(deps): bump pylint from 2.17.2 to 2.17.4 (#319) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.6 to 9.1.9 (#320) @dependabot</li> <li>pip(deps): bump pytest from 7.3.0 to 7.3.1 (#318) @dependabot</li> </ul> <p>Published Date: 2023 December 17, 16:23</p>"},{"location":"release-notes/#fixing-asyncdatabase-create-tables-v0110-beta3","title":"Fixing AsyncDatabase create tables (v0.11.0-beta3)","text":""},{"location":"release-notes/#whats-changed_1","title":"What's Changed","text":"<ul> <li>Fix of issues from Beta release (#361) @devsetgo</li> <li>359 tables are created before create tables is called (#360) @devsetgo</li> <li>Change Log (#358) @devsetgo</li> <li>fixing latest-changes (#357) @devsetgo</li> <li>removing jinja template from Latest Changes Action (#356) @devsetgo</li> <li>Action fixing adding main (#355) @devsetgo</li> <li>Fixing actions (#354) @devsetgo</li> <li>Fixing Beta Publishing issues and Documentation Improvements (#353) @devsetgo</li> <li>Update setup.py for sub packages (#352) @devsetgo</li> <li>Import Bug Fix (#351) @devsetgo</li> <li>Latest Changes Action Fix (#350) @devsetgo</li> <li>Next Release (#349) @devsetgo</li> <li>Dev (#348) @devsetgo</li> <li>pip(deps): bump autopep8 from 2.0.2 to 2.0.4 (#343) @dependabot</li> <li>pip(deps): bump wheel from 0.41.2 to 0.42.0 (#345) @dependabot</li> <li>pip(deps): bump mkdocstrings[python] from 0.21.2 to 0.24.0 (#346) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.3 to 1.5.3 (#347) @dependabot</li> <li>pip(deps): bump flake8 from 6.0.0 to 6.1.0 (#332) @dependabot</li> <li>pip(deps): bump click from 8.1.3 to 8.1.7 (#337) @dependabot</li> <li>pip(deps): bump wheel from 0.40.0 to 0.41.2 (#339) @dependabot</li> <li>github actionts(deps): bump actions/checkout from 2 to 4 (#340) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.17 to 9.4.2 (#341) @dependabot</li> <li>pip(deps): bump black from 23.3.0 to 23.9.1 (#342) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.15 to 9.1.17 (#326) @dependabot</li> <li>pip(deps): bump pytest from 7.3.1 to 7.4.0 (#327) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.2 to 1.4.3 (#328) @dependabot</li> <li>pip(deps): bump autoflake from 2.1.1 to 2.2.0 (#329) @dependabot</li> <li>pip(deps): bump pre-commit from 3.2.2 to 3.3.3 (#330) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.9 to 9.1.15 (#325) @dependabot</li> <li>pip(deps): bump autoflake from 2.0.2 to 2.1.1 (#324) @dependabot</li> <li>pip(deps): bump pytest-xdist from 3.2.1 to 3.3.1 (#323) @dependabot</li> <li>pip(deps): bump tox from 4.4.11 to 4.5.2 (#322) @dependabot</li> <li>pip(deps): bump pytest-cov from 4.0.0 to 4.1.0 (#321) @dependabot</li> <li>pip(deps): bump loguru from 0.6.0 to 0.7.0 (#317) @dependabot</li> <li>pip(deps): bump mkdocs-gen-files from 0.4.0 to 0.5.0 (#314) @dependabot</li> <li>pip(deps): bump pylint from 2.17.2 to 2.17.4 (#319) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.6 to 9.1.9 (#320) @dependabot</li> <li>pip(deps): bump pytest from 7.3.0 to 7.3.1 (#318) @dependabot</li> </ul> <p>Published Date: 2023 December 17, 16:18</p>"},{"location":"release-notes/#build-updates-v0110-beta2","title":"Build Updates  (v0.11.0-beta2)","text":""},{"location":"release-notes/#whats-changed_2","title":"What's Changed","text":"<ul> <li>Change Log (#358) @devsetgo</li> <li>fixing latest-changes (#357) @devsetgo</li> <li>removing jinja template from Latest Changes Action (#356) @devsetgo</li> <li>Action fixing adding main (#355) @devsetgo</li> <li>Fixing actions (#354) @devsetgo</li> <li>Fixing Beta Publishing issues and Documentation Improvements (#353) @devsetgo</li> <li>Update setup.py for sub packages (#352) @devsetgo</li> <li>Import Bug Fix (#351) @devsetgo</li> <li>Latest Changes Action Fix (#350) @devsetgo</li> <li>Next Release (#349) @devsetgo</li> <li>Dev (#348) @devsetgo</li> <li>pip(deps): bump autopep8 from 2.0.2 to 2.0.4 (#343) @dependabot</li> <li>pip(deps): bump wheel from 0.41.2 to 0.42.0 (#345) @dependabot</li> <li>pip(deps): bump mkdocstrings[python] from 0.21.2 to 0.24.0 (#346) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.3 to 1.5.3 (#347) @dependabot</li> <li>pip(deps): bump flake8 from 6.0.0 to 6.1.0 (#332) @dependabot</li> <li>pip(deps): bump click from 8.1.3 to 8.1.7 (#337) @dependabot</li> <li>pip(deps): bump wheel from 0.40.0 to 0.41.2 (#339) @dependabot</li> <li>github actionts(deps): bump actions/checkout from 2 to 4 (#340) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.17 to 9.4.2 (#341) @dependabot</li> <li>pip(deps): bump black from 23.3.0 to 23.9.1 (#342) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.15 to 9.1.17 (#326) @dependabot</li> <li>pip(deps): bump pytest from 7.3.1 to 7.4.0 (#327) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.2 to 1.4.3 (#328) @dependabot</li> <li>pip(deps): bump autoflake from 2.1.1 to 2.2.0 (#329) @dependabot</li> <li>pip(deps): bump pre-commit from 3.2.2 to 3.3.3 (#330) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.9 to 9.1.15 (#325) @dependabot</li> <li>pip(deps): bump autoflake from 2.0.2 to 2.1.1 (#324) @dependabot</li> <li>pip(deps): bump pytest-xdist from 3.2.1 to 3.3.1 (#323) @dependabot</li> <li>pip(deps): bump tox from 4.4.11 to 4.5.2 (#322) @dependabot</li> <li>pip(deps): bump pytest-cov from 4.0.0 to 4.1.0 (#321) @dependabot</li> <li>pip(deps): bump loguru from 0.6.0 to 0.7.0 (#317) @dependabot</li> <li>pip(deps): bump mkdocs-gen-files from 0.4.0 to 0.5.0 (#314) @dependabot</li> <li>pip(deps): bump pylint from 2.17.2 to 2.17.4 (#319) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.6 to 9.1.9 (#320) @dependabot</li> <li>pip(deps): bump pytest from 7.3.0 to 7.3.1 (#318) @dependabot</li> </ul> <p>Published Date: 2023 December 16, 20:34</p>"},{"location":"release-notes/#beta-release-with-fixes-for-multiple-issues-v0110-beta1-fix5","title":"Beta Release with fixes for multiple issues (v0.11.0-beta1-fix5)","text":""},{"location":"release-notes/#whats-changed_3","title":"What's Changed","text":"<ul> <li>fixing latest-changes (#357) @devsetgo</li> <li>removing jinja template from Latest Changes Action (#356) @devsetgo</li> <li>Action fixing adding main (#355) @devsetgo</li> <li>Fixing actions (#354) @devsetgo</li> <li>Fixing Beta Publishing issues and Documentation Improvements (#353) @devsetgo</li> <li>Update setup.py for sub packages (#352) @devsetgo</li> <li>Import Bug Fix (#351) @devsetgo</li> <li>Latest Changes Action Fix (#350) @devsetgo</li> <li>Next Release (#349) @devsetgo</li> <li>Dev (#348) @devsetgo</li> <li>pip(deps): bump autopep8 from 2.0.2 to 2.0.4 (#343) @dependabot</li> <li>pip(deps): bump wheel from 0.41.2 to 0.42.0 (#345) @dependabot</li> <li>pip(deps): bump mkdocstrings[python] from 0.21.2 to 0.24.0 (#346) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.3 to 1.5.3 (#347) @dependabot</li> <li>pip(deps): bump flake8 from 6.0.0 to 6.1.0 (#332) @dependabot</li> <li>pip(deps): bump click from 8.1.3 to 8.1.7 (#337) @dependabot</li> <li>pip(deps): bump wheel from 0.40.0 to 0.41.2 (#339) @dependabot</li> <li>github actionts(deps): bump actions/checkout from 2 to 4 (#340) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.17 to 9.4.2 (#341) @dependabot</li> <li>pip(deps): bump black from 23.3.0 to 23.9.1 (#342) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.15 to 9.1.17 (#326) @dependabot</li> <li>pip(deps): bump pytest from 7.3.1 to 7.4.0 (#327) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.2 to 1.4.3 (#328) @dependabot</li> <li>pip(deps): bump autoflake from 2.1.1 to 2.2.0 (#329) @dependabot</li> <li>pip(deps): bump pre-commit from 3.2.2 to 3.3.3 (#330) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.9 to 9.1.15 (#325) @dependabot</li> <li>pip(deps): bump autoflake from 2.0.2 to 2.1.1 (#324) @dependabot</li> <li>pip(deps): bump pytest-xdist from 3.2.1 to 3.3.1 (#323) @dependabot</li> <li>pip(deps): bump tox from 4.4.11 to 4.5.2 (#322) @dependabot</li> <li>pip(deps): bump pytest-cov from 4.0.0 to 4.1.0 (#321) @dependabot</li> <li>pip(deps): bump loguru from 0.6.0 to 0.7.0 (#317) @dependabot</li> <li>pip(deps): bump mkdocs-gen-files from 0.4.0 to 0.5.0 (#314) @dependabot</li> <li>pip(deps): bump pylint from 2.17.2 to 2.17.4 (#319) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.6 to 9.1.9 (#320) @dependabot</li> <li>pip(deps): bump pytest from 7.3.0 to 7.3.1 (#318) @dependabot</li> </ul> <p>Published Date: 2023 December 16, 16:33</p>"},{"location":"release-notes/#build-fixes-v0110-beta1-fix4","title":"Build Fixes  (v0.11.0-beta1-fix4)","text":""},{"location":"release-notes/#whats-changed_4","title":"What's Changed","text":"<ul> <li>Update setup.py for sub packages (#352) @devsetgo</li> <li>Import Bug Fix (#351) @devsetgo</li> <li>Latest Changes Action Fix (#350) @devsetgo</li> <li>Next Release (#349) @devsetgo</li> <li>Dev (#348) @devsetgo</li> <li>pip(deps): bump autopep8 from 2.0.2 to 2.0.4 (#343) @dependabot</li> <li>pip(deps): bump wheel from 0.41.2 to 0.42.0 (#345) @dependabot</li> <li>pip(deps): bump mkdocstrings[python] from 0.21.2 to 0.24.0 (#346) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.3 to 1.5.3 (#347) @dependabot</li> <li>pip(deps): bump flake8 from 6.0.0 to 6.1.0 (#332) @dependabot</li> <li>pip(deps): bump click from 8.1.3 to 8.1.7 (#337) @dependabot</li> <li>pip(deps): bump wheel from 0.40.0 to 0.41.2 (#339) @dependabot</li> <li>github actionts(deps): bump actions/checkout from 2 to 4 (#340) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.17 to 9.4.2 (#341) @dependabot</li> <li>pip(deps): bump black from 23.3.0 to 23.9.1 (#342) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.15 to 9.1.17 (#326) @dependabot</li> <li>pip(deps): bump pytest from 7.3.1 to 7.4.0 (#327) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.2 to 1.4.3 (#328) @dependabot</li> <li>pip(deps): bump autoflake from 2.1.1 to 2.2.0 (#329) @dependabot</li> <li>pip(deps): bump pre-commit from 3.2.2 to 3.3.3 (#330) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.9 to 9.1.15 (#325) @dependabot</li> <li>pip(deps): bump autoflake from 2.0.2 to 2.1.1 (#324) @dependabot</li> <li>pip(deps): bump pytest-xdist from 3.2.1 to 3.3.1 (#323) @dependabot</li> <li>pip(deps): bump tox from 4.4.11 to 4.5.2 (#322) @dependabot</li> <li>pip(deps): bump pytest-cov from 4.0.0 to 4.1.0 (#321) @dependabot</li> <li>pip(deps): bump loguru from 0.6.0 to 0.7.0 (#317) @dependabot</li> <li>pip(deps): bump mkdocs-gen-files from 0.4.0 to 0.5.0 (#314) @dependabot</li> <li>pip(deps): bump pylint from 2.17.2 to 2.17.4 (#319) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.6 to 9.1.9 (#320) @dependabot</li> <li>pip(deps): bump pytest from 7.3.0 to 7.3.1 (#318) @dependabot</li> </ul> <p>Published Date: 2023 December 12, 11:45</p>"},{"location":"release-notes/#async-database-and-fastapi-functions-v0110-beta0","title":"Async Database and FastAPI functions (v0.11.0-beta0)","text":""},{"location":"release-notes/#whats-changed_5","title":"What's Changed","text":"<ul> <li>Dev (#348) @devsetgo - New functionality and documentation for FastAPI Endpoints and Async Database Functionality</li> <li>pip(deps): bump autopep8 from 2.0.2 to 2.0.4 (#343) @dependabot</li> <li>pip(deps): bump wheel from 0.41.2 to 0.42.0 (#345) @dependabot</li> <li>pip(deps): bump mkdocstrings[python] from 0.21.2 to 0.24.0 (#346) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.3 to 1.5.3 (#347) @dependabot</li> <li>pip(deps): bump flake8 from 6.0.0 to 6.1.0 (#332) @dependabot</li> <li>pip(deps): bump click from 8.1.3 to 8.1.7 (#337) @dependabot</li> <li>pip(deps): bump wheel from 0.40.0 to 0.41.2 (#339) @dependabot</li> <li>github actionts(deps): bump actions/checkout from 2 to 4 (#340) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.17 to 9.4.2 (#341) @dependabot</li> <li>pip(deps): bump black from 23.3.0 to 23.9.1 (#342) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.15 to 9.1.17 (#326) @dependabot</li> <li>pip(deps): bump pytest from 7.3.1 to 7.4.0 (#327) @dependabot</li> <li>pip(deps): bump mkdocs from 1.4.2 to 1.4.3 (#328) @dependabot</li> <li>pip(deps): bump autoflake from 2.1.1 to 2.2.0 (#329) @dependabot</li> <li>pip(deps): bump pre-commit from 3.2.2 to 3.3.3 (#330) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.9 to 9.1.15 (#325) @dependabot</li> <li>pip(deps): bump autoflake from 2.0.2 to 2.1.1 (#324) @dependabot</li> <li>pip(deps): bump pytest-xdist from 3.2.1 to 3.3.1 (#323) @dependabot</li> <li>pip(deps): bump tox from 4.4.11 to 4.5.2 (#322) @dependabot</li> <li>pip(deps): bump pytest-cov from 4.0.0 to 4.1.0 (#321) @dependabot</li> <li>pip(deps): bump loguru from 0.6.0 to 0.7.0 (#317) @dependabot</li> <li>pip(deps): bump mkdocs-gen-files from 0.4.0 to 0.5.0 (#314) @dependabot</li> <li>pip(deps): bump pylint from 2.17.2 to 2.17.4 (#319) @dependabot</li> <li>pip(deps): bump mkdocs-material from 9.1.6 to 9.1.9 (#320) @dependabot</li> <li>pip(deps): bump pytest from 7.3.0 to 7.3.1 (#318) @dependabot</li> </ul> <p>Published Date: 2023 December 10, 20:17</p>"},{"location":"release-notes/#pattern-analysis-update-and-bug-fix-v0101","title":"Pattern Analysis Update and Bug Fix (v0.10.1)","text":""},{"location":"release-notes/#whats-changed_6","title":"What's Changed","text":"<ul> <li>Improvement to the patterns analysis (#313) @devsetgo</li> <li>pip(deps): bump mkdocs-material from 9.1.3 to 9.1.5 (#308) @dependabot</li> <li>pip(deps): bump pre-commit from 3.2.0 to 3.2.1 (#310) @dependabot</li> <li>pip(deps): bump watchdog from 2.3.1 to 3.0.0 (#309) @dependabot</li> <li>pip(deps): bump pylint from 2.17.0 to 2.17.1 (#311) @dependabot</li> <li>pip(deps): bump tox from 4.4.7 to 4.4.8 (#312) @dependabot</li> </ul> <p>Published Date: 2023 April 08, 21:45</p>"},{"location":"release-notes/#chatgpt-driven-improvements-v0100","title":"ChatGPT Driven Improvements (v0.10.0)","text":""},{"location":"release-notes/#chatgpt","title":"ChatGPT","text":"<p>Using ChatGPT to improve tests, find bugs, and improve performance. Code coverage is at 100% and the code base appears to be performing better than before.</p> <p>Major changes are in PR #304 </p>"},{"location":"release-notes/#whats-changed_7","title":"What's Changed","text":"<ul> <li>latest change fix for regex pattern. (#307) @devsetgo</li> <li>Dev (#306) @devsetgo</li> <li>Workflow changes (#305) @devsetgo</li> <li>ChatGPT Driven Improvements (#304) @devsetgo</li> <li>pip(deps): bump pre-commit from 3.0.2 to 3.1.1 (#300) @dependabot</li> <li>pip(deps): bump pytest-xdist from 3.1.0 to 3.2.0 (#302) @dependabot</li> <li>pip(deps): bump autoflake from 2.0.0 to 2.0.1 (#299) @dependabot</li> <li>pip(deps): bump watchdog from 2.1.9 to 2.3.1 (#301) @dependabot</li> <li>pip(deps): bump pytest from 7.2.0 to 7.2.1 (#303) @dependabot</li> <li>pip(deps): bump pylint from 2.15.7 to 2.16.1 (#298) @dependabot</li> <li>pip(deps): bump autopep8 from 2.0.0 to 2.0.1 (#289) @dependabot</li> <li>pip(deps): bump pylint from 2.15.7 to 2.15.10 (#295) @dependabot</li> <li>pip(deps): bump black from 22.10.0 to 23.1.0 (#294) @dependabot</li> <li>pip(deps): bump tox from 3.27.1 to 4.4.4 (#296) @dependabot</li> <li>pip(deps): bump pre-commit from 2.20.0 to 3.0.2 (#297) @dependabot</li> </ul> <p>Published Date: 2023 April 01, 00:27</p>"},{"location":"release-notes/#open-csv-enhancements-and-library-updates-v090","title":"Open CSV enhancements and library updates (v0.9.0)","text":""},{"location":"release-notes/#whats-changed_8","title":"What's Changed","text":"<ul> <li>fix of latest changes (#288) @devsetgo</li> <li>Open_CSV Enhancements (#287) @devsetgo</li> <li>pip(deps): bump pytest-cov from 3.0.0 to 4.0.0 (#274) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.4.2 to 8.5.5 (#276) @dependabot</li> <li>pip(deps): bump autoflake from 1.5.3 to 1.6.1 (#275) @dependabot</li> <li>pip(deps): bump tqdm from 4.64.0 to 4.64.1 (#273) @dependabot</li> <li>pip(deps): bump pytest from 7.1.2 to 7.1.3 (#272) @dependabot</li> <li>pip(deps): bump mkdocs from 1.3.1 to 1.4.0 (#271) @dependabot</li> <li>pip(deps): bump tox from 3.25.1 to 3.26.0 (#269) @dependabot</li> <li>pip(deps): bump pylint from 2.15.0 to 2.15.3 (#270) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.3.9 to 8.4.2 (#268) @dependabot</li> <li>pip(deps): bump autopep8 from 1.6.0 to 1.7.0 (#264) @dependabot</li> <li>pip(deps): bump pylint from 2.14.5 to 2.15.0 (#265) @dependabot</li> <li>pip(deps): bump autoflake from 1.4 to 1.5.3 (#263) @dependabot</li> <li>pip(deps): bump black from 22.6.0 to 22.8.0 (#267) @dependabot</li> <li>pip(deps): bump flake8 from 5.0.1 to 5.0.4 (#266) @dependabot</li> <li>pip(deps): bump pre-commit from 2.19.0 to 2.20.0 (#260) @dependabot</li> <li>pip(deps): bump mkdocs from 1.3.0 to 1.3.1 (#261) @dependabot</li> <li>pip(deps): bump flake8 from 4.0.1 to 5.0.1 (#259) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.3.8 to 8.3.9 (#258) @dependabot</li> <li>pip(deps): bump pylint from 2.14.4 to 2.14.5 (#262) @dependabot</li> <li>pip(deps): bump twine from 4.0.0 to 4.0.1 (#252) @dependabot</li> <li>pip(deps): bump pylint from 2.14.0 to 2.14.4 (#251) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.2.16 to 8.3.8 (#253) @dependabot</li> <li>pip(deps): bump black from 22.3.0 to 22.6.0 (#254) @dependabot</li> <li>pip(deps): bump tox from 3.25.0 to 3.25.1 (#255) @dependabot</li> <li>pip(deps): bump watchdog from 2.1.8 to 2.1.9 (#256) @dependabot</li> <li>github actionts(deps): bump actions/setup-python from 3 to 4 (#257) @dependabot</li> <li>pip(deps): bump pylint from 2.13.7 to 2.14.0 (#250) @dependabot</li> <li>pip(deps): bump watchdog from 2.1.7 to 2.1.8 (#246) @dependabot</li> <li>pip(deps): bump pre-commit from 2.18.1 to 2.19.0 (#248) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.2.12 to 8.2.16 (#249) @dependabot</li> <li>pip(deps): bump tox from 3.24.5 to 3.25.0 (#242) @dependabot</li> <li>pip(deps): bump pre-commit from 2.17.0 to 2.18.1 (#243) @dependabot</li> <li>pip(deps): bump click from 8.1.2 to 8.1.3 (#245) @dependabot</li> <li>pip(deps): bump pylint from 2.13.4 to 2.13.7 (#240) @dependabot</li> <li>pip(deps): bump tqdm from 4.63.1 to 4.64.0 (#244) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.2.8 to 8.2.12 (#241) @dependabot</li> <li>pip(deps): bump pytest from 7.1.1 to 7.1.2 (#239) @dependabot</li> <li>pip(deps): bump watchdog from 2.1.6 to 2.1.7 (#238) @dependabot</li> <li>pip(deps): bump pylint from 2.12.2 to 2.13.4 (#237) @dependabot</li> <li>pip(deps): bump mkdocs from 1.2.3 to 1.3.0 (#234) @dependabot</li> <li>pip(deps): bump tqdm from 4.63.0 to 4.63.1 (#233) @dependabot</li> <li>pip(deps): bump black from 22.1.0 to 22.3.0 (#236) @dependabot</li> <li>pip(deps): bump pytest from 7.0.1 to 7.1.1 (#231) @dependabot</li> <li>pip(deps): bump click from 8.0.4 to 8.1.2 (#235) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.2.5 to 8.2.8 (#232) @dependabot</li> <li>pip(deps): bump twine from 3.8.0 to 4.0.0 (#230) @dependabot</li> <li>document updates (#229) @devsetgo</li> </ul> <p>Published Date: 2022 December 04, 16:55</p>"},{"location":"release-notes/#additional-logging-configuration-v080","title":"Additional Logging Configuration (v0.8.0)","text":""},{"location":"release-notes/#whats-changed_9","title":"What's Changed","text":"<ul> <li>New Logging Configuration items (#228) @devsetgo</li> <li>pip(deps): bump tqdm from 4.62.3 to 4.63.0 (#224) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.2.3 to 8.2.4 (#227) @dependabot</li> <li>github actionts(deps): bump actions/setup-python from 2.3.1 to 3 (#226) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.1.9 to 8.2.3 (#225) @dependabot</li> <li>pip(deps): bump twine from 3.7.1 to 3.8.0 (#223) @dependabot</li> <li>pip(deps): bump pytest from 6.2.5 to 7.0.1 (#222) @dependabot</li> <li>pip(deps): bump pytest-runner from 5.3.1 to 6.0.0 (#221) @dependabot</li> <li>pip(deps): bump loguru from 0.5.3 to 0.6.0 (#218) @dependabot</li> <li>pip(deps): bump black from 21.12b0 to 22.1.0 (#219) @dependabot</li> <li>pip(deps): bump mkdocs-material from 8.1.8 to 8.1.9 (#220) @dependabot</li> </ul> <p>Published Date: 2022 March 12, 21:07</p>"},{"location":"release-notes/#v071","title":"(v0.7.1)","text":""},{"location":"release-notes/#whats-changed_10","title":"What's Changed","text":"<ul> <li>Bump version: 0.7.0 \u2192 0.7.1 (#217) @devsetgo</li> <li>Hotfix for setup file (#216) @devsetgo</li> </ul> <p>Published Date: 2022 January 29, 01:51</p>"},{"location":"release-notes/#logging-to-beta-testing-v070","title":"Logging to Beta Testing (v0.7.0)","text":"<p>Logging is now has basic unit tests and is more ready to use with live application.</p>"},{"location":"release-notes/#whats-changed_11","title":"What's Changed","text":"<ul> <li>Adding Logging Config (#215) @devsetgo</li> <li>pip(deps): bump pre-commit from 2.15.0 to 2.16.0 (#210) @dependabot</li> <li>pip(deps): bump pylint from 2.12.1 to 2.12.2 (#211) @dependabot</li> <li>pip(deps): bump tox from 3.24.4 to 3.24.5 (#212) @dependabot</li> <li>pip(deps): bump black from 21.11b1 to 21.12b0 (#213) @dependabot</li> <li>pip(deps): bump twine from 3.6.0 to 3.7.1 (#214) @dependabot</li> <li>pip(deps): bump twine from 3.5.0 to 3.6.0 (#204) @dependabot</li> <li>pip(deps): bump coverage-badge from 1.0.2 to 1.1.0 (#205) @dependabot</li> <li>pip(deps): bump mkdocs-material from 7.3.6 to 8.0.2 (#206) @dependabot</li> <li>pip(deps): bump pylint from 2.11.1 to 2.12.1 (#207) @dependabot</li> <li>pip(deps): bump black from 21.10b0 to 21.11b1 (#208) @dependabot</li> <li>github actionts(deps): bump actions/setup-python from 2.2.2 to 2.3.1 (#209) @dependabot</li> <li>Dev (#203) @devsetgo</li> <li>pip(deps): bump tox from 3.24.3 to 3.24.4 (#193) @dependabot</li> <li>pip(deps): bump tqdm from 4.62.2 to 4.62.3 (#194) @dependabot</li> <li>pip(deps): bump pylint from 2.10.2 to 2.11.1 (#195) @dependabot</li> <li>pip(deps): bump mkdocs-material from 7.2.6 to 7.3.0 (#196) @dependabot</li> <li>pip(deps): bump black from 21.8b0 to 21.9b0 (#197) @dependabot</li> <li>pip(deps): bump mkdocs-material from 7.2.4 to 7.2.6 (#189) @dependabot</li> <li>pip(deps): bump pytest from 6.2.4 to 6.2.5 (#191) @dependabot</li> <li>pip(deps): bump watchdog from 2.1.3 to 2.1.5 (#192) @dependabot</li> <li>pip(deps): bump tox from 3.24.1 to 3.24.3 (#190) @dependabot</li> <li>pip(deps): bump pre-commit from 2.14.0 to 2.15.0 (#188) @dependabot</li> <li>pip(deps): bump black from 21.7b0 to 21.8b0 (#187) @dependabot</li> <li>pip(deps): bump pylint from 2.9.6 to 2.10.2 (#184) @dependabot</li> <li>pip(deps): bump tqdm from 4.62.0 to 4.62.2 (#185) @dependabot</li> <li>github actionts(deps): bump actions/setup-python from 1 to 2.2.2 (#182) @dependabot</li> <li>Bump wheel from 0.36.2 to 0.37.0 (#180) @dependabot</li> <li>Bump mkdocs-material from 7.2.2 to 7.2.4 (#181) @dependabot</li> <li>Bump tox from 3.24.0 to 3.24.1 (#177) @dependabot</li> <li>Bump mkdocs-material from 7.2.1 to 7.2.2 (#178) @dependabot</li> <li>Bump pre-commit from 2.13.0 to 2.14.0 (#179) @dependabot</li> <li>Bump pylint from 2.9.5 to 2.9.6 (#176) @dependabot</li> <li>Bump tqdm from 4.61.2 to 4.62.0 (#175) @dependabot</li> <li>Bump mkdocs-material from 7.1.10 to 7.2.1 (#174) @dependabot</li> <li>Bump twine from 3.4.1 to 3.4.2 (#171) @dependabot</li> <li>Bump pylint from 2.9.3 to 2.9.5 (#170) @dependabot</li> <li>Bump mkdocs from 1.2.1 to 1.2.2 (#173) @dependabot</li> <li>documentation update (#169) @devsetgo</li> <li>README fix (#168) @devsetgo</li> </ul> <p>Published Date: 2022 January 29, 01:42</p>"},{"location":"release-notes/#logging-configuration-v060","title":"Logging Configuration (v0.6.0)","text":""},{"location":"release-notes/#whats-changed_12","title":"What's Changed","text":"<ul> <li>Adding Logging and Cleanup (#167) @devsetgo</li> <li>Bump tqdm from 4.61.1 to 4.61.2 (#166) @dependabot</li> <li>Bump pylint from 2.8.3 to 2.9.3 (#165) @dependabot</li> <li>Bump watchdog from 2.1.2 to 2.1.3 (#164) @dependabot</li> <li>Bump mkdocs-material from 7.1.8 to 7.1.9 (#163) @dependabot</li> <li>Bump tqdm from 4.61.0 to 4.61.1 (#162) @dependabot</li> <li>Bump mkdocs-material from 7.1.7 to 7.1.8 (#161) @dependabot</li> <li>Bump mkdocs from 1.1.2 to 1.2.1 (#159) @dependabot</li> <li>Bump black from 21.5b2 to 21.6b0 (#158) @dependabot</li> <li>Bump mkdocs-material from 7.1.6 to 7.1.7 (#160) @dependabot</li> <li>Bump pytest-cov from 2.12.0 to 2.12.1 (#154) @dependabot</li> <li>Bump pylint from 2.8.2 to 2.8.3 (#155) @dependabot</li> <li>Bump black from 21.5b1 to 21.5b2 (#156) @dependabot</li> <li>Bump mkdocs-material from 7.1.5 to 7.1.6 (#157) @dependabot</li> <li>Bump tqdm from 4.60.0 to 4.61.0 (#153) @dependabot</li> <li>Bump pre-commit from 2.12.1 to 2.13.0 (#151) @dependabot</li> <li>Bump pytest-runner from 5.3.0 to 5.3.1 (#152) @dependabot</li> <li>Bump mkdocs-material from 7.1.4 to 7.1.5 (#150) @dependabot</li> <li>Bump watchdog from 2.1.1 to 2.1.2 (#149) @dependabot</li> <li>Bump click from 7.1.2 to 8.0.1 (#148) @dependabot</li> <li>Bump black from 21.5b0 to 21.5b1 (#147) @dependabot</li> <li>Bump watchdog from 2.1.0 to 2.1.1 (#146) @dependabot</li> <li>Bump pytest-cov from 2.11.1 to 2.12.0 (#145) @dependabot</li> <li>Bump flake8 from 3.9.1 to 3.9.2 (#143) @dependabot</li> <li>Bump pytest from 6.2.3 to 6.2.4 (#139) @dependabot</li> <li>Bump watchdog from 2.0.3 to 2.1.0 (#138) @dependabot</li> <li>Bump black from 21.4b2 to 21.5b0 (#140) @dependabot</li> <li>Bump mkdocs-material from 7.1.3 to 7.1.4 (#141) @dependabot</li> <li>Dev (#142) @devsetgo</li> <li>Bump tox from 3.23.0 to 3.23.1 (#137) @dependabot</li> <li>Bump autopep8 from 1.5.6 to 1.5.7 (#136) @dependabot</li> <li>Bump pylint from 2.7.4 to 2.8.2 (#135) @dependabot</li> <li>Bump black from 20.8b1 to 21.4b2 (#134) @dependabot</li> <li>Bump mkdocs-material from 7.1.2 to 7.1.3 (#133) @dependabot</li> <li>Adding SonarCloud Code Coverage (#130) @devsetgo</li> <li>Bump mkdocs-material from 7.1.1 to 7.1.2 (#132) @dependabot</li> <li>Bump watchdog from 2.0.2 to 2.0.3 (#131) @dependabot</li> <li>Bump pre-commit from 2.12.0 to 2.12.1 (#129) @dependabot</li> <li>Bump flake8 from 3.9.0 to 3.9.1 (#128) @dependabot</li> <li>Bump mkdocs-material from 7.1.0 to 7.1.1 (#127) @dependabot</li> <li>Bump tqdm from 4.59.0 to 4.60.0 (#124) @dependabot</li> <li>Bump pytest from 6.2.2 to 6.2.3 (#125) @dependabot</li> <li>Bump pre-commit from 2.11.1 to 2.12.0 (#126) @dependabot</li> <li>Bump pylint from 2.7.2 to 2.7.4 (#122) @dependabot</li> <li>Bump mkdocs-material from 7.0.6 to 7.1.0 (#123) @dependabot</li> <li>Bump mkdocs-material from 7.0.5 to 7.0.6 (#121) @dependabot</li> <li>Bump flake8 from 3.8.4 to 3.9.0 (#120) @dependabot</li> <li>Bump twine from 3.3.0 to 3.4.1 (#118) @dependabot</li> <li>Bump autopep8 from 1.5.5 to 1.5.6 (#119) @dependabot</li> </ul> <p>Published Date: 2021 July 16, 23:44</p>"},{"location":"release-notes/#fixing-publish-v050-2","title":"Fixing Publish (v0.5.0-2)","text":""},{"location":"release-notes/#whats-changed_13","title":"What's Changed","text":"<ul> <li>adding update for publish (#117) @devsetgo</li> </ul> <p>Published Date: 2021 March 18, 17:19</p>"},{"location":"release-notes/#calendar-and-regex-function-documentation-v050","title":"Calendar and RegEx Function + Documentation (v0.5.0)","text":""},{"location":"release-notes/#whats-changed_14","title":"What's Changed","text":"<ul> <li>Adding Calendar Functions (#116) @devsetgo</li> <li>Bump pre-commit from 2.10.1 to 2.11.1 (#113) @dependabot</li> <li>update to Saturday (#115) @devsetgo</li> <li>Bump tqdm from 4.58.0 to 4.59.0 (#112) @dependabot</li> <li>Bump mkdocs-material from 7.0.4 to 7.0.5 (#114) @dependabot</li> <li>fixes for mkdoc material update (#111) @devsetgo</li> <li>Bump tox from 3.22.0 to 3.23.0 (#109) @dependabot</li> <li>Bump mkdocs-material from 7.0.2 to 7.0.4 (#108) @dependabot</li> <li>Bump pylint from 2.7.1 to 2.7.2 (#107) @dependabot</li> <li>Bump coverage from 5.4 to 5.5 (#110) @dependabot</li> <li>Bump pylint from 2.6.2 to 2.7.1 (#103) @dependabot</li> <li>Bump mkdocs-material from 6.2.8 to 7.0.2 (#104) @dependabot</li> <li>Bump watchdog from 2.0.1 to 2.0.2 (#105) @dependabot</li> <li>Bump tqdm from 4.57.0 to 4.58.0 (#106) @dependabot</li> <li>Bump tox from 3.21.4 to 3.22.0 (#101) @dependabot</li> <li>Bump watchdog from 2.0.0 to 2.0.1 (#99) @dependabot</li> <li>Bump pylint from 2.6.0 to 2.6.2 (#102) @dependabot</li> <li>Bump tqdm from 4.56.2 to 4.57.0 (#100) @dependabot</li> <li>Bump pytest-runner from 5.2 to 5.3.0 (#98) @dependabot</li> <li>Bump tqdm from 4.56.0 to 4.56.2 (#97) @dependabot</li> <li>Bump watchdog from 1.0.2 to 2.0.0 (#96) @dependabot</li> <li>Bump pre-commit from 2.10.0 to 2.10.1 (#95) @dependabot</li> <li>Bump mkdocs-material from 6.2.6 to 6.2.8 (#94) @dependabot</li> <li>Bump tox from 3.21.3 to 3.21.4 (#93) @dependabot</li> <li>Bump autopep8 from 1.5.4 to 1.5.5 (#92) @dependabot</li> <li>Bump tox from 3.21.2 to 3.21.3 (#87) @dependabot</li> <li>Bump mkdocs-material from 6.2.5 to 6.2.6 (#88) @dependabot</li> <li>Bump pytest from 6.2.1 to 6.2.2 (#89) @dependabot</li> <li>Bump coverage from 5.3.1 to 5.4 (#91) @dependabot</li> <li>Bump pre-commit from 2.9.3 to 2.10.0 (#90) @dependabot</li> <li>Bump tox from 3.21.1 to 3.21.2 (#84) @dependabot</li> <li>Bump mkdocs-material from 6.2.4 to 6.2.5 (#85) @dependabot</li> <li>Bump pytest-cov from 2.10.1 to 2.11.1 (#86) @dependabot</li> <li>Bump tox from 3.20.1 to 3.21.1 (#81) @dependabot</li> <li>Bump mkdocs-material from 6.2.3 to 6.2.4 (#82) @dependabot</li> <li>Bump tqdm from 4.55.1 to 4.56.0 (#83) @dependabot</li> <li>Bump tqdm from 4.55.0 to 4.55.1 (#80) @dependabot</li> <li>Bump mkdocs-material from 6.2.2 to 6.2.3 (#79) @dependabot</li> </ul> <p>Published Date: 2021 March 18, 17:06</p>"},{"location":"release-notes/#minor-updates-and-library-updates-v041","title":"Minor updates and library updates. (v0.4.1)","text":""},{"location":"release-notes/#whats-changed_15","title":"What's Changed","text":"<ul> <li>Updates and Minor updates (#78) @devsetgo</li> <li>Bump tqdm from 4.54.1 to 4.55.0 (#77) @dependabot</li> <li>Bump twine from 3.2.0 to 3.3.0 (#76) @dependabot</li> <li>Bump coverage from 5.3 to 5.3.1 (#74) @dependabot</li> <li>Bump mkdocs-material from 6.1.7 to 6.2.2 (#75) @dependabot</li> <li>Bump watchdog from 0.10.4 to 1.0.2 (#73) @dependabot</li> <li>Bump pytest from 6.1.2 to 6.2.1 (#71) @dependabot</li> <li>Bump wheel from 0.36.1 to 0.36.2 (#70) @dependabot</li> <li>Bump tqdm from 4.54.0 to 4.54.1 (#67) @dependabot</li> <li>Bump mkdocs-material from 6.1.6 to 6.1.7 (#68) @dependabot</li> <li>Bump pre-commit from 2.9.2 to 2.9.3 (#69) @dependabot</li> <li>Bump wheel from 0.36.0 to 0.36.1 (#66) @dependabot</li> <li>Bump wheel from 0.35.1 to 0.36.0 (#64) @dependabot</li> <li>Bump tqdm from 4.53.0 to 4.54.0 (#65) @dependabot</li> <li>Bump pre-commit from 2.8.2 to 2.9.2 (#61) @dependabot</li> <li>Bump mkdocs-material from 6.1.5 to 6.1.6 (#60) @dependabot</li> <li>Bump tqdm from 4.52.0 to 4.53.0 (#62) @dependabot</li> <li>Bump watchdog from 0.10.3 to 0.10.4 (#63) @dependabot</li> <li>Bump tqdm from 4.51.0 to 4.52.0 (#59) @dependabot</li> <li>Bump mkdocs-material from 6.1.4 to 6.1.5 (#58) @dependabot</li> <li>Bump mkdocs-material from 6.1.2 to 6.1.4 (#57) @dependabot</li> <li>Bump pre-commit from 2.8.0 to 2.8.2 (#55) @dependabot</li> <li>Bump mkdocs-material from 6.1.0 to 6.1.2 (#56) @dependabot</li> <li>Bump pytest from 6.1.1 to 6.1.2 (#52) @dependabot</li> <li>Bump pre-commit from 2.7.1 to 2.8.0 (#53) @dependabot</li> <li>Bump tqdm from 4.50.2 to 4.51.0 (#54) @dependabot</li> <li>Bump mkdocs-material from 6.0.2 to 6.1.0 (#51) @dependabot</li> <li>Bump tqdm from 4.50.1 to 4.50.2 (#49) @dependabot</li> <li>Bump tox from 3.20.0 to 3.20.1 (#50) @dependabot</li> <li>Bump pytest from 6.1.0 to 6.1.1 (#48) @dependabot</li> <li>Bump mkdocs-material from 6.0.1 to 6.0.2 (#47) @dependabot</li> <li>Bump flake8 from 3.8.3 to 3.8.4 (#45) @dependabot</li> <li>Bump tqdm from 4.50.0 to 4.50.1 (#44) @dependabot</li> <li>Bump bump2version from 1.0.0 to 1.0.1 (#46) @dependabot</li> <li>Bump tqdm from 4.49.0 to 4.50.0 (#42) @dependabot</li> <li>Bump black from 19.10b0 to 20.8b1 (#43) @dependabot</li> <li>Bump tqdm from 4.46.0 to 4.49.0 (#40) @dependabot</li> <li>Bump pytest from 5.4.2 to 6.1.0 (#39) @dependabot</li> <li>Bump coverage from 5.1 to 5.3 (#38) @dependabot</li> <li>Bump autoflake from 1.3.1 to 1.4 (#41) @dependabot</li> <li>Bump twine from 3.1.1 to 3.2.0 (#37) @dependabot</li> <li>Bump wheel from 0.34.2 to 0.35.1 (#34) @dependabot</li> <li>Bump pytest-cov from 2.9.0 to 2.10.1 (#36) @dependabot</li> <li>Bump watchdog from 0.10.2 to 0.10.3 (#35) @dependabot</li> <li>Bump mkdocs-material from 5.2.2 to 6.0.1 (#33) @dependabot</li> <li>Bump pylint from 2.5.2 to 2.6.0 (#32) @dependabot-preview</li> <li>Bump pre-commit from 2.4.0 to 2.7.1 (#31) @dependabot-preview</li> <li>Bump tox from 3.15.1 to 3.20.0 (#30) @dependabot-preview</li> <li>Bump flake8 from 3.8.2 to 3.8.3 (#29) @dependabot-preview</li> <li>Bump autopep8 from 1.5.2 to 1.5.4 (#28) @dependabot-preview</li> </ul> <p>Published Date: 2020 December 26, 23:51</p>"},{"location":"release-notes/#040-save_csv-options-v040","title":"0.4.0 - save_csv options (v0.4.0)","text":""},{"location":"release-notes/#040-examples-and-data","title":"[0.4.0] - Examples and Data","text":""},{"location":"release-notes/#added","title":"Added","text":"<ul> <li>skipping version 0.3.0 and adding to 0.4.0</li> <li>Adding delimiter option to save_csv<ul> <li>Tests to check if delimiter &gt; 1 character</li> <li>set ',' if none</li> </ul> </li> <li>Adding quotechar option to save_csv</li> <li>Tests to check if quotechar &gt; 1 character<ul> <li>set '\"' if none</li> </ul> </li> <li>Add test of non-list to save_csv</li> </ul>"},{"location":"release-notes/#030-examples-and-data","title":"[0.3.0] - Examples and Data","text":""},{"location":"release-notes/#added_1","title":"Added","text":"<ul> <li>Adding examples (see examples folder)</li> <li>Adding file_function documentation</li> <li>Adding documents site - https://devsetgo.github.io/devsetgo_lib/</li> </ul> <p>Published Date: 2020 April 16, 21:54</p>"},{"location":"release-notes/#improvements-v020","title":"Improvements (v0.2.0)","text":"<ul> <li>Improved Tests</li> <li>Improved Errors</li> <li>Adding more logging</li> </ul> <p>Published Date: 2020 January 26, 21:08</p>"},{"location":"release-notes/#v011-v011","title":"v0.1.1 (v0.1.1)","text":"<ul> <li>New documentation</li> <li>fixes to pypi deployment</li> </ul> <p>Published Date: 2020 January 26, 17:26</p>"},{"location":"release-notes/#beta-release-v010b2","title":"Beta Release (v0.1.0b2)","text":"<p>Basic Function (file and folder) Publish to PyPi (fixing PyPi publishing issues) Needs documentation.</p> <p>Published Date: 2020 January 26, 13:03</p>"},{"location":"release-notes/#pypi-beta-release-v010b","title":"Pypi Beta Release (v0.1.0b)","text":"<p>Change to semantic versioning - Publish to Pypi - Base Functions</p> <p>Published Date: 2020 January 26, 12:53</p>"},{"location":"database/async_database_setup/","title":"Reference","text":""},{"location":"database/async_database_setup/#dsg_lib.async_database","title":"<code>dsg_lib.async_database</code>","text":"<p>async_database.py.</p> <p>This module provides classes for managing asynchronous database operations using SQLAlchemy and asyncio.</p> <p>Classes:</p> Name Description <code>- DBConfig</code> <p>Manages the database configuration.</p> <code>- AsyncDatabase</code> <p>Manages the asynchronous database operations.</p> <p>The DBConfig class initializes the database configuration and creates a SQLAlchemy engine and a MetaData instance.</p> <p>The AsyncDatabase class uses an instance of DBConfig to perform asynchronous database operations. It provides methods to get a database session and to create tables in the database.</p> <p>This module uses the logger from the dsg_lib for logging.</p>"},{"location":"database/async_database_setup/#dsg_lib.async_database.AsyncDatabase","title":"<code>AsyncDatabase</code>","text":"<p>A class used to manage the asynchronous database operations.</p>"},{"location":"database/async_database_setup/#dsg_lib.async_database.AsyncDatabase--attributes","title":"Attributes","text":"<p>db_config : DBConfig     an instance of DBConfig class containing the database configuration Base : Base     the declarative base model for SQLAlchemy</p>"},{"location":"database/async_database_setup/#dsg_lib.async_database.AsyncDatabase--methods","title":"Methods","text":"<p>get_db_session():     Returns a context manager that provides a new database session. create_tables():     Asynchronously creates all tables in the database.</p> Source code in <code>dsg_lib/async_database.py</code> <pre><code>class AsyncDatabase:\n    \"\"\"\n    A class used to manage the asynchronous database operations.\n\n    Attributes\n    ----------\n    db_config : DBConfig\n        an instance of DBConfig class containing the database configuration\n    Base : Base\n        the declarative base model for SQLAlchemy\n\n    Methods\n    -------\n    get_db_session():\n        Returns a context manager that provides a new database session.\n    create_tables():\n        Asynchronously creates all tables in the database.\n    \"\"\"\n\n    def __init__(self, db_config: DBConfig):\n        \"\"\"Initialize the AsyncDatabase class with an instance of DBConfig.\n\n        Parameters:\n        db_config (DBConfig): An instance of DBConfig class containing the\n        database configuration.\n\n        Returns: None\n        \"\"\"\n        self.db_config = db_config\n        self.Base = BASE\n        logger.debug(\"AsyncDatabase initialized\")\n\n    def get_db_session(self):\n        \"\"\"This method returns a context manager that provides a new database\n        session.\n\n        Parameters: None\n\n        Returns: contextlib._GeneratorContextManager: A context manager that\n        provides a new database session.\n        \"\"\"\n        logger.debug(\"Getting database session\")\n        return self.db_config.get_db_session()\n\n    async def create_tables(self):\n        \"\"\"This method asynchronously creates all tables in the database.\n\n        Parameters: None\n\n        Returns: None\n        \"\"\"\n        logger.debug(\"Creating tables\")\n        try:\n            # Bind the engine to the metadata of the base class\n            self.Base.metadata.bind = self.db_config.engine\n\n            # Begin a new transaction\n            async with self.db_config.engine.begin() as conn:\n                # Run a function in a synchronous manner\n                await conn.run_sync(self.Base.metadata.create_all)\n            logger.info(\"Tables created successfully\")\n        except Exception as ex:  # pragma: no cover\n            # Log the error and raise it\n            logger.error(f\"Error creating tables: {ex}\")  # pragma: no cover\n            raise  # pragma: no cover\n</code></pre>"},{"location":"database/async_database_setup/#dsg_lib.async_database.AsyncDatabase.__init__","title":"<code>__init__(db_config)</code>","text":"<p>Initialize the AsyncDatabase class with an instance of DBConfig.</p> <p>Parameters: db_config (DBConfig): An instance of DBConfig class containing the database configuration.</p> <p>Returns: None</p> Source code in <code>dsg_lib/async_database.py</code> <pre><code>def __init__(self, db_config: DBConfig):\n    \"\"\"Initialize the AsyncDatabase class with an instance of DBConfig.\n\n    Parameters:\n    db_config (DBConfig): An instance of DBConfig class containing the\n    database configuration.\n\n    Returns: None\n    \"\"\"\n    self.db_config = db_config\n    self.Base = BASE\n    logger.debug(\"AsyncDatabase initialized\")\n</code></pre>"},{"location":"database/async_database_setup/#dsg_lib.async_database.AsyncDatabase.create_tables","title":"<code>create_tables()</code>  <code>async</code>","text":"<p>This method asynchronously creates all tables in the database.</p> <p>Parameters: None</p> <p>Returns: None</p> Source code in <code>dsg_lib/async_database.py</code> <pre><code>async def create_tables(self):\n    \"\"\"This method asynchronously creates all tables in the database.\n\n    Parameters: None\n\n    Returns: None\n    \"\"\"\n    logger.debug(\"Creating tables\")\n    try:\n        # Bind the engine to the metadata of the base class\n        self.Base.metadata.bind = self.db_config.engine\n\n        # Begin a new transaction\n        async with self.db_config.engine.begin() as conn:\n            # Run a function in a synchronous manner\n            await conn.run_sync(self.Base.metadata.create_all)\n        logger.info(\"Tables created successfully\")\n    except Exception as ex:  # pragma: no cover\n        # Log the error and raise it\n        logger.error(f\"Error creating tables: {ex}\")  # pragma: no cover\n        raise  # pragma: no cover\n</code></pre>"},{"location":"database/async_database_setup/#dsg_lib.async_database.AsyncDatabase.get_db_session","title":"<code>get_db_session()</code>","text":"<p>This method returns a context manager that provides a new database session.</p> <p>Parameters: None</p> <p>Returns: contextlib._GeneratorContextManager: A context manager that provides a new database session.</p> Source code in <code>dsg_lib/async_database.py</code> <pre><code>def get_db_session(self):\n    \"\"\"This method returns a context manager that provides a new database\n    session.\n\n    Parameters: None\n\n    Returns: contextlib._GeneratorContextManager: A context manager that\n    provides a new database session.\n    \"\"\"\n    logger.debug(\"Getting database session\")\n    return self.db_config.get_db_session()\n</code></pre>"},{"location":"database/base_schema/","title":"Reference","text":""},{"location":"database/base_schema/#dsg_lib.base_schema","title":"<code>dsg_lib.base_schema</code>","text":"<p>This module defines the base schema for database models in the application.</p> <p>The module uses SQLAlchemy as the ORM and provides a <code>SchemaBase</code> class that all other models should inherit from. The <code>SchemaBase</code> class includes common columns that are needed for most models like <code>pkid</code>, <code>date_created</code>, and <code>date_updated</code>.</p> <ul> <li><code>pkid</code>: A unique identifier for each record. It's a string representation of a   UUID.</li> <li><code>date_created</code>: The date and time when a particular row was inserted into the   table.     It defaults to the current UTC time when the instance is created.</li> <li><code>date_updated</code>: The date and time when a particular row was last updated.     It defaults to the current UTC time whenever the instance is updated.</li> </ul> <p>To create a new database model, import this module and extend the <code>SchemaBase</code> class.</p> <p>Example: ```python from dsg_lib import base_schema</p> <p>class MyModel(base_schema.SchemaBase):         # Define your model-specific columns here my_column =         base_schema.Column(base_schema.String(50)) ```</p>"},{"location":"database/base_schema/#dsg_lib.base_schema.SchemaBase","title":"<code>SchemaBase</code>","text":"<p>This class provides a base schema that includes common columns for most models. All other models should inherit from this class.</p> <p>Attributes:</p> Name Type Description <code>pkid</code> <code>str</code> <p>A unique identifier for each record. It's a string</p> <code>representation</code> <code>of a UUID. date_created (datetime</code> <p>The date and time</p> <code>date_updated</code> <code>datetime</code> <p>The date and time when a particular row was</p> <p>Example: ```python from dsg_lib import base_schema from sqlalchemy.orm import declarative_base</p> <p>BASE = declarative_base()</p> <p>class MyModel(base_schema.SchemaBase, BASE):     # Define your model-specific columns here my_column =     base_schema.Column(base_schema.String(50)) ```</p> Source code in <code>dsg_lib/base_schema.py</code> <pre><code>class SchemaBase:\n    \"\"\"\n    This class provides a base schema that includes common columns for most\n    models. All other models should inherit from this class.\n\n    Attributes:\n        pkid (str): A unique identifier for each record. It's a string\n        representation of a UUID. date_created (datetime): The date and time\n        when a particular row was inserted into the table.\n            It defaults to the current UTC time when the instance is created.\n        date_updated (datetime): The date and time when a particular row was\n        last updated.\n            It defaults to the current UTC time whenever the instance is\n            updated.\n\n    Example: ```python from dsg_lib import base_schema from sqlalchemy.orm\n    import declarative_base\n\n    BASE = declarative_base()\n\n    class MyModel(base_schema.SchemaBase, BASE):\n        # Define your model-specific columns here my_column =\n        base_schema.Column(base_schema.String(50))\n    ```\n    \"\"\"\n\n    # Each instance in the table will have a unique id which is a string\n    # representation of a UUID\n    pkid = Column(\n        String(36),\n        primary_key=True,\n        index=True,\n        default=lambda: str(uuid4()),\n    )\n\n    # The date and time when a particular row was inserted into the table. It\n    # defaults to the current UTC time when the instance is created.\n    date_created = Column(DateTime, index=True, default=datetime.utcnow())\n\n    # The date and time when a particular row was last updated. It defaults to\n    # the current UTC time whenever the instance is updated.\n    date_updated = Column(\n        DateTime,\n        index=True,\n        default=datetime.utcnow(),\n        onupdate=datetime.utcnow(),\n    )\n</code></pre>"},{"location":"database/base_schema/#dsg_lib.base_schema.import_sqlalchemy","title":"<code>import_sqlalchemy()</code>","text":"<p>This function tries to import SQLAlchemy and its components, and raises an ImportError if SQLAlchemy is not installed or if the installed version is not compatible with the minimum required version.</p> <p>Returns:</p> Name Type Description <code>Tuple</code> <code>Tuple</code> <p>A tuple containing the imported SQLAlchemy module and its</p> <code>Tuple</code> <p>components (Column, DateTime, String).</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If SQLAlchemy is not installed or if the installed version</p> <p>Example: <code>python from dsg_lib import base_schema sqlalchemy, Column, DateTime, String = base_schema.import_sqlalchemy()</code></p> Source code in <code>dsg_lib/base_schema.py</code> <pre><code>def import_sqlalchemy() -&gt; Tuple:\n    \"\"\"\n    This function tries to import SQLAlchemy and its components, and raises an\n    ImportError if SQLAlchemy is not installed or if the installed version is\n    not compatible with the minimum required version.\n\n    Returns:\n        Tuple: A tuple containing the imported SQLAlchemy module and its\n        components (Column, DateTime, String).\n\n    Raises:\n        ImportError: If SQLAlchemy is not installed or if the installed version\n        is not compatible with the minimum required version.\n\n    Example: ```python from dsg_lib import base_schema sqlalchemy, Column,\n    DateTime, String = base_schema.import_sqlalchemy() ```\n    \"\"\"\n    try:\n        import sqlalchemy\n        from sqlalchemy import Column, DateTime, String\n\n    except ImportError:\n        Column = DateTime = String = sqlalchemy = None\n\n    # Check SQLAlchemy version\n    min_version = \"1.4.0\"  # replace with your minimum required version\n    if sqlalchemy is not None and packaging_version.parse(\n        sqlalchemy.__version__\n    ) &lt; packaging_version.parse(min_version):\n        raise ImportError(\n            f\"SQLAlchemy version &gt;= {min_version} required, run `pip install --upgrade sqlalchemy`\"\n        )\n\n    return (\n        sqlalchemy,\n        Column,\n        DateTime,\n        String,\n    )\n</code></pre>"},{"location":"database/database_configuration/","title":"Reference","text":""},{"location":"database/database_configuration/#dsg_lib.database_config","title":"<code>dsg_lib.database_config</code>","text":"<p>This module provides classes and functions for managing asynchronous database operations using SQLAlchemy and asyncio.</p> <p>The main classes are DBConfig, which manages the database configuration and creates a SQLAlchemy engine and a MetaData instance, and AsyncDatabase, which uses an instance of DBConfig to perform asynchronous database operations.</p> <p>The module also provides a function, import_sqlalchemy, which tries to import SQLAlchemy and its components, and raises an ImportError if SQLAlchemy is not installed or if the installed version is not compatible.</p> <p>The module uses the logger from the <code>dsg_lib</code> for logging, and the <code>time</code> module for working with times. It also uses the <code>contextlib</code> module for creating context managers, and the <code>typing</code> module for type hinting.</p> <p>The <code>BASE</code> variable is a base class for declarative database models. It is created using the <code>declarative_base</code> function from <code>sqlalchemy.orm</code>.</p> <p>This module is part of the <code>dsg_lib</code> package, which provides utilities for working with databases in Python.</p> <p>Example: ```python from dsg_lib import database_config</p>"},{"location":"database/database_configuration/#dsg_lib.database_config--define-your-database-configuration-config","title":"Define your database configuration config = {","text":"<pre><code>\"database_uri\": \"postgresql+asyncpg://user:password@localhost/dbname\",\n\"echo\": True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n\"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n</code></pre> <p>}</p>"},{"location":"database/database_configuration/#dsg_lib.database_config--create-a-dbconfig-instance-db_config-database_configdbconfigconfig","title":"Create a DBConfig instance db_config = database_config.DBConfig(config)","text":""},{"location":"database/database_configuration/#dsg_lib.database_config--use-the-dbconfig-instance-to-get-a-database-session-async-with","title":"Use the DBConfig instance to get a database session async with","text":"<p>db_config.get_db_session() as session:     # Perform your database operations here pass ```</p>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig","title":"<code>DBConfig</code>","text":"<p>A class used to manage the database configuration and create a SQLAlchemy engine.</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>dict</code> <p>A dictionary containing the database configuration</p> <code>parameters.</code> <code>engine (Engine</code> <p>The SQLAlchemy engine created with the</p> <code>database</code> <code>URI from the config. metadata (MetaData</code> <p>The SQLAlchemy</p> <p>Create Engine Support Functions by Database Type Confirmed by testing [SQLITE, PostrgeSQL] To Be Tested [MySQL, Oracle, MSSQL] and should be considered experimental ------- Option          SQLite  PostgreSQL  MySQL Oracle  MSSQL echo                Yes         Yes         Yes     Yes Yes future              Yes         Yes         Yes     Yes     Yes pool_pre_ping       Yes         Yes         Yes     Yes     Yes pool_size No          Yes         Yes     Yes     Yes max_overflow        No Yes         Yes     Yes     Yes pool_recycle        Yes         Yes Yes     Yes     Yes pool_timeout        No          Yes         Yes     Yes Yes</p> <p>Example: ```python from dsg_lib import database_config</p>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig--define-your-database-configuration-config","title":"Define your database configuration config = {","text":"<pre><code>\"database_uri\": \"postgresql+asyncpg://user:password@localhost/dbname\",\n\"echo\": True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n\"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n</code></pre> <p>}</p>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig--create-a-dbconfig-instance-db_config-database_configdbconfigconfig","title":"Create a DBConfig instance db_config = database_config.DBConfig(config)","text":""},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig--use-the-dbconfig-instance-to-get-a-database-session-async-with","title":"Use the DBConfig instance to get a database session async with","text":"<p>db_config.get_db_session() as session:     # Perform your database operations here pass ```</p> Source code in <code>dsg_lib/database_config.py</code> <pre><code>class DBConfig:\n    \"\"\"\n    A class used to manage the database configuration and create a SQLAlchemy\n    engine.\n\n    Attributes:\n        config (dict): A dictionary containing the database configuration\n        parameters. engine (Engine): The SQLAlchemy engine created with the\n        database URI from the config. metadata (MetaData): The SQLAlchemy\n        MetaData instance.\n\n\n    Create Engine Support Functions by Database Type Confirmed by testing\n    [SQLITE, PostrgeSQL] To Be Tested [MySQL, Oracle, MSSQL] and should be\n    considered experimental ------- Option          SQLite  PostgreSQL  MySQL\n    Oracle  MSSQL echo                Yes         Yes         Yes     Yes\n    Yes future              Yes         Yes         Yes     Yes     Yes\n    pool_pre_ping       Yes         Yes         Yes     Yes     Yes pool_size\n    No          Yes         Yes     Yes     Yes max_overflow        No\n    Yes         Yes     Yes     Yes pool_recycle        Yes         Yes\n    Yes     Yes     Yes pool_timeout        No          Yes         Yes     Yes\n    Yes\n\n    Example: ```python from dsg_lib import database_config\n\n    # Define your database configuration config = {\n        \"database_uri\": \"postgresql+asyncpg://user:password@localhost/dbname\",\n        \"echo\": True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n        \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n    }\n\n    # Create a DBConfig instance db_config = database_config.DBConfig(config)\n\n    # Use the DBConfig instance to get a database session async with\n    db_config.get_db_session() as session:\n        # Perform your database operations here pass\n    ```\n\n    \"\"\"\n\n    SUPPORTED_PARAMETERS = {\n        \"sqlite\": {\"echo\", \"future\", \"pool_recycle\"},\n        \"postgresql\": {\n            \"echo\",\n            \"future\",\n            \"pool_pre_ping\",\n            \"pool_size\",\n            \"max_overflow\",\n            \"pool_recycle\",\n            \"pool_timeout\",\n        },\n        # Add other engines here...\n    }\n\n    def __init__(self, config: Dict):\n        \"\"\"\n        Initializes the DBConfig instance with the given database configuration.\n\n        The configuration should be a dictionary with the following keys: -\n        \"database_uri\": The URI for the database. - \"echo\": If True, the engine\n        will log all statements as well as a `repr()` of their parameter lists\n        to the engines logger, which defaults to sys.stdout. - \"future\": If\n        True, use the future version of SQLAlchemy, which supports asyncio. -\n        \"pool_pre_ping\": If True, the pool will test the connection for liveness\n        upon each checkout. - \"pool_size\": The size of the connection pool to be\n        maintained. - \"max_overflow\": The number of connections that can be\n        opened above the `pool_size` setting, when all other connections are in\n        use. - \"pool_recycle\": The number of seconds after which a connection is\n        automatically recycled. This is required for MySQL, which removes\n        connections after 8 hours idle by default. - \"pool_timeout\": The number\n        of seconds to wait before giving up on getting a connection from the\n        pool.\n\n        Args:\n            config (Dict): A dictionary containing the database configuration\n            parameters.\n\n        Raises:\n            Exception: If there are unsupported parameters for the database\n            engine type.\n\n        Example: ```python from dsg_lib import database_config\n\n        # Define your database configuration config = {\n            \"database_uri\":\n            \"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\": True,\n            \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n            \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n        }\n\n        # Create a DBConfig instance db_config =\n        database_config.DBConfig(config) ```\n        \"\"\"\n        self.config = config\n        engine_type = self.config[\"database_uri\"].split(\"+\")[0]\n        supported_parameters = self.SUPPORTED_PARAMETERS.get(engine_type, set())\n        unsupported_parameters = (\n            set(config.keys()) - supported_parameters - {\"database_uri\"}\n        )\n        if unsupported_parameters:\n            error_message = (\n                f\"Unsupported parameters for {engine_type}: {unsupported_parameters}\"\n            )\n            logger.error(error_message)\n            raise Exception(error_message)\n\n        engine_parameters = {\n            param: self.config.get(param)\n            for param in supported_parameters\n            if self.config.get(param) is not None\n        }\n        self.engine = create_async_engine(\n            self.config[\"database_uri\"], **engine_parameters\n        )\n        self.metadata = MetaData()\n\n    @asynccontextmanager\n    async def get_db_session(self):\n        \"\"\"\n        This method returns a context manager that provides a new database\n        session.\n\n        The session is created using the SQLAlchemy engine from the DBConfig\n        instance, and it does not expire on commit. The session is of type\n        AsyncSession.\n\n        This method should be used with the `async with` statement.\n\n        Yields:\n            AsyncSession: A new SQLAlchemy asynchronous session.\n\n        Raises:\n            SQLAlchemyError: If a database error occurs.\n\n        Example: ```python from dsg_lib import database_config\n\n        # Define your database configuration config = {\n            \"database_uri\":\n            \"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\": True,\n            \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n            \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n        }\n\n        # Create a DBConfig instance db_config =\n        database_config.DBConfig(config)\n\n        # Use the DBConfig instance to get a database session async with\n        db_config.get_db_session() as session:\n            # Perform your database operations here pass\n        ```\n        \"\"\"\n        logger.debug(\"Creating new database session\")\n        try:\n            # Create a new database session\n            async with sessionmaker(\n                self.engine, expire_on_commit=False, class_=AsyncSession\n            )() as session:\n                # Yield the session to the context manager\n                yield session\n        except SQLAlchemyError as e:  # pragma: no cover\n            # Log the error and raise it\n            logger.error(f\"Database error occurred: {str(e)}\")  # pragma: no cover\n            raise  # pragma: no cover\n        finally:  # pragma: no cover\n            # Log the end of the database session\n            logger.debug(\"Database session ended\")  # pragma: no cover\n</code></pre>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig.__init__","title":"<code>__init__(config)</code>","text":"<p>Initializes the DBConfig instance with the given database configuration.</p> <p>The configuration should be a dictionary with the following keys: - \"database_uri\": The URI for the database. - \"echo\": If True, the engine will log all statements as well as a <code>repr()</code> of their parameter lists to the engines logger, which defaults to sys.stdout. - \"future\": If True, use the future version of SQLAlchemy, which supports asyncio. - \"pool_pre_ping\": If True, the pool will test the connection for liveness upon each checkout. - \"pool_size\": The size of the connection pool to be maintained. - \"max_overflow\": The number of connections that can be opened above the <code>pool_size</code> setting, when all other connections are in use. - \"pool_recycle\": The number of seconds after which a connection is automatically recycled. This is required for MySQL, which removes connections after 8 hours idle by default. - \"pool_timeout\": The number of seconds to wait before giving up on getting a connection from the pool.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict</code> <p>A dictionary containing the database configuration</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If there are unsupported parameters for the database</p> <p>Example: ```python from dsg_lib import database_config</p>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig.__init__--define-your-database-configuration-config","title":"Define your database configuration config = {","text":"<pre><code>\"database_uri\":\n\"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\": True,\n\"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n\"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n</code></pre> <p>}</p>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig.__init__--create-a-dbconfig-instance-db_config","title":"Create a DBConfig instance db_config =","text":"<p>database_config.DBConfig(config) ```</p> Source code in <code>dsg_lib/database_config.py</code> <pre><code>def __init__(self, config: Dict):\n    \"\"\"\n    Initializes the DBConfig instance with the given database configuration.\n\n    The configuration should be a dictionary with the following keys: -\n    \"database_uri\": The URI for the database. - \"echo\": If True, the engine\n    will log all statements as well as a `repr()` of their parameter lists\n    to the engines logger, which defaults to sys.stdout. - \"future\": If\n    True, use the future version of SQLAlchemy, which supports asyncio. -\n    \"pool_pre_ping\": If True, the pool will test the connection for liveness\n    upon each checkout. - \"pool_size\": The size of the connection pool to be\n    maintained. - \"max_overflow\": The number of connections that can be\n    opened above the `pool_size` setting, when all other connections are in\n    use. - \"pool_recycle\": The number of seconds after which a connection is\n    automatically recycled. This is required for MySQL, which removes\n    connections after 8 hours idle by default. - \"pool_timeout\": The number\n    of seconds to wait before giving up on getting a connection from the\n    pool.\n\n    Args:\n        config (Dict): A dictionary containing the database configuration\n        parameters.\n\n    Raises:\n        Exception: If there are unsupported parameters for the database\n        engine type.\n\n    Example: ```python from dsg_lib import database_config\n\n    # Define your database configuration config = {\n        \"database_uri\":\n        \"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\": True,\n        \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n        \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n    }\n\n    # Create a DBConfig instance db_config =\n    database_config.DBConfig(config) ```\n    \"\"\"\n    self.config = config\n    engine_type = self.config[\"database_uri\"].split(\"+\")[0]\n    supported_parameters = self.SUPPORTED_PARAMETERS.get(engine_type, set())\n    unsupported_parameters = (\n        set(config.keys()) - supported_parameters - {\"database_uri\"}\n    )\n    if unsupported_parameters:\n        error_message = (\n            f\"Unsupported parameters for {engine_type}: {unsupported_parameters}\"\n        )\n        logger.error(error_message)\n        raise Exception(error_message)\n\n    engine_parameters = {\n        param: self.config.get(param)\n        for param in supported_parameters\n        if self.config.get(param) is not None\n    }\n    self.engine = create_async_engine(\n        self.config[\"database_uri\"], **engine_parameters\n    )\n    self.metadata = MetaData()\n</code></pre>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig.get_db_session","title":"<code>get_db_session()</code>  <code>async</code>","text":"<p>This method returns a context manager that provides a new database session.</p> <p>The session is created using the SQLAlchemy engine from the DBConfig instance, and it does not expire on commit. The session is of type AsyncSession.</p> <p>This method should be used with the <code>async with</code> statement.</p> <p>Yields:</p> Name Type Description <code>AsyncSession</code> <p>A new SQLAlchemy asynchronous session.</p> <p>Raises:</p> Type Description <code>SQLAlchemyError</code> <p>If a database error occurs.</p> <p>Example: ```python from dsg_lib import database_config</p>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig.get_db_session--define-your-database-configuration-config","title":"Define your database configuration config = {","text":"<pre><code>\"database_uri\":\n\"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\": True,\n\"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n\"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n</code></pre> <p>}</p>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig.get_db_session--create-a-dbconfig-instance-db_config","title":"Create a DBConfig instance db_config =","text":"<p>database_config.DBConfig(config)</p>"},{"location":"database/database_configuration/#dsg_lib.database_config.DBConfig.get_db_session--use-the-dbconfig-instance-to-get-a-database-session-async-with","title":"Use the DBConfig instance to get a database session async with","text":"<p>db_config.get_db_session() as session:     # Perform your database operations here pass ```</p> Source code in <code>dsg_lib/database_config.py</code> <pre><code>@asynccontextmanager\nasync def get_db_session(self):\n    \"\"\"\n    This method returns a context manager that provides a new database\n    session.\n\n    The session is created using the SQLAlchemy engine from the DBConfig\n    instance, and it does not expire on commit. The session is of type\n    AsyncSession.\n\n    This method should be used with the `async with` statement.\n\n    Yields:\n        AsyncSession: A new SQLAlchemy asynchronous session.\n\n    Raises:\n        SQLAlchemyError: If a database error occurs.\n\n    Example: ```python from dsg_lib import database_config\n\n    # Define your database configuration config = {\n        \"database_uri\":\n        \"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\": True,\n        \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n        \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n    }\n\n    # Create a DBConfig instance db_config =\n    database_config.DBConfig(config)\n\n    # Use the DBConfig instance to get a database session async with\n    db_config.get_db_session() as session:\n        # Perform your database operations here pass\n    ```\n    \"\"\"\n    logger.debug(\"Creating new database session\")\n    try:\n        # Create a new database session\n        async with sessionmaker(\n            self.engine, expire_on_commit=False, class_=AsyncSession\n        )() as session:\n            # Yield the session to the context manager\n            yield session\n    except SQLAlchemyError as e:  # pragma: no cover\n        # Log the error and raise it\n        logger.error(f\"Database error occurred: {str(e)}\")  # pragma: no cover\n        raise  # pragma: no cover\n    finally:  # pragma: no cover\n        # Log the end of the database session\n        logger.debug(\"Database session ended\")  # pragma: no cover\n</code></pre>"},{"location":"database/database_configuration/#dsg_lib.database_config.import_sqlalchemy","title":"<code>import_sqlalchemy()</code>","text":"<p>This function tries to import SQLAlchemy and its components, and raises an ImportError if SQLAlchemy is not installed or if the installed version is not compatible with the minimum required version.</p> <p>Returns:</p> Name Type Description <code>Tuple</code> <code>Tuple</code> <p>A tuple containing the imported SQLAlchemy module and its</p> <code>Tuple</code> <p>components (MetaData, create_engine, text, IntegrityError,</p> <code>Tuple</code> <p>SQLAlchemyError, AsyncSession, create_async_engine, select,</p> <code>Tuple</code> <p>declarative_base, sessionmaker).</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If SQLAlchemy is not installed or if the installed version</p> <p>Example: <code>python from dsg_lib import database_config sqlalchemy, MetaData, create_engine, text, IntegrityError, SQLAlchemyError, AsyncSession, create_async_engine, select, declarative_base, sessionmaker = database_config.import_sqlalchemy()</code></p> Source code in <code>dsg_lib/database_config.py</code> <pre><code>def import_sqlalchemy() -&gt; Tuple:\n    \"\"\"\n    This function tries to import SQLAlchemy and its components, and raises an\n    ImportError if SQLAlchemy is not installed or if the installed version is\n    not compatible with the minimum required version.\n\n    Returns:\n        Tuple: A tuple containing the imported SQLAlchemy module and its\n        components (MetaData, create_engine, text, IntegrityError,\n        SQLAlchemyError, AsyncSession, create_async_engine, select,\n        declarative_base, sessionmaker).\n\n    Raises:\n        ImportError: If SQLAlchemy is not installed or if the installed version\n        is not compatible with the minimum required version.\n\n    Example: ```python from dsg_lib import database_config sqlalchemy, MetaData,\n    create_engine, text, IntegrityError, SQLAlchemyError, AsyncSession,\n    create_async_engine, select, declarative_base, sessionmaker =\n    database_config.import_sqlalchemy() ```\n    \"\"\"\n    # Try to import SQLAlchemy, handle ImportError if SQLAlchemy is not\n    # installed\n    try:\n        import sqlalchemy\n        from sqlalchemy import MetaData, create_engine, text\n        from sqlalchemy.exc import IntegrityError, SQLAlchemyError\n        from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine\n        from sqlalchemy.future import select\n        from sqlalchemy.orm import declarative_base, sessionmaker\n\n    except ImportError:  # pragma: no cover\n        create_engine = text = sqlalchemy = None  # pragma: no cover\n\n    # Check SQLAlchemy version\n    min_version = \"2.0.0\"  # replace with your minimum required version\n    if sqlalchemy is not None and packaging_version.parse(\n        sqlalchemy.__version__\n    ) &lt; packaging_version.parse(min_version):\n        raise ImportError(\n            f\"SQLAlchemy version &gt;= {min_version} required, run `pip install --upgrade sqlalchemy`\"\n        )  # pragma: no cover\n\n    return (\n        sqlalchemy,\n        MetaData,\n        create_engine,\n        text,\n        IntegrityError,\n        SQLAlchemyError,\n        AsyncSession,\n        create_async_engine,\n        select,\n        declarative_base,\n        sessionmaker,\n    )\n</code></pre>"},{"location":"database/database_operations/","title":"Reference","text":""},{"location":"database/database_operations/#dsg_lib.database_operations","title":"<code>dsg_lib.database_operations</code>","text":"<p>This module provides functions for performing basic CRUD operations on a database using SQLAlchemy and asyncio.</p> <p>It uses an instance of the <code>AsyncDatabase</code> class to perform these operations asynchronously.</p> <p>The module imports necessary modules and packages from <code>sqlalchemy</code> for database operations and error handling. It also imports <code>AsyncDatabase</code> from the local module <code>async_database</code>.</p> <p>The <code>DatabaseOperations</code> class has the following methods: - <code>__init__</code>: Initializes a new instance of the <code>DatabaseOperations</code> class. - <code>get_columns_details</code>: Retrieves the details of the columns of a given table. - <code>get_primary_keys</code>: Retrieves the primary keys of a given table. - <code>get_table_names</code>: Retrieves the names of all tables in the database. - <code>get_one_record</code>: Retrieves a single record from the database based on a given query. - <code>create_one</code>: Adds a single record to the database. - <code>create_many</code>: Adds multiple records to the database. - <code>count_query</code>: Executes a count query and returns the result. - <code>read_query</code>: Executes a fetch query and returns the result. - <code>read_multi_query</code>: Executes multiple fetch queries and returns the results. - <code>update_one</code>: Updates a single record in the database. - <code>delete_one</code>: Deletes a single record from the database.</p> <p>These functions are designed to be used with the <code>DBConfig</code> class from the <code>database_config</code> module, which manages the database configuration and creates a SQLAlchemy engine and a MetaData instance.</p> <p>This module is part of the <code>dsg_lib</code> package, which provides utilities for working with databases in Python.</p> <p>Example: ```python from dsg_lib import database_config, database_operations</p>"},{"location":"database/database_operations/#dsg_lib.database_operations--define-your-database-configuration-config","title":"Define your database configuration config = {","text":"<pre><code>\"database_uri\": \"postgresql+asyncpg://user:password@localhost/dbname\",\n\"echo\": True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n\"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n</code></pre> <p>}</p>"},{"location":"database/database_operations/#dsg_lib.database_operations--create-a-dbconfig-instance-db_config-database_configdbconfigconfig","title":"Create a DBConfig instance db_config = database_config.DBConfig(config)","text":""},{"location":"database/database_operations/#dsg_lib.database_operations--use-the-dbconfig-instance-to-get-a-database-session-async-with","title":"Use the DBConfig instance to get a database session async with","text":"<p>db_config.get_db_session() as session:     # Perform database operations database_operations.create_one(session,     MyModel, {\"field1\": \"value1\", \"field2\": \"value2\"}) record =     database_operations.read_one(session, MyModel, 1)     database_operations.update_one(session, MyModel, 1, {\"field1\":     \"new_value1\"}) database_operations.delete_one(session, MyModel, 1) ```</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations","title":"<code>DatabaseOperations</code>","text":"<p>A class used to manage database operations.</p> <p>This class provides methods for performing basic CRUD operations on a database using SQLAlchemy and asyncio.</p> <p>The main methods are: - <code>create_one</code>: Inserts a new record into the database. - <code>read_one</code>: Fetches a single record from the database. - <code>update_one</code>: Updates a single record in the database. - <code>delete_one</code>: Deletes a single record from the database.</p> <p>These methods are designed to be used with the <code>DBConfig</code> class from the <code>database_config</code> module, which manages the database configuration and creates a SQLAlchemy engine and a MetaData instance.</p> <p>Example: ```python from dsg_lib import database_config, database_operations</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations--define-your-database-configuration-config","title":"Define your database configuration config = {","text":"<pre><code>\"database_uri\": \"postgresql+asyncpg://user:password@localhost/dbname\",\n\"echo\": True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n\"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n</code></pre> <p>}</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations--create-a-dbconfig-instance-db_config-database_configdbconfigconfig","title":"Create a DBConfig instance db_config = database_config.DBConfig(config)","text":""},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations--create-a-databaseoperations-instance-db_ops","title":"Create a DatabaseOperations instance db_ops =","text":"<p>database_operations.DatabaseOperations()</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations--use-the-databaseoperations-instance-to-perform-database-operations-async","title":"Use the DatabaseOperations instance to perform database operations async","text":"<p>with db_config.get_db_session() as session:     db_ops.create_one(session, MyModel, {\"field1\": \"value1\", \"field2\":     \"value2\"}) record = db_ops.read_one(session, MyModel, 1)     db_ops.update_one(session, MyModel, 1, {\"field1\": \"new_value1\"})     db_ops.delete_one(session, MyModel, 1) ```</p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>class DatabaseOperations:\n    \"\"\"\n    A class used to manage database operations.\n\n    This class provides methods for performing basic CRUD operations on a\n    database using SQLAlchemy and asyncio.\n\n    The main methods are: - `create_one`: Inserts a new record into the\n    database. - `read_one`: Fetches a single record from the database. -\n    `update_one`: Updates a single record in the database. - `delete_one`:\n    Deletes a single record from the database.\n\n    These methods are designed to be used with the `DBConfig` class from the\n    `database_config` module, which manages the database configuration and\n    creates a SQLAlchemy engine and a MetaData instance.\n\n    Example: ```python from dsg_lib import database_config, database_operations\n\n    # Define your database configuration config = {\n        \"database_uri\": \"postgresql+asyncpg://user:password@localhost/dbname\",\n        \"echo\": True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n        \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n    }\n\n    # Create a DBConfig instance db_config = database_config.DBConfig(config)\n\n    # Create a DatabaseOperations instance db_ops =\n    database_operations.DatabaseOperations()\n\n    # Use the DatabaseOperations instance to perform database operations async\n    with db_config.get_db_session() as session:\n        db_ops.create_one(session, MyModel, {\"field1\": \"value1\", \"field2\":\n        \"value2\"}) record = db_ops.read_one(session, MyModel, 1)\n        db_ops.update_one(session, MyModel, 1, {\"field1\": \"new_value1\"})\n        db_ops.delete_one(session, MyModel, 1)\n    ```\n    \"\"\"\n\n    def __init__(self, async_db: AsyncDatabase):\n        \"\"\"\n        Initializes a new instance of the DatabaseOperations class.\n\n        Args:\n            async_db (module_name.AsyncDatabase): An instance of the\n            AsyncDatabase class for performing asynchronous database operations.\n\n        Example:\n            &gt;&gt;&gt; from dsg_lib import module_name\n            &gt;&gt;&gt; async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments\n            &gt;&gt;&gt; db_ops = module_name.DatabaseOperations(async_db)\n        \"\"\"\n        # Log the start of the initialization\n        logger.debug(\"Initializing DatabaseOperations instance\")\n\n        # Store the AsyncDatabase instance in the async_db attribute This\n        # instance will be used for performing asynchronous database operations\n        self.async_db = async_db\n\n        # Log the successful initialization\n        logger.info(\"DatabaseOperations instance initialized successfully\")\n\n    async def get_columns_details(self, table):\n        \"\"\"\n        Retrieves the details of the columns of a given table.\n\n        This asynchronous method accepts a table object and returns a\n        dictionary. Each key in the dictionary is a column name from the table,\n        and the corresponding value is another dictionary containing details\n        about that column, such as type, if it's nullable, if it's a primary\n        key, if it's unique, its autoincrement status, and its default value.\n\n        Args:\n            table (Table): An instance of the SQLAlchemy Table class\n            representing the database table for which column details are\n            required.\n\n        Returns:\n            dict: A dictionary where each key is a column name, and each value\n            is a dictionary with the column's details.\n\n        Raises:\n            Exception: If any error occurs during the database operation.\n\n        Example: ```python from sqlalchemy import Table, MetaData, Column,\n        Integer, String from dsg_lib import module_name metadata = MetaData()\n        my_table = Table('my_table', metadata,\n                        Column('id', Integer, primary_key=True), Column('name',\n                        String))\n        async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes\n        no arguments db_ops = module_name.DatabaseOperations(async_db)\n        asyncio.run(db_ops.get_columns_details(my_table))\n            {\n                'id': {\n                    'type': 'INTEGER', 'nullable': False, 'primary_key': True,\n                    'unique': False, 'autoincrement': 'auto', 'default': None\n                }, 'name': {\n                    'type': 'VARCHAR', 'nullable': True, 'primary_key': False,\n                    'unique': False, 'autoincrement': False, 'default': None\n                }\n            }\n        ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(\n            f\"Starting get_columns_details operation for table: {table.__name__}\"\n        )\n\n        try:\n            # Log the start of the column retrieval\n            logger.debug(f\"Getting columns for table: {table.__name__}\")\n\n            # Retrieve the details of the columns and store them in a dictionary\n            # The keys are the column names and the values are dictionaries\n            # containing the column details\n            columns = {\n                c.name: {\n                    \"type\": str(c.type),\n                    \"nullable\": c.nullable,\n                    \"primary_key\": c.primary_key,\n                    \"unique\": c.unique,\n                    \"autoincrement\": c.autoincrement,\n                    \"default\": str(c.default.arg)\n                    if c.default is not None and not callable(c.default.arg)\n                    else None,\n                }\n                for c in table.__table__.columns\n            }\n\n            # Log the successful column retrieval\n            logger.info(f\"Successfully retrieved columns for table: {table.__name__}\")\n\n            return columns\n        except Exception as ex:  # pragma: no cover\n            # Handle any exceptions that occur during the column retrieval\n            logger.error(\n                f\"An error occurred while getting columns for table: {table.__name__}\"\n            )  # pragma: no cover\n            return handle_exceptions(ex)  # pragma: no cover\n\n    async def get_primary_keys(self, table):\n        \"\"\"\n        Retrieves the primary keys of a given table.\n\n        This asynchronous method accepts a table object and returns a list\n        containing the names of its primary keys. It is useful for understanding\n        the structure of the table and for operations that require knowledge of\n        the primary keys.\n\n        Args:\n            table (Table): An instance of the SQLAlchemy Table class\n            representing the database table for which primary keys are required.\n\n        Returns:\n            list: A list containing the names of the primary keys of the table.\n\n        Raises:\n            Exception: If any error occurs during the database operation.\n\n        Example:\n            ```python from sqlalchemy import Table, MetaData, Column, Integer,\n            String from dsg_lib import module_name metadata = MetaData()\n            my_table = Table('my_table', metadata,\n                             Column('id', Integer, primary_key=True),\n                             Column('name', String, primary_key=True))\n            async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n            takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n            asyncio.run(db_ops.get_primary_keys(my_table)) # Output: ['id',\n            'name'] ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(f\"Starting get_primary_keys operation for table: {table.__name__}\")\n\n        try:\n            # Log the start of the primary key retrieval\n            logger.debug(f\"Getting primary keys for table: {table.__name__}\")\n\n            # Retrieve the primary keys and store them in a list\n            primary_keys = table.__table__.primary_key.columns.keys()\n\n            # Log the successful primary key retrieval\n            logger.info(f\"Primary keys retrieved successfully: {primary_keys}\")\n\n            return primary_keys\n\n        except Exception as ex:  # pragma: no cover\n            # Handle any exceptions that occur during the primary key retrieval\n            logger.error(f\"Exception occurred: {ex}\")  # pragma: no cover\n            return handle_exceptions(ex)  # pragma: no cover\n\n    async def get_table_names(self):\n        \"\"\"\n        Retrieves the names of all tables in the database.\n\n        This asynchronous method returns a list containing the names of all\n        tables in the database. It is useful for database introspection,\n        allowing the user to know which tables are available in the current\n        database context.\n\n        Returns:\n            list: A list containing the names of all tables in the database.\n\n        Raises:\n            Exception: If any error occurs during the database operation.\n\n        Example:\n            ```python from dsg_lib import module_name async_db =\n            module_name.AsyncDatabase()  # assuming AsyncDatabase takes no\n            arguments db_ops = module_name.DatabaseOperations(async_db)\n            asyncio.run(db_ops.get_table_names()) # Output: ['table1', 'table2',\n            ...] ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(\"Starting get_table_names operation\")\n\n        try:\n            # Log the start of the table name retrieval\n            logger.debug(\"Retrieving table names\")\n\n            # Retrieve the table names and store them in a list The keys of the\n            # metadata.tables dictionary are the table names\n            table_names = list(self.async_db.Base.metadata.tables.keys())\n\n            # Log the successful table name retrieval\n            logger.info(f\"Table names retrieved successfully: {table_names}\")\n\n            return table_names\n\n        except Exception as ex:  # pragma: no cover\n            # Handle any exceptions that occur during the table name retrieval\n            logger.error(f\"Exception occurred: {ex}\")  # pragma: no cover\n            return handle_exceptions(ex)  # pragma: no cover\n\n    async def get_one_record(self, query):\n        \"\"\"\n        Retrieves a single record from the database based on the provided query.\n\n        This asynchronous method accepts a SQL query object and returns the\n        first record that matches the query. If no record matches the query, it\n        raises an exception. This method is useful for fetching specific data\n        when the expected result is a single record.\n\n        Parameters:\n            query (Select): An instance of the SQLAlchemy Select class,\n            representing the query to be executed.\n\n        Returns:\n            Result: The first record that matches the query.\n\n        Raises:\n            NoResultFound: If no record matches the query. Exception: If any\n            other error occurs during the database operation.\n\n        Example:\n            ```python from sqlalchemy import select, Table, Column, Integer,\n            String, MetaData from dsg_lib import module_name metadata =\n            MetaData() my_table = Table('my_table', metadata,\n                             Column('id', Integer, primary_key=True),\n                             Column('name', String))\n            query = select(my_table).where(my_table.c.id == 1) async_db =\n            module_name.AsyncDatabase()  # assuming AsyncDatabase takes no\n            arguments db_ops = module_name.DatabaseOperations(async_db)\n            asyncio.run(db_ops.get_one_record(query)) # Output: {'id': 1,\n            'name': 'John Doe'} ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(f\"Starting get_one_record operation for {query}\")\n\n        try:\n            # Start a new database session\n            async with self.async_db.get_db_session() as session:\n                # Log the start of the record retrieval\n                logger.debug(f\"Getting record with query: {query}\")\n\n                # Execute the query and retrieve the first record\n                result = await session.execute(query)\n                record = result.scalar_one()\n\n                # Log the successful record retrieval\n                logger.info(f\"Record retrieved successfully: {record}\")\n\n                return record\n\n        except Exception as ex:  # pragma: no cover\n            # Handle any exceptions that occur during the record retrieval\n            logger.error(f\"Exception occurred: {ex}\")  # pragma: no cover\n            return handle_exceptions(ex)  # pragma: no cover\n\n    async def create_one(self, record):\n        \"\"\"\n        Adds a single record to the database.\n\n        This asynchronous method accepts a record object and adds it to the\n        database. If the operation is successful, it returns the added record.\n        The method is useful for inserting a new row into a database table.\n\n        Parameters:\n            record (Base): An instance of the SQLAlchemy declarative base class\n            representing the record to be added to the database.\n\n        Returns:\n            Base: The instance of the record that was added to the database.\n\n        Raises:\n            Exception: If any error occurs during the database operation.\n\n        Example:\n            ```python from sqlalchemy.ext.declarative import declarative_base\n            from sqlalchemy import Column, Integer, String from dsg_lib import\n            module_name Base = declarative_base()\n\n            class MyModel(Base):\n                __tablename__ = 'my_table' id = Column(Integer,\n                primary_key=True) name = Column(String)\n\n            # Create an instance of MyModel new_record = MyModel(id=1,\n            name='John Doe')\n\n            async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n            takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n            asyncio.run(db_ops.create_one(new_record)) # Output: &lt;MyModel object\n            at 0x...&gt; ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(\"Starting create_one operation\")\n\n        try:\n            # Start a new database session\n            async with self.async_db.get_db_session() as session:\n                # Log the record being added\n                logger.debug(f\"Adding record to session: {record.__dict__}\")\n\n                # Add the record to the session and commit the changes\n                session.add(record)\n                await session.commit()\n\n                # Log the successful record addition\n                logger.info(f\"Record added successfully: {record}\")\n\n                return record\n\n        except Exception as ex:\n            # Handle any exceptions that occur during the record addition\n            logger.error(f\"Exception occurred: {ex}\")\n            return handle_exceptions(ex)\n\n    async def create_many(self, records):\n        \"\"\"\n        Adds multiple records to the database.\n\n        This asynchronous method accepts a list of record objects and adds them\n        to the database. If the operation is successful, it returns the added\n        records. This method is useful for bulk inserting multiple rows into a\n        database table efficiently.\n\n        Parameters:\n            records (list[Base]): A list of instances of the SQLAlchemy\n            declarative base class, each representing a record to be added to\n            the database.\n\n        Returns:\n            list[Base]: A list of instances of the records that were added to\n            the database.\n\n        Raises:\n            Exception: If any error occurs during the database operation.\n\n        Example:\n            ```python from sqlalchemy.ext.declarative import declarative_base\n            from sqlalchemy import Column, Integer, String from dsg_lib import\n            module_name Base = declarative_base()\n\n            class MyModel(Base):\n                __tablename__ = 'my_table' id = Column(Integer,\n                primary_key=True) name = Column(String)\n\n            # Create a list of MyModel instances new_records = [MyModel(id=1,\n            name='John Doe'), MyModel(id=2, name='Jane Doe')]\n\n            async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n            takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n            asyncio.run(db_ops.create_many(new_records)) # Output: [&lt;MyModel\n            object at 0x...&gt;, &lt;MyModel object at 0x...&gt;] ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(\"Starting create_many operation\")\n\n        try:\n            # Start a timer to measure the operation time\n            t0 = time.time()\n\n            # Start a new database session\n            async with self.async_db.get_db_session() as session:\n                # Log the number of records being added\n                logger.debug(f\"Adding {len(records)} records to session\")\n\n                # Add the records to the session and commit the changes\n                session.add_all(records)\n                await session.commit()\n\n                # Log the added records\n                records_data = [record.__dict__ for record in records]\n                logger.debug(f\"Records added to session: {records_data}\")\n\n                # Calculate the operation time and log the successful record\n                # addition\n                num_records = len(records)\n                t1 = time.time() - t0\n                logger.info(\n                    f\"Record operations were successful. {num_records} records were created in {t1:.4f} seconds.\"\n                )\n\n                return records\n\n        except Exception as ex:\n            # Handle any exceptions that occur during the record addition\n            logger.error(f\"Exception occurred: {ex}\")\n            return handle_exceptions(ex)\n\n    async def count_query(self, query):\n        \"\"\"\n        Executes a count query on the database and returns the number of records\n        that match the query.\n\n        This asynchronous method accepts a SQLAlchemy `Select` query object and\n        returns the count of records that match the query. This is particularly\n        useful for getting the total number of records that satisfy certain\n        conditions without actually fetching the records themselves.\n\n        Parameters:\n            query (Select): A SQLAlchemy `Select` query object specifying the\n            conditions to count records for.\n\n        Returns:\n            int: The number of records that match the query.\n\n        Raises:\n            Exception: If any error occurs during the execution of the query.\n\n        Example:\n            ```python from sqlalchemy import select, func from\n            sqlalchemy.ext.declarative import declarative_base from sqlalchemy\n            import Column, Integer, String from dsg_lib import module_name\n\n            Base = declarative_base()\n\n            class MyModel(Base):\n                __tablename__ = 'my_table' id = Column(Integer,\n                primary_key=True) name = Column(String)\n\n            async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n            takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n\n            # Creating a query to count records with a specific condition query\n            = select([func.count()]).select_from(MyModel).where(MyModel.name ==\n            'John Doe')\n\n            # Using the count_query method result =\n            asyncio.run(db_ops.count_query(query)) # Output: The count of\n            records where name is 'John Doe' ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(\"Starting count_query operation\")\n\n        try:\n            # Start a new database session\n            async with self.async_db.get_db_session() as session:\n                # Log the query being executed\n                logger.debug(f\"Executing count query: {query}\")\n\n                # Execute the count query and retrieve the count\n                result = await session.execute(select(func.count()).select_from(query))\n                count = result.scalar()\n\n                # Log the successful query execution\n                logger.info(f\"Count query executed successfully. Result: {count}\")\n\n                return count\n\n        except Exception as ex:\n            # Handle any exceptions that occur during the query execution\n            logger.error(f\"Exception occurred: {ex}\")\n            return handle_exceptions(ex)\n\n    async def read_query(self, query, limit=500, offset=0):\n        \"\"\"\n        Executes a fetch query on the database and returns a list of records\n        that match the query.\n\n        This asynchronous method accepts a SQLAlchemy `Select` query object\n        along with optional limit and offset parameters. It returns a list of\n        records that match the query, with the number of records controlled by\n        the limit, and the starting point of the records determined by the\n        offset.\n\n        Parameters:\n            query (Select): A SQLAlchemy `Select` query object specifying the\n            conditions to fetch records for. limit (int, optional): The maximum\n            number of records to return. Defaults to 500. offset (int,\n            optional): The number of records to skip before starting to return\n            records. Defaults to 0.\n\n        Returns:\n            list: A list of records that match the query.\n\n        Raises:\n            Exception: If any error occurs during the execution of the query.\n\n        Example:\n            ```python from sqlalchemy import select from\n            sqlalchemy.ext.declarative import declarative_base from sqlalchemy\n            import Column, Integer, String from dsg_lib import module_name\n\n            Base = declarative_base()\n\n            class MyModel(Base):\n                __tablename__ = 'my_table' id = Column(Integer,\n                primary_key=True) name = Column(String)\n\n            async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n            takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n\n            # Creating a query to fetch records query =\n            select(MyModel).where(MyModel.name == 'John Doe')\n\n            # Using the read_query method result =\n            asyncio.run(db_ops.read_query(query, limit=10, offset=0)) # Output:\n            A list of up to 10 records where name is 'John Doe', starting from\n            the first record ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(\"Starting read_query operation\")\n\n        try:\n            # Start a new database session\n            async with self.async_db.get_db_session() as session:\n                # Log the query being executed\n                logger.debug(\n                    f\"Executing fetch query: {query} with limit: {limit} and offset: {offset}\"\n                )\n\n                # Execute the fetch query and retrieve the records\n                result = await session.execute(query.limit(limit).offset(offset))\n                records = result.scalars().all()\n\n                # Log the successful query execution\n                records_data = [record.__dict__ for record in records]\n                logger.info(\n                    f\"Fetch query executed successfully. Records: {records_data}\"\n                )\n\n                return records\n\n        except Exception as ex:\n            # Handle any exceptions that occur during the query execution\n            logger.error(f\"Exception occurred: {ex}\")\n            return handle_exceptions(ex)\n\n    async def read_multi_query(self, queries: Dict[str, str], limit=500, offset=0):\n        \"\"\"\n        Executes multiple fetch queries on the database and returns a dictionary\n        of results for each query.\n\n        This asynchronous method takes a dictionary where each key is a query\n        name and each value is a SQLAlchemy `Select` query object. It also\n        accepts optional limit and offset parameters. The method executes each\n        query and returns a dictionary where each key is the query name, and the\n        corresponding value is a list of records that match that query.\n\n        Parameters:\n            queries (Dict[str, Select]): A dictionary of SQLAlchemy `Select`\n            query objects. limit (int, optional): The maximum number of records\n            to return for each query. Defaults to 500. offset (int, optional):\n            The number of records to skip before returning records for each\n            query. Defaults to 0.\n\n        Returns:\n            dict: A dictionary where each key is a query name and each value is\n            a list of records that match the query.\n\n        Raises:\n            Exception: If any error occurs during the execution of the queries.\n\n        Example:\n            ```python from sqlalchemy import select from\n            sqlalchemy.ext.declarative import declarative_base from sqlalchemy\n            import Column, Integer, String from dsg_lib import module_name\n\n            Base = declarative_base()\n\n            class User(Base):\n                __tablename__ = 'users' id = Column(Integer, primary_key=True)\n                name = Column(String) age = Column(Integer)\n\n            async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n            takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n\n            # Creating queries query1 = select(User).where(User.age &gt; 30) query2\n            = select(User).where(User.name.startswith('J'))\n\n            queries = {\"older_users\": query1, \"j_users\": query2}\n\n            # Using the read_multi_query method results =\n            asyncio.run(db_ops.read_multi_query(queries, limit=10)) # Output:\n            Dictionary with keys 'older_users' and 'j_users' each containing a\n            list of up to 10 records ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(\"Starting read_multi_query operation\")\n\n        try:\n            results = {}\n            # Start a new database session\n            async with self.async_db.get_db_session() as session:\n                for query_name, query in queries.items():\n                    # Log the query being executed\n                    logger.debug(f\"Executing fetch query: {query}\")\n\n                    # Execute the fetch query and retrieve the records\n                    result = await session.execute(query.limit(limit).offset(offset))\n                    data = result.scalars().all()\n\n                    # Convert the records to dictionaries for logging\n                    data_dicts = [record.__dict__ for record in data]\n                    logger.debug(f\"Fetch result for query '{query_name}': {data_dicts}\")\n\n                    # Log the successful query execution\n                    logger.info(\n                        f\"Fetch query executed successfully: {query_name} with {len(data)} records\"\n                    )\n\n                    # Store the records in the results dictionary\n                    results[query_name] = data\n            return results\n\n        except Exception as ex:\n            # Handle any exceptions that occur during the query execution\n            logger.error(f\"Exception occurred: {ex}\")\n            return handle_exceptions(ex)\n\n    async def update_one(self, table, record_id: str, new_values: dict):\n        \"\"\"\n        Updates a single record in the database identified by its ID.\n\n        This asynchronous method takes a SQLAlchemy `Table` object, a record ID,\n        and a dictionary of new values to update the record. It updates the\n        specified record in the given table with the new values. The method does\n        not allow updating certain fields, such as 'id' or 'date_created'.\n\n        Parameters:\n            table (Table): The SQLAlchemy `Table` object representing the table\n            in the database. record_id (str): The ID of the record to be\n            updated. new_values (dict): A dictionary containing the fields to\n            update and their new values.\n\n        Returns:\n            Base: The updated record if successful; otherwise, an error\n            dictionary.\n\n        Raises:\n            Exception: If any error occurs during the update operation.\n\n        Example:\n            ```python from sqlalchemy.ext.declarative import declarative_base\n            from sqlalchemy import Column, Integer, String from dsg_lib import\n            database_config, database_operations\n\n            Base = declarative_base()\n\n            class User(Base):\n                __tablename__ = 'users' id = Column(Integer, primary_key=True)\n                name = Column(String) age = Column(Integer)\n\n            # Define your database configuration config = {\n                \"database_uri\":\n                \"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\":\n                True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n                \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n            }\n\n            db_config = database_config.DBConfig(config) db_ops =\n            database_operations.DatabaseOperations()\n\n            # Updating a record in the 'users' table async with\n            db_config.get_db_session() as session:\n                updated_record = await db_ops.update_one(User.__table__, '1',\n                {\"name\": \"Updated Name\", \"age\": 30}) # Output: Updated User\n                record with the new name and age\n            ```\n        \"\"\"\n        non_updatable_fields = [\"id\", \"date_created\"]\n\n        # Log the start of the operation\n        logger.debug(\n            f\"Starting update_one operation for record_id: {record_id} in table: {table.__name__}\"\n        )\n\n        try:\n            # Start a new database session\n            async with self.async_db.get_db_session() as session:\n                # Log the record being fetched\n                logger.debug(f\"Fetching record with id: {record_id}\")\n\n                # Fetch the record\n                record = await session.get(table, record_id)\n                if not record:\n                    # Log the error if no record is found\n                    logger.error(f\"No record found with pkid: {record_id}\")\n                    return {\n                        \"error\": \"Record not found\",\n                        \"details\": f\"No record found with pkid {record_id}\",\n                    }\n\n                # Log the record being updated\n                logger.debug(f\"Updating record with new values: {new_values}\")\n\n                # Update the record with the new values\n                for key, value in new_values.items():\n                    if key not in non_updatable_fields:\n                        setattr(record, key, value)\n                await session.commit()\n\n                # Log the successful record update\n                logger.info(f\"Record updated successfully: {record.pkid}\")\n                return record\n\n        except Exception as ex:\n            # Handle any exceptions that occur during the record update\n            logger.error(f\"Exception occurred: {ex}\")\n            return handle_exceptions(ex)\n\n    async def delete_one(self, table, record_id: str):\n        \"\"\"\n        Deletes a single record from the database based on the provided table\n        and record ID.\n\n        This asynchronous method accepts a SQLAlchemy `Table` object and a\n        record ID. It attempts to delete the record with the given ID from the\n        specified table. If the record is successfully deleted, it returns a\n        success message. If no record with the given ID is found, it returns an\n        error message.\n\n        Args:\n            table (Table): An instance of the SQLAlchemy `Table` class\n            representing the database table from which the record will be\n            deleted. record_id (str): The ID of the record to be deleted.\n\n        Returns:\n            dict: A dictionary containing a success message if the record was\n            deleted successfully, or an error message if the record was not\n            found or an exception occurred.\n\n        Raises:\n            Exception: If any error occurs during the delete operation.\n\n        Example:\n            ```python from sqlalchemy import Table, MetaData, Column, Integer,\n            String from dsg_lib import database_config, database_operations\n\n            # Define your database configuration config = {\n                \"database_uri\":\n                \"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\":\n                True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n                \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n            }\n\n            # Define a table metadata = MetaData() my_table = Table('my_table',\n            metadata,\n                             Column('id', Integer, primary_key=True),\n                             Column('name', String))\n\n            # Initialize DatabaseOperations and DBConfig db_config =\n            database_config.DBConfig(config) db_ops =\n            database_operations.DatabaseOperations()\n\n            # Delete a record from 'my_table' async with\n            db_config.get_db_session() as session:\n                result = await db_ops.delete_one(my_table, '1') # Output:\n                {'success': 'Record deleted successfully'} or {'error': 'Record\n                not found'}\n            ```\n        \"\"\"\n        # Log the start of the operation\n        logger.debug(\n            f\"Starting delete_one operation for record_id: {record_id} in table: {table.__name__}\"\n        )\n\n        try:\n            # Start a new database session\n            async with self.async_db.get_db_session() as session:\n                # Log the record being fetched\n                logger.debug(f\"Fetching record with id: {record_id}\")\n\n                # Fetch the record\n                record = await session.get(table, record_id)\n\n                # If the record doesn't exist, return an error\n                if not record:\n                    logger.error(f\"No record found with pkid: {record_id}\")\n                    return {\n                        \"error\": \"Record not found\",\n                        \"details\": f\"No record found with pkid {record_id}\",\n                    }\n\n                # Log the record being deleted\n                logger.debug(f\"Deleting record with id: {record_id}\")\n\n                # Delete the record\n                await session.delete(record)\n\n                # Log the successful record deletion from the session\n                logger.debug(f\"Record deleted from session: {record}\")\n\n                # Log the start of the commit\n                logger.debug(\n                    f\"Committing changes to delete record with id: {record_id}\"\n                )\n\n                # Commit the changes\n                await session.commit()\n\n                # Log the successful record deletion\n                logger.info(f\"Record deleted successfully: {record_id}\")\n\n                return {\"success\": \"Record deleted successfully\"}\n\n        except Exception as ex:\n            # Handle any exceptions that occur during the record deletion\n            logger.error(f\"Exception occurred: {ex}\")\n            return handle_exceptions(ex)\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.__init__","title":"<code>__init__(async_db)</code>","text":"<p>Initializes a new instance of the DatabaseOperations class.</p> <p>Parameters:</p> Name Type Description Default <code>async_db</code> <code>AsyncDatabase</code> <p>An instance of the</p> required Example <p>from dsg_lib import module_name async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db)</p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>def __init__(self, async_db: AsyncDatabase):\n    \"\"\"\n    Initializes a new instance of the DatabaseOperations class.\n\n    Args:\n        async_db (module_name.AsyncDatabase): An instance of the\n        AsyncDatabase class for performing asynchronous database operations.\n\n    Example:\n        &gt;&gt;&gt; from dsg_lib import module_name\n        &gt;&gt;&gt; async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments\n        &gt;&gt;&gt; db_ops = module_name.DatabaseOperations(async_db)\n    \"\"\"\n    # Log the start of the initialization\n    logger.debug(\"Initializing DatabaseOperations instance\")\n\n    # Store the AsyncDatabase instance in the async_db attribute This\n    # instance will be used for performing asynchronous database operations\n    self.async_db = async_db\n\n    # Log the successful initialization\n    logger.info(\"DatabaseOperations instance initialized successfully\")\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.count_query","title":"<code>count_query(query)</code>  <code>async</code>","text":"<p>Executes a count query on the database and returns the number of records that match the query.</p> <p>This asynchronous method accepts a SQLAlchemy <code>Select</code> query object and returns the count of records that match the query. This is particularly useful for getting the total number of records that satisfy certain conditions without actually fetching the records themselves.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Select</code> <p>A SQLAlchemy <code>Select</code> query object specifying the</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The number of records that match the query.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the execution of the query.</p> Example <p>```python from sqlalchemy import select, func from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Column, Integer, String from dsg_lib import module_name</p> <p>Base = declarative_base()</p> <p>class MyModel(Base):     tablename = 'my_table' id = Column(Integer,     primary_key=True) name = Column(String)</p> <p>async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db)</p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def count_query(self, query):\n    \"\"\"\n    Executes a count query on the database and returns the number of records\n    that match the query.\n\n    This asynchronous method accepts a SQLAlchemy `Select` query object and\n    returns the count of records that match the query. This is particularly\n    useful for getting the total number of records that satisfy certain\n    conditions without actually fetching the records themselves.\n\n    Parameters:\n        query (Select): A SQLAlchemy `Select` query object specifying the\n        conditions to count records for.\n\n    Returns:\n        int: The number of records that match the query.\n\n    Raises:\n        Exception: If any error occurs during the execution of the query.\n\n    Example:\n        ```python from sqlalchemy import select, func from\n        sqlalchemy.ext.declarative import declarative_base from sqlalchemy\n        import Column, Integer, String from dsg_lib import module_name\n\n        Base = declarative_base()\n\n        class MyModel(Base):\n            __tablename__ = 'my_table' id = Column(Integer,\n            primary_key=True) name = Column(String)\n\n        async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n        takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n\n        # Creating a query to count records with a specific condition query\n        = select([func.count()]).select_from(MyModel).where(MyModel.name ==\n        'John Doe')\n\n        # Using the count_query method result =\n        asyncio.run(db_ops.count_query(query)) # Output: The count of\n        records where name is 'John Doe' ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(\"Starting count_query operation\")\n\n    try:\n        # Start a new database session\n        async with self.async_db.get_db_session() as session:\n            # Log the query being executed\n            logger.debug(f\"Executing count query: {query}\")\n\n            # Execute the count query and retrieve the count\n            result = await session.execute(select(func.count()).select_from(query))\n            count = result.scalar()\n\n            # Log the successful query execution\n            logger.info(f\"Count query executed successfully. Result: {count}\")\n\n            return count\n\n    except Exception as ex:\n        # Handle any exceptions that occur during the query execution\n        logger.error(f\"Exception occurred: {ex}\")\n        return handle_exceptions(ex)\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.count_query--creating-a-query-to-count-records-with-a-specific-condition-query","title":"Creating a query to count records with a specific condition query","text":"<p>= select([func.count()]).select_from(MyModel).where(MyModel.name == 'John Doe')</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.count_query--using-the-count_query-method-result","title":"Using the count_query method result =","text":"<p>asyncio.run(db_ops.count_query(query)) # Output: The count of records where name is 'John Doe' ```</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.create_many","title":"<code>create_many(records)</code>  <code>async</code>","text":"<p>Adds multiple records to the database.</p> <p>This asynchronous method accepts a list of record objects and adds them to the database. If the operation is successful, it returns the added records. This method is useful for bulk inserting multiple rows into a database table efficiently.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list[Base]</code> <p>A list of instances of the SQLAlchemy</p> required <p>Returns:</p> Type Description <p>list[Base]: A list of instances of the records that were added to</p> <p>the database.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the database operation.</p> Example <p>```python from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Column, Integer, String from dsg_lib import module_name Base = declarative_base()</p> <p>class MyModel(Base):     tablename = 'my_table' id = Column(Integer,     primary_key=True) name = Column(String)</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.create_many--create-a-list-of-mymodel-instances-new_records-mymodelid1","title":"Create a list of MyModel instances new_records = [MyModel(id=1,","text":"<p>name='John Doe'), MyModel(id=2, name='Jane Doe')]</p> <p>async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db) asyncio.run(db_ops.create_many(new_records)) # Output: [, ] ``` Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def create_many(self, records):\n    \"\"\"\n    Adds multiple records to the database.\n\n    This asynchronous method accepts a list of record objects and adds them\n    to the database. If the operation is successful, it returns the added\n    records. This method is useful for bulk inserting multiple rows into a\n    database table efficiently.\n\n    Parameters:\n        records (list[Base]): A list of instances of the SQLAlchemy\n        declarative base class, each representing a record to be added to\n        the database.\n\n    Returns:\n        list[Base]: A list of instances of the records that were added to\n        the database.\n\n    Raises:\n        Exception: If any error occurs during the database operation.\n\n    Example:\n        ```python from sqlalchemy.ext.declarative import declarative_base\n        from sqlalchemy import Column, Integer, String from dsg_lib import\n        module_name Base = declarative_base()\n\n        class MyModel(Base):\n            __tablename__ = 'my_table' id = Column(Integer,\n            primary_key=True) name = Column(String)\n\n        # Create a list of MyModel instances new_records = [MyModel(id=1,\n        name='John Doe'), MyModel(id=2, name='Jane Doe')]\n\n        async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n        takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n        asyncio.run(db_ops.create_many(new_records)) # Output: [&lt;MyModel\n        object at 0x...&gt;, &lt;MyModel object at 0x...&gt;] ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(\"Starting create_many operation\")\n\n    try:\n        # Start a timer to measure the operation time\n        t0 = time.time()\n\n        # Start a new database session\n        async with self.async_db.get_db_session() as session:\n            # Log the number of records being added\n            logger.debug(f\"Adding {len(records)} records to session\")\n\n            # Add the records to the session and commit the changes\n            session.add_all(records)\n            await session.commit()\n\n            # Log the added records\n            records_data = [record.__dict__ for record in records]\n            logger.debug(f\"Records added to session: {records_data}\")\n\n            # Calculate the operation time and log the successful record\n            # addition\n            num_records = len(records)\n            t1 = time.time() - t0\n            logger.info(\n                f\"Record operations were successful. {num_records} records were created in {t1:.4f} seconds.\"\n            )\n\n            return records\n\n    except Exception as ex:\n        # Handle any exceptions that occur during the record addition\n        logger.error(f\"Exception occurred: {ex}\")\n        return handle_exceptions(ex)\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.create_one","title":"<code>create_one(record)</code>  <code>async</code>","text":"<p>Adds a single record to the database.</p> <p>This asynchronous method accepts a record object and adds it to the database. If the operation is successful, it returns the added record. The method is useful for inserting a new row into a database table.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Base</code> <p>An instance of the SQLAlchemy declarative base class</p> required <p>Returns:</p> Name Type Description <code>Base</code> <p>The instance of the record that was added to the database.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the database operation.</p> Example <p>```python from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Column, Integer, String from dsg_lib import module_name Base = declarative_base()</p> <p>class MyModel(Base):     tablename = 'my_table' id = Column(Integer,     primary_key=True) name = Column(String)</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.create_one--create-an-instance-of-mymodel-new_record-mymodelid1","title":"Create an instance of MyModel new_record = MyModel(id=1,","text":"<p>name='John Doe')</p> <p>async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db) asyncio.run(db_ops.create_one(new_record)) # Output:  ``` Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def create_one(self, record):\n    \"\"\"\n    Adds a single record to the database.\n\n    This asynchronous method accepts a record object and adds it to the\n    database. If the operation is successful, it returns the added record.\n    The method is useful for inserting a new row into a database table.\n\n    Parameters:\n        record (Base): An instance of the SQLAlchemy declarative base class\n        representing the record to be added to the database.\n\n    Returns:\n        Base: The instance of the record that was added to the database.\n\n    Raises:\n        Exception: If any error occurs during the database operation.\n\n    Example:\n        ```python from sqlalchemy.ext.declarative import declarative_base\n        from sqlalchemy import Column, Integer, String from dsg_lib import\n        module_name Base = declarative_base()\n\n        class MyModel(Base):\n            __tablename__ = 'my_table' id = Column(Integer,\n            primary_key=True) name = Column(String)\n\n        # Create an instance of MyModel new_record = MyModel(id=1,\n        name='John Doe')\n\n        async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n        takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n        asyncio.run(db_ops.create_one(new_record)) # Output: &lt;MyModel object\n        at 0x...&gt; ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(\"Starting create_one operation\")\n\n    try:\n        # Start a new database session\n        async with self.async_db.get_db_session() as session:\n            # Log the record being added\n            logger.debug(f\"Adding record to session: {record.__dict__}\")\n\n            # Add the record to the session and commit the changes\n            session.add(record)\n            await session.commit()\n\n            # Log the successful record addition\n            logger.info(f\"Record added successfully: {record}\")\n\n            return record\n\n    except Exception as ex:\n        # Handle any exceptions that occur during the record addition\n        logger.error(f\"Exception occurred: {ex}\")\n        return handle_exceptions(ex)\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.delete_one","title":"<code>delete_one(table, record_id)</code>  <code>async</code>","text":"<p>Deletes a single record from the database based on the provided table and record ID.</p> <p>This asynchronous method accepts a SQLAlchemy <code>Table</code> object and a record ID. It attempts to delete the record with the given ID from the specified table. If the record is successfully deleted, it returns a success message. If no record with the given ID is found, it returns an error message.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>An instance of the SQLAlchemy <code>Table</code> class</p> required <code>deleted.</code> <code>record_id (str</code> <p>The ID of the record to be deleted.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing a success message if the record was</p> <p>deleted successfully, or an error message if the record was not</p> <p>found or an exception occurred.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the delete operation.</p> Example <p>```python from sqlalchemy import Table, MetaData, Column, Integer, String from dsg_lib import database_config, database_operations</p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def delete_one(self, table, record_id: str):\n    \"\"\"\n    Deletes a single record from the database based on the provided table\n    and record ID.\n\n    This asynchronous method accepts a SQLAlchemy `Table` object and a\n    record ID. It attempts to delete the record with the given ID from the\n    specified table. If the record is successfully deleted, it returns a\n    success message. If no record with the given ID is found, it returns an\n    error message.\n\n    Args:\n        table (Table): An instance of the SQLAlchemy `Table` class\n        representing the database table from which the record will be\n        deleted. record_id (str): The ID of the record to be deleted.\n\n    Returns:\n        dict: A dictionary containing a success message if the record was\n        deleted successfully, or an error message if the record was not\n        found or an exception occurred.\n\n    Raises:\n        Exception: If any error occurs during the delete operation.\n\n    Example:\n        ```python from sqlalchemy import Table, MetaData, Column, Integer,\n        String from dsg_lib import database_config, database_operations\n\n        # Define your database configuration config = {\n            \"database_uri\":\n            \"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\":\n            True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n            \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n        }\n\n        # Define a table metadata = MetaData() my_table = Table('my_table',\n        metadata,\n                         Column('id', Integer, primary_key=True),\n                         Column('name', String))\n\n        # Initialize DatabaseOperations and DBConfig db_config =\n        database_config.DBConfig(config) db_ops =\n        database_operations.DatabaseOperations()\n\n        # Delete a record from 'my_table' async with\n        db_config.get_db_session() as session:\n            result = await db_ops.delete_one(my_table, '1') # Output:\n            {'success': 'Record deleted successfully'} or {'error': 'Record\n            not found'}\n        ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(\n        f\"Starting delete_one operation for record_id: {record_id} in table: {table.__name__}\"\n    )\n\n    try:\n        # Start a new database session\n        async with self.async_db.get_db_session() as session:\n            # Log the record being fetched\n            logger.debug(f\"Fetching record with id: {record_id}\")\n\n            # Fetch the record\n            record = await session.get(table, record_id)\n\n            # If the record doesn't exist, return an error\n            if not record:\n                logger.error(f\"No record found with pkid: {record_id}\")\n                return {\n                    \"error\": \"Record not found\",\n                    \"details\": f\"No record found with pkid {record_id}\",\n                }\n\n            # Log the record being deleted\n            logger.debug(f\"Deleting record with id: {record_id}\")\n\n            # Delete the record\n            await session.delete(record)\n\n            # Log the successful record deletion from the session\n            logger.debug(f\"Record deleted from session: {record}\")\n\n            # Log the start of the commit\n            logger.debug(\n                f\"Committing changes to delete record with id: {record_id}\"\n            )\n\n            # Commit the changes\n            await session.commit()\n\n            # Log the successful record deletion\n            logger.info(f\"Record deleted successfully: {record_id}\")\n\n            return {\"success\": \"Record deleted successfully\"}\n\n    except Exception as ex:\n        # Handle any exceptions that occur during the record deletion\n        logger.error(f\"Exception occurred: {ex}\")\n        return handle_exceptions(ex)\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.delete_one--define-your-database-configuration-config","title":"Define your database configuration config = {","text":"<pre><code>\"database_uri\":\n\"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\":\nTrue, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n\"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n</code></pre> <p>}</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.delete_one--define-a-table-metadata-metadata-my_table-tablemy_table","title":"Define a table metadata = MetaData() my_table = Table('my_table',","text":"<p>metadata,                  Column('id', Integer, primary_key=True),                  Column('name', String))</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.delete_one--initialize-databaseoperations-and-dbconfig-db_config","title":"Initialize DatabaseOperations and DBConfig db_config =","text":"<p>database_config.DBConfig(config) db_ops = database_operations.DatabaseOperations()</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.delete_one--delete-a-record-from-my_table-async-with","title":"Delete a record from 'my_table' async with","text":"<p>db_config.get_db_session() as session:     result = await db_ops.delete_one(my_table, '1') # Output:     {'success': 'Record deleted successfully'} or {'error': 'Record     not found'} ```</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.get_columns_details","title":"<code>get_columns_details(table)</code>  <code>async</code>","text":"<p>Retrieves the details of the columns of a given table.</p> <p>This asynchronous method accepts a table object and returns a dictionary. Each key in the dictionary is a column name from the table, and the corresponding value is another dictionary containing details about that column, such as type, if it's nullable, if it's a primary key, if it's unique, its autoincrement status, and its default value.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>An instance of the SQLAlchemy Table class</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary where each key is a column name, and each value</p> <p>is a dictionary with the column's details.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the database operation.</p> <p>Example: <code>python from sqlalchemy import Table, MetaData, Column, Integer, String from dsg_lib import module_name metadata = MetaData() my_table = Table('my_table', metadata,                 Column('id', Integer, primary_key=True), Column('name',                 String)) async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db) asyncio.run(db_ops.get_columns_details(my_table))     {         'id': {             'type': 'INTEGER', 'nullable': False, 'primary_key': True,             'unique': False, 'autoincrement': 'auto', 'default': None         }, 'name': {             'type': 'VARCHAR', 'nullable': True, 'primary_key': False,             'unique': False, 'autoincrement': False, 'default': None         }     }</code></p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def get_columns_details(self, table):\n    \"\"\"\n    Retrieves the details of the columns of a given table.\n\n    This asynchronous method accepts a table object and returns a\n    dictionary. Each key in the dictionary is a column name from the table,\n    and the corresponding value is another dictionary containing details\n    about that column, such as type, if it's nullable, if it's a primary\n    key, if it's unique, its autoincrement status, and its default value.\n\n    Args:\n        table (Table): An instance of the SQLAlchemy Table class\n        representing the database table for which column details are\n        required.\n\n    Returns:\n        dict: A dictionary where each key is a column name, and each value\n        is a dictionary with the column's details.\n\n    Raises:\n        Exception: If any error occurs during the database operation.\n\n    Example: ```python from sqlalchemy import Table, MetaData, Column,\n    Integer, String from dsg_lib import module_name metadata = MetaData()\n    my_table = Table('my_table', metadata,\n                    Column('id', Integer, primary_key=True), Column('name',\n                    String))\n    async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes\n    no arguments db_ops = module_name.DatabaseOperations(async_db)\n    asyncio.run(db_ops.get_columns_details(my_table))\n        {\n            'id': {\n                'type': 'INTEGER', 'nullable': False, 'primary_key': True,\n                'unique': False, 'autoincrement': 'auto', 'default': None\n            }, 'name': {\n                'type': 'VARCHAR', 'nullable': True, 'primary_key': False,\n                'unique': False, 'autoincrement': False, 'default': None\n            }\n        }\n    ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(\n        f\"Starting get_columns_details operation for table: {table.__name__}\"\n    )\n\n    try:\n        # Log the start of the column retrieval\n        logger.debug(f\"Getting columns for table: {table.__name__}\")\n\n        # Retrieve the details of the columns and store them in a dictionary\n        # The keys are the column names and the values are dictionaries\n        # containing the column details\n        columns = {\n            c.name: {\n                \"type\": str(c.type),\n                \"nullable\": c.nullable,\n                \"primary_key\": c.primary_key,\n                \"unique\": c.unique,\n                \"autoincrement\": c.autoincrement,\n                \"default\": str(c.default.arg)\n                if c.default is not None and not callable(c.default.arg)\n                else None,\n            }\n            for c in table.__table__.columns\n        }\n\n        # Log the successful column retrieval\n        logger.info(f\"Successfully retrieved columns for table: {table.__name__}\")\n\n        return columns\n    except Exception as ex:  # pragma: no cover\n        # Handle any exceptions that occur during the column retrieval\n        logger.error(\n            f\"An error occurred while getting columns for table: {table.__name__}\"\n        )  # pragma: no cover\n        return handle_exceptions(ex)  # pragma: no cover\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.get_one_record","title":"<code>get_one_record(query)</code>  <code>async</code>","text":"<p>Retrieves a single record from the database based on the provided query.</p> <p>This asynchronous method accepts a SQL query object and returns the first record that matches the query. If no record matches the query, it raises an exception. This method is useful for fetching specific data when the expected result is a single record.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Select</code> <p>An instance of the SQLAlchemy Select class,</p> required <p>Returns:</p> Name Type Description <code>Result</code> <p>The first record that matches the query.</p> <p>Raises:</p> Type Description <code>NoResultFound</code> <p>If no record matches the query. Exception: If any</p> Example <p><code>python from sqlalchemy import select, Table, Column, Integer, String, MetaData from dsg_lib import module_name metadata = MetaData() my_table = Table('my_table', metadata,                  Column('id', Integer, primary_key=True),                  Column('name', String)) query = select(my_table).where(my_table.c.id == 1) async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db) asyncio.run(db_ops.get_one_record(query)) # Output: {'id': 1, 'name': 'John Doe'}</code></p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def get_one_record(self, query):\n    \"\"\"\n    Retrieves a single record from the database based on the provided query.\n\n    This asynchronous method accepts a SQL query object and returns the\n    first record that matches the query. If no record matches the query, it\n    raises an exception. This method is useful for fetching specific data\n    when the expected result is a single record.\n\n    Parameters:\n        query (Select): An instance of the SQLAlchemy Select class,\n        representing the query to be executed.\n\n    Returns:\n        Result: The first record that matches the query.\n\n    Raises:\n        NoResultFound: If no record matches the query. Exception: If any\n        other error occurs during the database operation.\n\n    Example:\n        ```python from sqlalchemy import select, Table, Column, Integer,\n        String, MetaData from dsg_lib import module_name metadata =\n        MetaData() my_table = Table('my_table', metadata,\n                         Column('id', Integer, primary_key=True),\n                         Column('name', String))\n        query = select(my_table).where(my_table.c.id == 1) async_db =\n        module_name.AsyncDatabase()  # assuming AsyncDatabase takes no\n        arguments db_ops = module_name.DatabaseOperations(async_db)\n        asyncio.run(db_ops.get_one_record(query)) # Output: {'id': 1,\n        'name': 'John Doe'} ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(f\"Starting get_one_record operation for {query}\")\n\n    try:\n        # Start a new database session\n        async with self.async_db.get_db_session() as session:\n            # Log the start of the record retrieval\n            logger.debug(f\"Getting record with query: {query}\")\n\n            # Execute the query and retrieve the first record\n            result = await session.execute(query)\n            record = result.scalar_one()\n\n            # Log the successful record retrieval\n            logger.info(f\"Record retrieved successfully: {record}\")\n\n            return record\n\n    except Exception as ex:  # pragma: no cover\n        # Handle any exceptions that occur during the record retrieval\n        logger.error(f\"Exception occurred: {ex}\")  # pragma: no cover\n        return handle_exceptions(ex)  # pragma: no cover\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.get_primary_keys","title":"<code>get_primary_keys(table)</code>  <code>async</code>","text":"<p>Retrieves the primary keys of a given table.</p> <p>This asynchronous method accepts a table object and returns a list containing the names of its primary keys. It is useful for understanding the structure of the table and for operations that require knowledge of the primary keys.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>An instance of the SQLAlchemy Table class</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing the names of the primary keys of the table.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the database operation.</p> Example <p><code>python from sqlalchemy import Table, MetaData, Column, Integer, String from dsg_lib import module_name metadata = MetaData() my_table = Table('my_table', metadata,                  Column('id', Integer, primary_key=True),                  Column('name', String, primary_key=True)) async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db) asyncio.run(db_ops.get_primary_keys(my_table)) # Output: ['id', 'name']</code></p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def get_primary_keys(self, table):\n    \"\"\"\n    Retrieves the primary keys of a given table.\n\n    This asynchronous method accepts a table object and returns a list\n    containing the names of its primary keys. It is useful for understanding\n    the structure of the table and for operations that require knowledge of\n    the primary keys.\n\n    Args:\n        table (Table): An instance of the SQLAlchemy Table class\n        representing the database table for which primary keys are required.\n\n    Returns:\n        list: A list containing the names of the primary keys of the table.\n\n    Raises:\n        Exception: If any error occurs during the database operation.\n\n    Example:\n        ```python from sqlalchemy import Table, MetaData, Column, Integer,\n        String from dsg_lib import module_name metadata = MetaData()\n        my_table = Table('my_table', metadata,\n                         Column('id', Integer, primary_key=True),\n                         Column('name', String, primary_key=True))\n        async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n        takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n        asyncio.run(db_ops.get_primary_keys(my_table)) # Output: ['id',\n        'name'] ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(f\"Starting get_primary_keys operation for table: {table.__name__}\")\n\n    try:\n        # Log the start of the primary key retrieval\n        logger.debug(f\"Getting primary keys for table: {table.__name__}\")\n\n        # Retrieve the primary keys and store them in a list\n        primary_keys = table.__table__.primary_key.columns.keys()\n\n        # Log the successful primary key retrieval\n        logger.info(f\"Primary keys retrieved successfully: {primary_keys}\")\n\n        return primary_keys\n\n    except Exception as ex:  # pragma: no cover\n        # Handle any exceptions that occur during the primary key retrieval\n        logger.error(f\"Exception occurred: {ex}\")  # pragma: no cover\n        return handle_exceptions(ex)  # pragma: no cover\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.get_table_names","title":"<code>get_table_names()</code>  <code>async</code>","text":"<p>Retrieves the names of all tables in the database.</p> <p>This asynchronous method returns a list containing the names of all tables in the database. It is useful for database introspection, allowing the user to know which tables are available in the current database context.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing the names of all tables in the database.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the database operation.</p> Example <p><code>python from dsg_lib import module_name async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db) asyncio.run(db_ops.get_table_names()) # Output: ['table1', 'table2', ...]</code></p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def get_table_names(self):\n    \"\"\"\n    Retrieves the names of all tables in the database.\n\n    This asynchronous method returns a list containing the names of all\n    tables in the database. It is useful for database introspection,\n    allowing the user to know which tables are available in the current\n    database context.\n\n    Returns:\n        list: A list containing the names of all tables in the database.\n\n    Raises:\n        Exception: If any error occurs during the database operation.\n\n    Example:\n        ```python from dsg_lib import module_name async_db =\n        module_name.AsyncDatabase()  # assuming AsyncDatabase takes no\n        arguments db_ops = module_name.DatabaseOperations(async_db)\n        asyncio.run(db_ops.get_table_names()) # Output: ['table1', 'table2',\n        ...] ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(\"Starting get_table_names operation\")\n\n    try:\n        # Log the start of the table name retrieval\n        logger.debug(\"Retrieving table names\")\n\n        # Retrieve the table names and store them in a list The keys of the\n        # metadata.tables dictionary are the table names\n        table_names = list(self.async_db.Base.metadata.tables.keys())\n\n        # Log the successful table name retrieval\n        logger.info(f\"Table names retrieved successfully: {table_names}\")\n\n        return table_names\n\n    except Exception as ex:  # pragma: no cover\n        # Handle any exceptions that occur during the table name retrieval\n        logger.error(f\"Exception occurred: {ex}\")  # pragma: no cover\n        return handle_exceptions(ex)  # pragma: no cover\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.read_multi_query","title":"<code>read_multi_query(queries, limit=500, offset=0)</code>  <code>async</code>","text":"<p>Executes multiple fetch queries on the database and returns a dictionary of results for each query.</p> <p>This asynchronous method takes a dictionary where each key is a query name and each value is a SQLAlchemy <code>Select</code> query object. It also accepts optional limit and offset parameters. The method executes each query and returns a dictionary where each key is the query name, and the corresponding value is a list of records that match that query.</p> <p>Parameters:</p> Name Type Description Default <code>queries</code> <code>Dict[str, Select]</code> <p>A dictionary of SQLAlchemy <code>Select</code></p> required <code>query</code> <code>objects. limit (int</code> <p>The maximum number of records</p> required <code>to</code> <code>return for each query. Defaults to 500. offset (int</code> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary where each key is a query name and each value is</p> <p>a list of records that match the query.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the execution of the queries.</p> Example <p>```python from sqlalchemy import select from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Column, Integer, String from dsg_lib import module_name</p> <p>Base = declarative_base()</p> <p>class User(Base):     tablename = 'users' id = Column(Integer, primary_key=True)     name = Column(String) age = Column(Integer)</p> <p>async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db)</p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def read_multi_query(self, queries: Dict[str, str], limit=500, offset=0):\n    \"\"\"\n    Executes multiple fetch queries on the database and returns a dictionary\n    of results for each query.\n\n    This asynchronous method takes a dictionary where each key is a query\n    name and each value is a SQLAlchemy `Select` query object. It also\n    accepts optional limit and offset parameters. The method executes each\n    query and returns a dictionary where each key is the query name, and the\n    corresponding value is a list of records that match that query.\n\n    Parameters:\n        queries (Dict[str, Select]): A dictionary of SQLAlchemy `Select`\n        query objects. limit (int, optional): The maximum number of records\n        to return for each query. Defaults to 500. offset (int, optional):\n        The number of records to skip before returning records for each\n        query. Defaults to 0.\n\n    Returns:\n        dict: A dictionary where each key is a query name and each value is\n        a list of records that match the query.\n\n    Raises:\n        Exception: If any error occurs during the execution of the queries.\n\n    Example:\n        ```python from sqlalchemy import select from\n        sqlalchemy.ext.declarative import declarative_base from sqlalchemy\n        import Column, Integer, String from dsg_lib import module_name\n\n        Base = declarative_base()\n\n        class User(Base):\n            __tablename__ = 'users' id = Column(Integer, primary_key=True)\n            name = Column(String) age = Column(Integer)\n\n        async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n        takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n\n        # Creating queries query1 = select(User).where(User.age &gt; 30) query2\n        = select(User).where(User.name.startswith('J'))\n\n        queries = {\"older_users\": query1, \"j_users\": query2}\n\n        # Using the read_multi_query method results =\n        asyncio.run(db_ops.read_multi_query(queries, limit=10)) # Output:\n        Dictionary with keys 'older_users' and 'j_users' each containing a\n        list of up to 10 records ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(\"Starting read_multi_query operation\")\n\n    try:\n        results = {}\n        # Start a new database session\n        async with self.async_db.get_db_session() as session:\n            for query_name, query in queries.items():\n                # Log the query being executed\n                logger.debug(f\"Executing fetch query: {query}\")\n\n                # Execute the fetch query and retrieve the records\n                result = await session.execute(query.limit(limit).offset(offset))\n                data = result.scalars().all()\n\n                # Convert the records to dictionaries for logging\n                data_dicts = [record.__dict__ for record in data]\n                logger.debug(f\"Fetch result for query '{query_name}': {data_dicts}\")\n\n                # Log the successful query execution\n                logger.info(\n                    f\"Fetch query executed successfully: {query_name} with {len(data)} records\"\n                )\n\n                # Store the records in the results dictionary\n                results[query_name] = data\n        return results\n\n    except Exception as ex:\n        # Handle any exceptions that occur during the query execution\n        logger.error(f\"Exception occurred: {ex}\")\n        return handle_exceptions(ex)\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.read_multi_query--creating-queries-query1-selectuserwhereuserage-30-query2","title":"Creating queries query1 = select(User).where(User.age &gt; 30) query2","text":"<p>= select(User).where(User.name.startswith('J'))</p> <p>queries = {\"older_users\": query1, \"j_users\": query2}</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.read_multi_query--using-the-read_multi_query-method-results","title":"Using the read_multi_query method results =","text":"<p>asyncio.run(db_ops.read_multi_query(queries, limit=10)) # Output: Dictionary with keys 'older_users' and 'j_users' each containing a list of up to 10 records ```</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.read_query","title":"<code>read_query(query, limit=500, offset=0)</code>  <code>async</code>","text":"<p>Executes a fetch query on the database and returns a list of records that match the query.</p> <p>This asynchronous method accepts a SQLAlchemy <code>Select</code> query object along with optional limit and offset parameters. It returns a list of records that match the query, with the number of records controlled by the limit, and the starting point of the records determined by the offset.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Select</code> <p>A SQLAlchemy <code>Select</code> query object specifying the</p> required <code>conditions</code> <code>to fetch records for. limit (int</code> <p>The maximum</p> required <code>optional)</code> <p>The number of records to skip before starting to return</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of records that match the query.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the execution of the query.</p> Example <p>```python from sqlalchemy import select from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Column, Integer, String from dsg_lib import module_name</p> <p>Base = declarative_base()</p> <p>class MyModel(Base):     tablename = 'my_table' id = Column(Integer,     primary_key=True) name = Column(String)</p> <p>async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase takes no arguments db_ops = module_name.DatabaseOperations(async_db)</p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def read_query(self, query, limit=500, offset=0):\n    \"\"\"\n    Executes a fetch query on the database and returns a list of records\n    that match the query.\n\n    This asynchronous method accepts a SQLAlchemy `Select` query object\n    along with optional limit and offset parameters. It returns a list of\n    records that match the query, with the number of records controlled by\n    the limit, and the starting point of the records determined by the\n    offset.\n\n    Parameters:\n        query (Select): A SQLAlchemy `Select` query object specifying the\n        conditions to fetch records for. limit (int, optional): The maximum\n        number of records to return. Defaults to 500. offset (int,\n        optional): The number of records to skip before starting to return\n        records. Defaults to 0.\n\n    Returns:\n        list: A list of records that match the query.\n\n    Raises:\n        Exception: If any error occurs during the execution of the query.\n\n    Example:\n        ```python from sqlalchemy import select from\n        sqlalchemy.ext.declarative import declarative_base from sqlalchemy\n        import Column, Integer, String from dsg_lib import module_name\n\n        Base = declarative_base()\n\n        class MyModel(Base):\n            __tablename__ = 'my_table' id = Column(Integer,\n            primary_key=True) name = Column(String)\n\n        async_db = module_name.AsyncDatabase()  # assuming AsyncDatabase\n        takes no arguments db_ops = module_name.DatabaseOperations(async_db)\n\n        # Creating a query to fetch records query =\n        select(MyModel).where(MyModel.name == 'John Doe')\n\n        # Using the read_query method result =\n        asyncio.run(db_ops.read_query(query, limit=10, offset=0)) # Output:\n        A list of up to 10 records where name is 'John Doe', starting from\n        the first record ```\n    \"\"\"\n    # Log the start of the operation\n    logger.debug(\"Starting read_query operation\")\n\n    try:\n        # Start a new database session\n        async with self.async_db.get_db_session() as session:\n            # Log the query being executed\n            logger.debug(\n                f\"Executing fetch query: {query} with limit: {limit} and offset: {offset}\"\n            )\n\n            # Execute the fetch query and retrieve the records\n            result = await session.execute(query.limit(limit).offset(offset))\n            records = result.scalars().all()\n\n            # Log the successful query execution\n            records_data = [record.__dict__ for record in records]\n            logger.info(\n                f\"Fetch query executed successfully. Records: {records_data}\"\n            )\n\n            return records\n\n    except Exception as ex:\n        # Handle any exceptions that occur during the query execution\n        logger.error(f\"Exception occurred: {ex}\")\n        return handle_exceptions(ex)\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.read_query--creating-a-query-to-fetch-records-query","title":"Creating a query to fetch records query =","text":"<p>select(MyModel).where(MyModel.name == 'John Doe')</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.read_query--using-the-read_query-method-result","title":"Using the read_query method result =","text":"<p>asyncio.run(db_ops.read_query(query, limit=10, offset=0)) # Output: A list of up to 10 records where name is 'John Doe', starting from the first record ```</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.update_one","title":"<code>update_one(table, record_id, new_values)</code>  <code>async</code>","text":"<p>Updates a single record in the database identified by its ID.</p> <p>This asynchronous method takes a SQLAlchemy <code>Table</code> object, a record ID, and a dictionary of new values to update the record. It updates the specified record in the given table with the new values. The method does not allow updating certain fields, such as 'id' or 'date_created'.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>The SQLAlchemy <code>Table</code> object representing the table</p> required <code>in</code> <code>the database. record_id (str</code> <p>The ID of the record to be</p> required <code>updated.</code> <code>new_values (dict</code> <p>A dictionary containing the fields to</p> required <p>Returns:</p> Name Type Description <code>Base</code> <p>The updated record if successful; otherwise, an error</p> <p>dictionary.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If any error occurs during the update operation.</p> Example <p>```python from sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Column, Integer, String from dsg_lib import database_config, database_operations</p> <p>Base = declarative_base()</p> <p>class User(Base):     tablename = 'users' id = Column(Integer, primary_key=True)     name = Column(String) age = Column(Integer)</p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>async def update_one(self, table, record_id: str, new_values: dict):\n    \"\"\"\n    Updates a single record in the database identified by its ID.\n\n    This asynchronous method takes a SQLAlchemy `Table` object, a record ID,\n    and a dictionary of new values to update the record. It updates the\n    specified record in the given table with the new values. The method does\n    not allow updating certain fields, such as 'id' or 'date_created'.\n\n    Parameters:\n        table (Table): The SQLAlchemy `Table` object representing the table\n        in the database. record_id (str): The ID of the record to be\n        updated. new_values (dict): A dictionary containing the fields to\n        update and their new values.\n\n    Returns:\n        Base: The updated record if successful; otherwise, an error\n        dictionary.\n\n    Raises:\n        Exception: If any error occurs during the update operation.\n\n    Example:\n        ```python from sqlalchemy.ext.declarative import declarative_base\n        from sqlalchemy import Column, Integer, String from dsg_lib import\n        database_config, database_operations\n\n        Base = declarative_base()\n\n        class User(Base):\n            __tablename__ = 'users' id = Column(Integer, primary_key=True)\n            name = Column(String) age = Column(Integer)\n\n        # Define your database configuration config = {\n            \"database_uri\":\n            \"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\":\n            True, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n            \"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n        }\n\n        db_config = database_config.DBConfig(config) db_ops =\n        database_operations.DatabaseOperations()\n\n        # Updating a record in the 'users' table async with\n        db_config.get_db_session() as session:\n            updated_record = await db_ops.update_one(User.__table__, '1',\n            {\"name\": \"Updated Name\", \"age\": 30}) # Output: Updated User\n            record with the new name and age\n        ```\n    \"\"\"\n    non_updatable_fields = [\"id\", \"date_created\"]\n\n    # Log the start of the operation\n    logger.debug(\n        f\"Starting update_one operation for record_id: {record_id} in table: {table.__name__}\"\n    )\n\n    try:\n        # Start a new database session\n        async with self.async_db.get_db_session() as session:\n            # Log the record being fetched\n            logger.debug(f\"Fetching record with id: {record_id}\")\n\n            # Fetch the record\n            record = await session.get(table, record_id)\n            if not record:\n                # Log the error if no record is found\n                logger.error(f\"No record found with pkid: {record_id}\")\n                return {\n                    \"error\": \"Record not found\",\n                    \"details\": f\"No record found with pkid {record_id}\",\n                }\n\n            # Log the record being updated\n            logger.debug(f\"Updating record with new values: {new_values}\")\n\n            # Update the record with the new values\n            for key, value in new_values.items():\n                if key not in non_updatable_fields:\n                    setattr(record, key, value)\n            await session.commit()\n\n            # Log the successful record update\n            logger.info(f\"Record updated successfully: {record.pkid}\")\n            return record\n\n    except Exception as ex:\n        # Handle any exceptions that occur during the record update\n        logger.error(f\"Exception occurred: {ex}\")\n        return handle_exceptions(ex)\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.update_one--define-your-database-configuration-config","title":"Define your database configuration config = {","text":"<pre><code>\"database_uri\":\n\"postgresql+asyncpg://user:password@localhost/dbname\", \"echo\":\nTrue, \"future\": True, \"pool_pre_ping\": True, \"pool_size\": 5,\n\"max_overflow\": 10, \"pool_recycle\": 3600, \"pool_timeout\": 30,\n</code></pre> <p>}</p> <p>db_config = database_config.DBConfig(config) db_ops = database_operations.DatabaseOperations()</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.DatabaseOperations.update_one--updating-a-record-in-the-users-table-async-with","title":"Updating a record in the 'users' table async with","text":"<p>db_config.get_db_session() as session:     updated_record = await db_ops.update_one(User.table, '1',     {\"name\": \"Updated Name\", \"age\": 30}) # Output: Updated User     record with the new name and age ```</p>"},{"location":"database/database_operations/#dsg_lib.database_operations.handle_exceptions","title":"<code>handle_exceptions(ex)</code>","text":"<p>Handles exceptions for database operations.</p> <p>This function checks the type of the exception, logs an appropriate error message, and returns a dictionary containing the error details.</p> <p>Parameters:</p> Name Type Description Default <code>ex</code> <code>Exception</code> <p>The exception to handle.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, str]</code> <p>A dictionary containing the error details. The dictionary has two</p> <code>keys</code> <code>Dict[str, str]</code> <p>'error' and 'details'.</p> <p>Example: ```python from dsg_lib import database_operations</p> try <p>except Exception as ex:     error_details = database_operations.handle_exceptions(ex)     print(error_details) ```</p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>def handle_exceptions(ex: Exception) -&gt; Dict[str, str]:\n    \"\"\"\n    Handles exceptions for database operations.\n\n    This function checks the type of the exception, logs an appropriate error\n    message, and returns a dictionary containing the error details.\n\n    Args:\n        ex (Exception): The exception to handle.\n\n    Returns:\n        dict: A dictionary containing the error details. The dictionary has two\n        keys: 'error' and 'details'.\n\n    Example: ```python from dsg_lib import database_operations\n\n    try:\n        # Some database operation that might raise an exception pass\n    except Exception as ex:\n        error_details = database_operations.handle_exceptions(ex)\n        print(error_details)\n    ```\n    \"\"\"\n    # Extract the error message before the SQL statement\n    error_only = str(ex).split(\"[SQL:\")[0]\n\n    # Check the type of the exception\n    if isinstance(ex, IntegrityError):\n        # Log the error and return the error details\n        logger.error(f\"IntegrityError occurred: {ex}\")\n        return {\"error\": \"IntegrityError\", \"details\": error_only}\n    elif isinstance(ex, SQLAlchemyError):\n        # Log the error and return the error details\n        logger.error(f\"SQLAlchemyError occurred: {ex}\")\n        return {\"error\": \"SQLAlchemyError\", \"details\": error_only}\n    else:\n        # Log the error and return the error details\n        logger.error(f\"Exception occurred: {ex}\")\n        return {\"error\": \"General Exception\", \"details\": str(ex)}\n</code></pre>"},{"location":"database/database_operations/#dsg_lib.database_operations.handle_exceptions--some-database-operation-that-might-raise-an-exception-pass","title":"Some database operation that might raise an exception pass","text":""},{"location":"database/database_operations/#dsg_lib.database_operations.import_sqlalchemy","title":"<code>import_sqlalchemy()</code>","text":"<p>This function tries to import SQLAlchemy and its components, and raises an ImportError if SQLAlchemy is not installed or if the installed version is not compatible with the minimum required version.</p> <p>Returns:</p> Name Type Description <code>Tuple</code> <code>Tuple</code> <p>A tuple containing the imported SQLAlchemy module and its</p> <code>Tuple</code> <p>components (MetaData, create_engine, text, IntegrityError,</p> <code>Tuple</code> <p>SQLAlchemyError, AsyncSession, create_async_engine, select,</p> <code>Tuple</code> <p>declarative_base, sessionmaker).</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If SQLAlchemy is not installed or if the installed version</p> <p>Example: <code>python from dsg_lib import database_config sqlalchemy, MetaData, create_engine, text, IntegrityError, SQLAlchemyError, AsyncSession, create_async_engine, select, declarative_base, sessionmaker = database_config.import_sqlalchemy()</code></p> Source code in <code>dsg_lib/database_operations.py</code> <pre><code>def import_sqlalchemy() -&gt; Tuple:\n    \"\"\"\n    This function tries to import SQLAlchemy and its components, and raises an\n    ImportError if SQLAlchemy is not installed or if the installed version is\n    not compatible with the minimum required version.\n\n    Returns:\n        Tuple: A tuple containing the imported SQLAlchemy module and its\n        components (MetaData, create_engine, text, IntegrityError,\n        SQLAlchemyError, AsyncSession, create_async_engine, select,\n        declarative_base, sessionmaker).\n\n    Raises:\n        ImportError: If SQLAlchemy is not installed or if the installed version\n        is not compatible with the minimum required version.\n\n    Example: ```python from dsg_lib import database_config sqlalchemy, MetaData,\n    create_engine, text, IntegrityError, SQLAlchemyError, AsyncSession,\n    create_async_engine, select, declarative_base, sessionmaker =\n    database_config.import_sqlalchemy() ```\n    \"\"\"\n    # Define the minimum required version of SQLAlchemy\n    min_version = \"1.4.0\"\n\n    try:\n        # Try to import necessary components from SQLAlchemy\n        import sqlalchemy\n        from sqlalchemy import func\n        from sqlalchemy.exc import IntegrityError, SQLAlchemyError\n        from sqlalchemy.future import select\n    except ImportError:\n        # If import fails, set all components to None\n        func = select = sqlalchemy = None\n\n    # Check if SQLAlchemy is imported and if its version is compatible\n    if sqlalchemy is not None and packaging_version.parse(\n        sqlalchemy.__version__\n    ) &lt; packaging_version.parse(min_version):\n        # If the version is not compatible, raise an ImportError\n        raise ImportError(\n            f\"SQLAlchemy version &gt;= {min_version} required, run `pip install --upgrade sqlalchemy`\"\n        )\n\n    # Return the imported components\n    return sqlalchemy, func, IntegrityError, SQLAlchemyError, select\n</code></pre>"},{"location":"endpoints/http_codes/","title":"Reference","text":""},{"location":"endpoints/http_codes/#dsg_lib.http_codes","title":"<code>dsg_lib.http_codes</code>","text":"<p>This module provides a dictionary of HTTP status codes and their descriptions.</p> <p>The dictionary <code>ALL_HTTP_CODES</code> contains the HTTP status codes as keys. Each key maps to another dictionary that contains a description of the status code and a link to its documentation on the Mozilla Developer Network (MDN).</p> Example <p>```python from dsg_lib import http_codes</p> Variables <p>ALL_HTTP_CODES (dict): A dictionary of HTTP status codes. Each key is an HTTP status code (int), and each value is another dictionary with keys 'description' (str) and 'link' (str).</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes--get-the-description-and-link-for-http-status-code-200-status_200","title":"Get the description and link for HTTP status code 200 status_200 =","text":"<p>http_codes.ALL_HTTP_CODES[200] print(status_200)  # {'description': 'OK', 'link': 'https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200'} ```</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.DELETE_CODES","title":"<code>DELETE_CODES = generate_code_dict(common_codes + [202, 204, 205, 409])</code>  <code>module-attribute</code>","text":"<p>DELETE_CODES is a dictionary of HTTP status codes for DELETE requests. It includes all the common codes, plus some additional codes that are specific to DELETE requests.</p> Example <p>```python from dsg_lib import http_codes</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.DELETE_CODES--print-the-dictionary-of-http-status-codes-for-delete-requests","title":"Print the dictionary of HTTP status codes for DELETE requests","text":"<p>print(http_codes.DELETE_CODES) ```</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.GET_CODES","title":"<code>GET_CODES = generate_code_dict(common_codes + [206, 304, 307, 410, 502])</code>  <code>module-attribute</code>","text":"<p>GET_CODES is a dictionary of HTTP status codes for GET requests. It includes all the common codes, plus some additional codes that are specific to GET requests.</p> Example <p>```python from dsg_lib import http_codes</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.GET_CODES--print-the-dictionary-of-http-status-codes-for-get-requests","title":"Print the dictionary of HTTP status codes for GET requests","text":"<p>print(http_codes.GET_CODES) ```</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.PATCH_CODES","title":"<code>PATCH_CODES = generate_code_dict(common_codes + [202, 204, 206, 409, 412, 413])</code>  <code>module-attribute</code>","text":"<p>PATCH_CODES is a dictionary of HTTP status codes for PATCH requests. It includes all the common codes, plus some additional codes that are specific to PATCH requests.</p> Example <p>```python from dsg_lib import http_codes</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.PATCH_CODES--print-the-dictionary-of-http-status-codes-for-patch-requests","title":"Print the dictionary of HTTP status codes for PATCH requests","text":"<p>print(http_codes.PATCH_CODES) ```</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.POST_CODES","title":"<code>POST_CODES = generate_code_dict(common_codes + [201, 202, 205, 307, 409, 413, 415])</code>  <code>module-attribute</code>","text":"<p>POST_CODES is a dictionary of HTTP status codes for POST requests. It includes all the common codes, plus some additional codes that are specific to POST requests.</p> Example <p>```python from dsg_lib import http_codes</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.POST_CODES--print-the-dictionary-of-http-status-codes-for-post-requests","title":"Print the dictionary of HTTP status codes for POST requests","text":"<p>print(http_codes.POST_CODES) ```</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.PUT_CODES","title":"<code>PUT_CODES = generate_code_dict(common_codes + [202, 204, 206, 409, 412, 413])</code>  <code>module-attribute</code>","text":"<p>PUT_CODES is a dictionary of HTTP status codes for PUT requests. It includes all the common codes, plus some additional codes that are specific to PUT requests.</p> Example <p>```python from dsg_lib import http_codes</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.PUT_CODES--print-the-dictionary-of-http-status-codes-for-put-requests","title":"Print the dictionary of HTTP status codes for PUT requests","text":"<p>print(http_codes.PUT_CODES) ```</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.generate_code_dict","title":"<code>generate_code_dict(codes, description_only=False)</code>","text":"<p>Generate a dictionary of specific HTTP error codes from the http_codes dictionary.</p> <p>This function takes a list of HTTP status codes and an optional boolean flag. If the flag is True, the function returns a dictionary where each key is an HTTP status code from the input list and each value is the corresponding description from the ALL_HTTP_CODES dictionary. If the flag is False, the function returns a dictionary where each key is an HTTP status code from the input list and each value is the corresponding dictionary from the ALL_HTTP_CODES dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>codes</code> <code>list</code> <p>A list of HTTP status codes. description_only (bool,</p> required <code>optional)</code> <p>If True, only the description of the codes will be returned.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary where each key is an HTTP error code from the input</p> <p>list and each value depends on the description_only parameter.</p> Example <p>```python from dsg_lib import http_codes</p> Source code in <code>dsg_lib/http_codes.py</code> <pre><code>def generate_code_dict(codes, description_only=False):\n    \"\"\"\n    Generate a dictionary of specific HTTP error codes from the http_codes\n    dictionary.\n\n    This function takes a list of HTTP status codes and an optional boolean\n    flag. If the flag is True, the function returns a dictionary where each key\n    is an HTTP status code from the input list and each value is the\n    corresponding description from the ALL_HTTP_CODES dictionary. If the flag is\n    False, the function returns a dictionary where each key is an HTTP status\n    code from the input list and each value is the corresponding dictionary from\n    the ALL_HTTP_CODES dictionary.\n\n    Args:\n        codes (list): A list of HTTP status codes. description_only (bool,\n        optional): If True, only the description of the codes will be returned.\n        Defaults to False.\n\n    Returns:\n        dict: A dictionary where each key is an HTTP error code from the input\n        list and each value depends on the description_only parameter.\n\n    Example:\n        ```python from dsg_lib import http_codes\n\n        # Generate a dictionary for HTTP status codes 200 and 404 status_dict =\n        http_codes.generate_code_dict([200, 404]) print(status_dict)  # {200:\n        {'description': 'OK', 'link':\n        'https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200'}, 404:\n        {'description': 'Not Found', 'link':\n        'https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404'}}\n\n        # Generate a dictionary for HTTP status codes 200 and 404 with only\n        descriptions status_dict = http_codes.generate_code_dict([200, 404],\n        description_only=True) print(status_dict)  # {200: 'OK', 404: 'Not\n        Found'} ```\n    \"\"\"\n\n    if description_only:\n        # Log the operation\n        logger.debug(f\"description_only is True and returning HTTP codes: {codes}\")\n\n        # If description_only is True, return a dictionary where each key is an\n        # HTTP error code from the input list and each value is the\n        # corresponding description from the ALL_HTTP_CODES dictionary.\n        return {\n            code: ALL_HTTP_CODES[code][\"description\"]\n            for code in codes\n            if code in ALL_HTTP_CODES\n        }\n    else:\n        # Log the operation\n        logger.debug(f\"returning HTTP codes: {codes}\")\n\n        # If description_only is False, return a dictionary where each key is an\n        # HTTP error code from the input list and each value is the\n        # corresponding dictionary from the ALL_HTTP_CODES dictionary.\n        return {code: ALL_HTTP_CODES[code] for code in codes if code in ALL_HTTP_CODES}\n</code></pre>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.generate_code_dict--generate-a-dictionary-for-http-status-codes-200-and-404-status_dict","title":"Generate a dictionary for HTTP status codes 200 and 404 status_dict =","text":"<p>http_codes.generate_code_dict([200, 404]) print(status_dict)  # {200: {'description': 'OK', 'link': 'https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200'}, 404: {'description': 'Not Found', 'link': 'https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404'}}</p>"},{"location":"endpoints/http_codes/#dsg_lib.http_codes.generate_code_dict--generate-a-dictionary-for-http-status-codes-200-and-404-with-only","title":"Generate a dictionary for HTTP status codes 200 and 404 with only","text":"<p>descriptions status_dict = http_codes.generate_code_dict([200, 404], description_only=True) print(status_dict)  # {200: 'OK', 404: 'Not Found'} ```</p>"},{"location":"endpoints/http_codes/#dsg_lib._all_codes","title":"<code>dsg_lib._all_codes</code>","text":"<p>A dictionary containing all HTTP status codes, their descriptions, and links to their documentation.</p> <p>This dictionary is a mapping from HTTP status codes to dictionaries containing their descriptions and links to their documentation.</p> <p>Each key in this dictionary is an HTTP status code, and each value is another dictionary with keys 'description' and 'link'. The \\ 'description' key maps to a string that describes the HTTP status code, and the 'link' key maps to a string that is a link to the \\ documentation for the HTTP status code.</p> Example <p>```python from dsg_lib.http_codes import ALL_HTTP_CODES</p>"},{"location":"endpoints/http_codes/#dsg_lib._all_codes--get-the-dictionary-for-http-status-code-200-status_200","title":"Get the dictionary for HTTP status code 200 status_200 =","text":"<p>ALL_HTTP_CODES[200] print(status_200)  # {'description': 'OK', 'link': 'https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200'}</p>"},{"location":"endpoints/http_codes/#dsg_lib._all_codes--get-the-description-for-http-status-code-404-description_404","title":"Get the description for HTTP status code 404 description_404 =","text":"<p>ALL_HTTP_CODES404 print(description_404)  # 'Not Found'</p>"},{"location":"endpoints/http_codes/#dsg_lib._all_codes--get-the-link-to-the-documentation-for-http-status-code-500-link_500","title":"Get the link to the documentation for HTTP status code 500 link_500 =","text":"<p>ALL_HTTP_CODES500 print(link_500)  # 'https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500' ```</p>"},{"location":"endpoints/system_health_endpoints/","title":"Reference","text":""},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints","title":"<code>dsg_lib.system_health_endpoints</code>","text":"<p>This module provides a configurable health endpoint for a FastAPI application. It includes the following routes:</p> <ul> <li> <p><code>/api/health/status</code>: Returns the status of the application. If the   application is running, it will return <code>{\"status\": \"UP\"}</code>. This endpoint can   be enabled or disabled using the configuration.</p> </li> <li> <p><code>/api/health/uptime</code>: Returns the uptime of the application in a dictionary   with the keys \"Days\", \"Hours\", \"Minutes\", and \"Seconds\". The uptime is   calculated from the time the application was started. This endpoint can be   enabled or disabled using the configuration.</p> </li> <li> <p><code>/api/health/heapdump</code>: Returns a heap dump of the application. The heap dump   is a list of dictionaries, each representing a line of code. Each dictionary   includes the filename, line number, size of memory consumed, and the number of   times the line is referenced. This endpoint can be enabled or disabled using   the configuration.</p> </li> </ul> <p>The module uses the <code>FastAPI</code>, <code>time</code>, <code>tracemalloc</code>, <code>loguru</code>, <code>packaging</code>, and <code>dsg_lib.http_codes</code> modules.</p> <p>Functions:</p> Name Description <code>create_health_router</code> <p>dict) -&gt; FastAPI.APIRouter: Creates a FastAPI router with health endpoints based on the provided configuration.</p> Example <p>```python from FastAPI import FastAPI from dsg_lib import system_health_endpoints</p> <p>app = FastAPI()</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints--user-configuration-config","title":"User configuration config = {","text":"<pre><code>\"enable_status_endpoint\": True, \"enable_uptime_endpoint\": False,\n\"enable_heapdump_endpoint\": True,\n</code></pre> <p>}</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints--health-router-health_router","title":"Health router health_router =","text":"<p>system_health_endpoints.create_health_router(config) app.include_router(health_router, prefix=\"/api/health\", tags=[\"system-health\"])</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints--get-the-status-of-the-application-response","title":"Get the status of the application response =","text":"<p>client.get(\"/api/health/status\") print(response.json())  # {\"status\": \"UP\"}</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints--get-the-uptime-of-the-application-response","title":"Get the uptime of the application response =","text":"<p>client.get(\"/api/health/uptime\") print(response.json())  # {\"uptime\": {\"Days\": 0, \"Hours\": 0, \"Minutes\": 1, \"Seconds\": 42.17}}</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints--get-the-heap-dump-of-the-application-response","title":"Get the heap dump of the application response =","text":"<p>client.get(\"/api/health/heapdump\") print(response.json())  # {\"memory_use\": {\"current\": \"123456\", \"peak\": \"789012\"}, \"heap_dump\": [{\"filename\": \"main.py\", \"lineno\": 10, \"size\": 1234, \"count\": 1}, ...]} ```</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints.create_health_router","title":"<code>create_health_router(config)</code>","text":"<p>Create a health router with the following endpoints:</p> <ul> <li> <p><code>/status</code>: Returns the status of the application. This endpoint can be   enabled or disabled using the <code>enable_status_endpoint</code> key in the   configuration.</p> </li> <li> <p><code>/uptime</code>: Returns the uptime of the application. This endpoint can be   enabled or disabled using the <code>enable_uptime_endpoint</code> key in the   configuration.</p> </li> <li> <p><code>/heapdump</code>: Returns a heap dump of the application. This endpoint can be   enabled or disabled using the <code>enable_heapdump_endpoint</code> key in the   configuration.</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>A dictionary with the configuration for the endpoints.</p> required <p>Returns:</p> Name Type Description <code>APIRouter</code> <p>A FastAPI router with the configured endpoints.</p> Example <p>```python from FastAPI import FastAPI from dsg_lib import system_health_endpoints</p> <p>app = FastAPI()</p> Source code in <code>dsg_lib/system_health_endpoints.py</code> <pre><code>def create_health_router(config: dict):\n    \"\"\"\n    Create a health router with the following endpoints:\n\n    - `/status`: Returns the status of the application. This endpoint can be\n      enabled or disabled using the `enable_status_endpoint` key in the\n      configuration.\n\n    - `/uptime`: Returns the uptime of the application. This endpoint can be\n      enabled or disabled using the `enable_uptime_endpoint` key in the\n      configuration.\n\n    - `/heapdump`: Returns a heap dump of the application. This endpoint can be\n      enabled or disabled using the `enable_heapdump_endpoint` key in the\n      configuration.\n\n    Args:\n        config (dict): A dictionary with the configuration for the endpoints.\n        Each key should be the name of an endpoint (e.g.,\n        `enable_status_endpoint`) and the value should be a boolean indicating\n        whether the endpoint is enabled or not.\n\n    Returns:\n        APIRouter: A FastAPI router with the configured endpoints.\n\n    Example:\n        ```python from FastAPI import FastAPI from dsg_lib import\n        system_health_endpoints\n\n        app = FastAPI()\n\n        # User configuration config = {\n            \"enable_status_endpoint\": True, \"enable_uptime_endpoint\": True,\n            \"enable_heapdump_endpoint\": True,\n        }\n\n        # Health router health_router =\n        system_health_endpoints.create_health_router(config)\n        app.include_router(health_router, prefix=\"/api/health\",\n        tags=[\"system-health\"])\n\n        # Get the status of the application response =\n        client.get(\"/api/health/status\") print(response.json())  # {\"status\":\n        \"UP\"}\n\n        # Get the uptime of the application response =\n        client.get(\"/api/health/uptime\") print(response.json())  # {\"uptime\":\n        {\"Days\": 0, \"Hours\": 0, \"Minutes\": 1, \"Seconds\": 42.17}}\n\n        # Get the heap dump of the application response =\n        client.get(\"/api/health/heapdump\") print(response.json())  #\n        {\"memory_use\": {\"current\": \"123456\", \"peak\": \"789012\"}, \"heap_dump\":\n        [{\"filename\": \"main.py\", \"lineno\": 10, \"size\": 1234, \"count\": 1}, ...]}\n        ```\n    \"\"\"\n    # Try to import FastAPI, handle ImportError if FastAPI is not installed\n    try:\n        import fastapi\n        from fastapi import APIRouter, HTTPException, status\n        from fastapi.responses import ORJSONResponse\n    except ImportError:  # pragma: no cover\n        APIRouter = (\n            HTTPException\n        ) = status = ORJSONResponse = fastapi = None  # pragma: no cover\n\n    # Check FastAPI version\n    min_version = \"0.100.0\"  # replace with your minimum required version\n    if fastapi is not None and packaging_version.parse(\n        fastapi.__version__\n    ) &lt; packaging_version.parse(min_version):\n        raise ImportError(\n            f\"FastAPI version &gt;= {min_version} required, run `pip install --upgrade fastapi`\"\n        )  # pragma: no cover\n\n    # Store the start time of the application\n    app_start_time = time.time()\n\n    # TODO: determine method to shutdown/restart python application\n\n    status_response = generate_code_dict([400, 405, 500], description_only=False)\n\n    tracemalloc.start()\n    # Create a new router\n    router = APIRouter()\n\n    # Check if the status endpoint is enabled in the configuration\n    if config.get(\"enable_status_endpoint\", True):\n        # Define the status endpoint\n        @router.get(\n            \"/status\",\n            tags=[\"system-health\"],\n            status_code=status.HTTP_200_OK,\n            response_class=ORJSONResponse,\n            responses=status_response,\n        )\n        async def health_status():\n            \"\"\"\n            Returns the status of the application.\n\n            This endpoint returns a dictionary with the status of the\n            application. If the application is running, it will return\n            `{\"status\": \"UP\"}`.\n\n            Returns:\n                dict: A dictionary with the status of the application. The\n                dictionary has a single key, \"status\", and the value is a string\n                that indicates the status of the application.\n\n            Raises:\n                HTTPException: If there is an error while getting the status of\n                the application.\n\n            Example:\n                ```python from FastAPI import FastAPI from dsg_lib import\n                system_health_endpoints\n\n                app = FastAPI()\n\n                # User configuration config = {\n                    \"enable_status_endpoint\": True, \"enable_uptime_endpoint\":\n                    False, \"enable_heapdump_endpoint\": False,\n                }\n\n                # Health router health_router =\n                system_health_endpoints.create_health_router(config)\n                app.include_router(health_router, prefix=\"/api/health\",\n                tags=[\"system-health\"])\n\n                # Get the status of the application response =\n                client.get(\"/api/health/status\") print(response.json())  #\n                {\"status\": \"UP\"} ```\n            \"\"\"\n            # Log the status request\n            logger.info(\"Health status of up returned\")\n            # Return a dictionary with the status of the application\n            return {\"status\": \"UP\"}\n\n    # Check if the uptime endpoint is enabled in the configuration\n    if config.get(\"enable_uptime_endpoint\", True):\n        # Define the uptime endpoint\n        @router.get(\"/uptime\", response_class=ORJSONResponse, responses=status_response)\n        async def get_uptime():\n            \"\"\"\n            Calculate and return the uptime of the application.\n\n            This endpoint returns a dictionary with the uptime of the\n            application. The uptime is calculated from the time the application\n            was started and is returned in a dictionary with the keys \"Days\",\n            \"Hours\", \"Minutes\", and \"Seconds\".\n\n            Returns:\n                dict: A dictionary with the uptime of the application. The\n                dictionary has keys for \"Days\", \"Hours\", \"Minutes\", and\n                \"Seconds\".\n\n            Raises:\n                HTTPException: If there is an error while calculating the uptime\n                of the application.\n\n            Example:\n                ```python from FastAPI import FastAPI from dsg_lib import\n                system_health_endpoints\n\n                app = FastAPI()\n\n                # User configuration config = {\n                    \"enable_status_endpoint\": False, \"enable_uptime_endpoint\":\n                    True, \"enable_heapdump_endpoint\": False,\n                }\n\n                # Health router health_router =\n                system_health_endpoints.create_health_router(config)\n                app.include_router(health_router, prefix=\"/api/health\",\n                tags=[\"system-health\"])\n\n                # Get the uptime of the application response =\n                client.get(\"/api/health/uptime\") print(response.json())  #\n                {\"uptime\": {\"Days\": 0, \"Hours\": 0, \"Minutes\": 1, \"Seconds\":\n                42.17}} ```\n            \"\"\"\n            # Calculate the total uptime in seconds This is done by subtracting\n            # the time when the application started from the current time\n            uptime_seconds = time.time() - app_start_time\n\n            # Convert the uptime from seconds to days, hours, minutes, and\n            # seconds\n            days, rem = divmod(uptime_seconds, 86400)\n            hours, rem = divmod(rem, 3600)\n            minutes, seconds = divmod(rem, 60)\n\n            # Log the uptime\n            logger.info(\n                f\"Uptime: {int(days)} days, {int(hours)} hours, {int(minutes)} minutes, {round(seconds, 2)} seconds\"\n            )\n\n            # Return a dictionary with the uptime The dictionary has keys for\n            # days, hours, minutes, and seconds\n            return {\n                \"uptime\": {\n                    \"Days\": int(days),\n                    \"Hours\": int(hours),\n                    \"Minutes\": int(minutes),\n                    \"Seconds\": round(seconds, 2),\n                }\n            }\n\n    if config.get(\"enable_heapdump_endpoint\", True):\n\n        @router.get(\n            \"/heapdump\", response_class=ORJSONResponse, responses=status_response\n        )\n        async def get_heapdump():\n            \"\"\"\n            Returns a heap dump of the application.\n\n            This endpoint returns a snapshot of the current memory usage of the\n            application. The heap dump is a list of dictionaries, each\n            representing a line of code. Each dictionary includes the filename,\n            line number, size of memory consumed, and the number of times the\n            line is referenced.\n\n            Returns:\n                dict: A dictionary with the current and peak memory usage, and\n                the heap dump of the application. The dictionary has two keys,\n                \"memory_use\" and \"heap_dump\". The \"memory_use\" key contains a\n                dictionary with the current and peak memory usage. The\n                \"heap_dump\" key contains a list of dictionaries, each\n                representing a line of code.\n\n            Raises:\n                HTTPException: If there is an error while getting the heap dump\n                of the application.\n\n            Example:\n                ```python from FastAPI import FastAPI from dsg_lib import\n                system_health_endpoints\n\n                app = FastAPI()\n\n                # User configuration config = {\n                    \"enable_status_endpoint\": False, \"enable_uptime_endpoint\":\n                    False, \"enable_heapdump_endpoint\": True,\n                }\n\n                # Health router health_router =\n                system_health_endpoints.create_health_router(config)\n                app.include_router(health_router, prefix=\"/api/health\",\n                tags=[\"system-health\"])\n\n                # Get the heap dump of the application response =\n                client.get(\"/api/health/heapdump\") print(response.json())  #\n                {\"memory_use\": {\"current\": \"123456\", \"peak\": \"789012\"},\n                \"heap_dump\": [{\"filename\": \"main.py\", \"lineno\": 10, \"size\":\n                1234, \"count\": 1}, ...]} ```\n            \"\"\"\n\n            try:\n                # Take a snapshot of the current memory usage\n                snapshot = tracemalloc.take_snapshot()\n                # Get the top 10 lines consuming memory\n                top_stats = snapshot.statistics(\"traceback\")\n\n                heap_dump = []\n                for stat in top_stats[:10]:\n                    # Get the first frame from the traceback\n                    frame = stat.traceback[0]\n                    # Add the frame to the heap dump\n                    heap_dump.append(\n                        {\n                            \"filename\": frame.filename,\n                            \"lineno\": frame.lineno,\n                            \"size\": stat.size,\n                            \"count\": stat.count,\n                        }\n                    )\n\n                logger.debug(f\"Heap dump returned {heap_dump}\")\n                memory_use = tracemalloc.get_traced_memory()\n                return {\n                    \"memory_use\": {\n                        \"current\": f\"{memory_use[0]:,}\",\n                        \"peak\": f\"{memory_use[1]:,}\",\n                    },\n                    \"heap_dump\": heap_dump,\n                }\n            except Exception as ex:\n                logger.error(f\"Error in get_heapdump: {ex}\")\n                raise HTTPException(\n                    status_code=500, detail=f\"Error in get_heapdump: {ex}\"\n                )\n\n    return router\n</code></pre>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints.create_health_router--user-configuration-config","title":"User configuration config = {","text":"<pre><code>\"enable_status_endpoint\": True, \"enable_uptime_endpoint\": True,\n\"enable_heapdump_endpoint\": True,\n</code></pre> <p>}</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints.create_health_router--health-router-health_router","title":"Health router health_router =","text":"<p>system_health_endpoints.create_health_router(config) app.include_router(health_router, prefix=\"/api/health\", tags=[\"system-health\"])</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints.create_health_router--get-the-status-of-the-application-response","title":"Get the status of the application response =","text":"<p>client.get(\"/api/health/status\") print(response.json())  # {\"status\": \"UP\"}</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints.create_health_router--get-the-uptime-of-the-application-response","title":"Get the uptime of the application response =","text":"<p>client.get(\"/api/health/uptime\") print(response.json())  # {\"uptime\": {\"Days\": 0, \"Hours\": 0, \"Minutes\": 1, \"Seconds\": 42.17}}</p>"},{"location":"endpoints/system_health_endpoints/#dsg_lib.system_health_endpoints.create_health_router--get-the-heap-dump-of-the-application-response","title":"Get the heap dump of the application response =","text":"<p>client.get(\"/api/health/heapdump\") print(response.json())  # {\"memory_use\": {\"current\": \"123456\", \"peak\": \"789012\"}, \"heap_dump\": [{\"filename\": \"main.py\", \"lineno\": 10, \"size\": 1234, \"count\": 1}, ...]} ```</p>"},{"location":"functions/calendar_functions/","title":"Reference","text":""},{"location":"functions/calendar_functions/#dsg_lib.calendar_functions","title":"<code>dsg_lib.calendar_functions</code>","text":"<p>This module provides two main functions to convert between month numbers and their corresponding names.</p> <p>Functions:</p> Name Description <code>get_month</code> <p>int) -&gt; str: Converts an integer month number to its corresponding month name.</p> <p>Args:     month (int): An integer between 1 and 12 representing the month     number.</p> <p>Returns:     str: The full name of the month corresponding to the input month     number.          If the input is not within the range of 1-12, returns \"Invalid          month number\". If the input is not an integer, returns \"Invalid          input, integer is required\".</p> <code>get_month_number</code> <p>str) -&gt; int: Converts a month name to its corresponding month number.</p> <p>Args:     month_name (str): A string containing the full name of a month.</p> <p>Returns:     int: The month number corresponding to the input month name.          If the input is not a valid month name, returns -1. If the          input is not a string, returns \"Invalid input, string is          required\".</p> <p>Example: <code>python from dsg_lib.calendar_functions import get_month, get_month_number print(get_month(1))  # Outputs: 'January' print(get_month_number('January'))  # Outputs: 1</code></p> <p>This module is part of the dsg_lib package and is used for handling and converting between month numbers and names.</p>"},{"location":"functions/calendar_functions/#dsg_lib.calendar_functions.get_month","title":"<code>get_month(month)</code>","text":"<p>Converts an integer month number to its corresponding month name.</p> <p>Parameters:</p> Name Type Description Default <code>month</code> <code>int</code> <p>An integer or integer-like float between 1 and 12</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The full name of the month corresponding to the input month number.  If the input is not within the range of 1-12, returns \"Invalid  month number\". If the input is not an integer or integer-like  float, returns \"Invalid input, integer is required\".</p> Source code in <code>dsg_lib/calendar_functions.py</code> <pre><code>def get_month(month: int) -&gt; str:\n    \"\"\"\n    Converts an integer month number to its corresponding month name.\n\n    Args:\n        month (int): An integer or integer-like float between 1 and 12\n        representing the month number.\n\n    Returns:\n        str: The full name of the month corresponding to the input month number.\n             If the input is not within the range of 1-12, returns \"Invalid\n             month number\". If the input is not an integer or integer-like\n             float, returns \"Invalid input, integer is required\".\n    \"\"\"\n\n    # Define a tuple containing the names of all months\n    months = (\n        \"January\",\n        \"February\",\n        \"March\",\n        \"April\",\n        \"May\",\n        \"June\",\n        \"July\",\n        \"August\",\n        \"September\",\n        \"October\",\n        \"November\",\n        \"December\",\n    )\n\n    # Convert integer-like floats to integers\n    if isinstance(month, float) and month.is_integer():\n        month = int(month)\n\n    # Check if the input month is an integer\n    if not isinstance(month, int):\n        logger.error(\"Invalid input: %s, integer is required\", month)\n        return \"Invalid input, integer is required\"\n\n    # Check if the input month is within the range of 1-12\n    if 1 &lt;= month &lt;= 12:\n        logger.info(\"Returning month name for month number: %s\", month)\n        return months[month - 1]\n    else:\n        logger.error(\n            \"Invalid input: %s, month number should be between 1 and 12\", month\n        )\n        return \"Invalid month number\"\n</code></pre>"},{"location":"functions/calendar_functions/#dsg_lib.calendar_functions.get_month_number","title":"<code>get_month_number(month_name)</code>","text":"<p>Converts a month name to its corresponding month number.</p> <p>Parameters:</p> Name Type Description Default <code>month_name</code> <code>str</code> <p>A string containing the full name of a month.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The month number corresponding to the input month name.  If the input is not a valid month name or not a string, returns -1.</p> Source code in <code>dsg_lib/calendar_functions.py</code> <pre><code>def get_month_number(month_name: str) -&gt; int:\n    \"\"\"\n    Converts a month name to its corresponding month number.\n\n    Args:\n        month_name (str): A string containing the full name of a month.\n\n    Returns:\n        int: The month number corresponding to the input month name.\n             If the input is not a valid month name or not a string, returns -1.\n    \"\"\"\n\n    # Define a dictionary mapping month names to month numbers\n    month_dict = {\n        \"January\": 1,\n        \"February\": 2,\n        \"March\": 3,\n        \"April\": 4,\n        \"May\": 5,\n        \"June\": 6,\n        \"July\": 7,\n        \"August\": 8,\n        \"September\": 9,\n        \"October\": 10,\n        \"November\": 11,\n        \"December\": 12,\n    }\n\n    # Check if the input month name is a string\n    if not isinstance(month_name, str):\n        logger.error(\"Invalid input, string is required\")\n        return -1\n\n    # Convert the input string to title case and remove leading/trailing spaces\n    month_name = month_name.strip().title()\n\n    # Check if the input month name is a valid key in the dictionary\n    if month_name in month_dict:\n        return month_dict[month_name]\n    else:\n        logger.error(\"Invalid month name: %s\", month_name)\n        return -1\n</code></pre>"},{"location":"functions/file_functions/","title":"Reference","text":""},{"location":"functions/file_functions/#dsg_lib.file_functions","title":"<code>dsg_lib.file_functions</code>","text":"<p>file_functions.py</p> <p>This module provides a function to delete a file with a specified name from a specified directory.</p> <p>Functions:</p> Name Description <code>delete_file</code> <p>str) -&gt; str: Deletes a file with the specified file name from the directory specified by the <code>directory_to_files</code> variable. The file type is determined by the file extension, and the file is deleted from the subdirectory corresponding to the file type.</p> <p>Args:     file_name (str): The name of the file to be deleted.</p> <p>Returns:     str: A string indicating that the file has been deleted.</p> <p>Raises:     TypeError: If the file name is not a string. ValueError: If the file     name contains a forward slash or backslash, or if the file type is     not supported. FileNotFoundError: If the file does not exist.</p> <p>Example: <code>python from dsg_lib import file_functions file_functions.delete_file(\"test.csv\")  # Outputs: 'complete'</code></p>"},{"location":"functions/file_functions/#dsg_lib.file_functions.create_sample_files","title":"<code>create_sample_files(file_name, sample_size)</code>","text":"<p>Create sample CSV and JSON files with random data.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The base name for the sample files (without extension).</p> required <code>sample_size</code> <code>int</code> <p>The number of rows to generate for the sample files.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs while creating the sample files.</p> <p>Example: <code>python from dsg_lib import file_functions file_functions.create_sample_files(\"test\", 100)  # Creates 'test.csv' and 'test.json' each with 100 rows of random data</code></p> Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def create_sample_files(file_name: str, sample_size: int) -&gt; None:\n    \"\"\"\n    Create sample CSV and JSON files with random data.\n\n    Args:\n        file_name (str): The base name for the sample files (without extension).\n        sample_size (int): The number of rows to generate for the sample files.\n\n    Returns:\n        None\n\n    Raises:\n        Exception: If an error occurs while creating the sample files.\n\n    Example: ```python from dsg_lib import file_functions\n    file_functions.create_sample_files(\"test\", 100)  # Creates 'test.csv' and\n    'test.json' each with 100 rows of random data ```\n    \"\"\"\n    logger.debug(f\"Creating sample files for {file_name} with {sample_size} rows.\")\n\n    try:\n        # Generate the CSV data\n        csv_header = [\"name\", \"birth_date\", \"number\"]\n        csv_data: List[List[str]] = [csv_header]\n\n        # Generate rows for CSV data\n        for i in range(1, sample_size + 1):\n            r_int: int = random.randint(0, len(first_name) - 1)\n            name = first_name[r_int]\n            row: List[str] = [name, generate_random_date(), str(i)]\n            csv_data.append(row)\n\n        # Save the CSV file\n        csv_file = f\"{file_name}.csv\"\n        save_csv(csv_file, csv_data)\n\n        # Generate the JSON data\n        json_data: List[dict] = []\n\n        # Generate rows for JSON data\n        for i in range(1, sample_size + 1):\n            r_int: int = random.randint(0, len(first_name) - 1)\n            name = first_name[r_int]\n            sample_dict: dict = {\n                \"name\": name,\n                \"birthday_date\": generate_random_date(),\n            }\n            json_data.append(sample_dict)\n\n        # Save the JSON file\n        json_file: str = f\"{file_name}.json\"\n        save_json(json_file, json_data)\n\n        # Log the data\n        logger.debug(f\"CSV Data: {csv_data}\")\n        logger.debug(f\"JSON Data: {json_data}\")\n\n    except Exception as e:  # pragma: no cover\n        logger.exception(\n            f\"Error occurred while creating sample files: {e}\"\n        )  # pragma: no cover\n        raise  # pragma: no cover\n</code></pre>"},{"location":"functions/file_functions/#dsg_lib.file_functions.delete_file","title":"<code>delete_file(file_name)</code>","text":"<p>Deletes a file with the specified file name from the specified directory. The file type is determined by the file extension.</p> <p>Parameters:</p> Name Type Description Default <code>directory_to_files</code> <code>str</code> <p>The directory where the file is located.</p> required <code>file_name</code> <code>str</code> <p>The name of the file to be deleted.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A message indicating whether the file has been deleted successfully</p> <code>str</code> <p>or an error occurred.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the directory or file name is not a string. ValueError: If</p> <code>is not supported. FileNotFoundError</code> <p>If the file does not exist.</p> <p>Example: <code>python from dsg_lib import file_functions file_functions.delete_file(\"test.csv\")  # Outputs: 'File deleted successfully'</code></p> Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def delete_file(file_name: str) -&gt; str:\n    \"\"\"\n    Deletes a file with the specified file name from the specified directory.\n    The file type is determined by the file extension.\n\n    Args:\n        directory_to_files (str): The directory where the file is located.\n        file_name (str): The name of the file to be deleted.\n\n    Returns:\n        str: A message indicating whether the file has been deleted successfully\n        or an error occurred.\n\n    Raises:\n        TypeError: If the directory or file name is not a string. ValueError: If\n        the file name contains a forward slash or backslash, or if the file type\n        is not supported. FileNotFoundError: If the file does not exist.\n\n    Example: ```python from dsg_lib import file_functions\n    file_functions.delete_file(\"test.csv\")  # Outputs: 'File deleted\n    successfully' ```\n    \"\"\"\n    logger.info(f\"Deleting file: {file_name}\")\n\n    # Check that the file name is a string\n    if not isinstance(file_name, str):\n        raise TypeError(f\"{file_name} is not a valid string\")\n\n    # Split the file name into its name and extension components\n    file_name, file_ext = os.path.splitext(file_name)\n\n    # Check that the file name does not contain a forward slash or backslash\n    if os.path.sep in file_name:\n        raise ValueError(f\"{file_name} cannot contain {os.path.sep}\")\n\n    # Check that the file type is supported\n    if file_ext not in directory_map:\n        raise ValueError(\n            f\"unsupported file type: {file_ext}. Supported file types are: {', '.join(directory_map.keys())}\"\n        )\n\n    # Construct the full file path\n    file_directory = Path.cwd() / directory_to_files / directory_map[file_ext]\n    file_path = file_directory / f\"{file_name}{file_ext}\"\n\n    # Check that the file exists\n    if not file_path.is_file():\n        raise FileNotFoundError(f\"file not found: {file_name}{file_ext}\")\n\n    # Delete the file\n    os.remove(file_path)\n    logger.info(f\"File {file_name}{file_ext} deleted from file path: {file_path}\")\n\n    # Return a string indicating that the file has been deleted\n    return \"complete\"\n</code></pre>"},{"location":"functions/file_functions/#dsg_lib.file_functions.generate_random_date","title":"<code>generate_random_date()</code>","text":"<p>Generate a random datetime string in the format yyyy-mm-dd hh:mm:ss.ffffff.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A randomly generated datetime string.</p> <p>Example: <code>python from dsg_lib import file_functions random_date = file_functions.generate_random_date()  # Returns: '1992-03-15 10:30:45.123456'</code></p> Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def generate_random_date() -&gt; str:\n    \"\"\"\n    Generate a random datetime string in the format yyyy-mm-dd hh:mm:ss.ffffff.\n\n    Returns:\n        str: A randomly generated datetime string.\n\n    Example: ```python from dsg_lib import file_functions random_date =\n    file_functions.generate_random_date()  # Returns: '1992-03-15\n    10:30:45.123456' ```\n    \"\"\"\n    # Define the minimum and maximum years for the date range\n    min_year: int = 1905\n    max_year: int = datetime.now().year\n\n    # Generate random values for the year, month, day, hour, minute, and second\n    year: int = random.randrange(min_year, max_year + 1)\n    month: int = random.randint(1, 12)\n    day: int = random.randint(1, 28)\n    hour: int = random.randint(0, 12)\n    minute: int = random.randint(0, 59)\n    second: int = random.randint(0, 59)\n\n    # Create a datetime object with the random values\n    date_value: datetime = datetime(year, month, day, hour, minute, second)\n\n    # Format the datetime string and return it\n    return f\"{date_value:%Y-%m-%d %H:%M:%S.%f}\"\n</code></pre>"},{"location":"functions/file_functions/#dsg_lib.file_functions.open_csv","title":"<code>open_csv(file_name, delimiter=',', quote_level='minimal', skip_initial_space=True)</code>","text":"<p>Opens a CSV file with the specified file name and returns its contents as a list of dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The name of the file to open. Should include the '.csv'</p> required <code>extension.</code> <code>delimiter (str</code> <p>The character used to separate</p> required <code>fields</code> <code>in the CSV file. Defaults to ','. quote_level (str</code> required <code>optional)</code> <p>Whether to skip initial whitespace in the CSV file. Defaults</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>The contents of the CSV file as a list of dictionaries. Each</p> <code>list</code> <p>dictionary represents a row in the CSV file, where the keys are column</p> <code>list</code> <p>names and the values are the data for those columns.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>file_name</code> is not a string. ValueError: If <code>quote_level</code></p> <code>is not a valid level. FileNotFoundError</code> <p>If the file does not exist.</p> <p>Example: <code>python from dsg_lib import file_functions data = file_functions.open_csv(\"test.csv\", delimiter=\";\", quote_level=\"all\", skip_initial_space=False)  # Returns: [{'column1': 'value1', 'column2': 'value2'}]</code></p> Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def open_csv(\n    file_name: str,\n    delimiter: str = \",\",\n    quote_level: str = \"minimal\",\n    skip_initial_space: bool = True,\n) -&gt; list:\n    \"\"\"\n    Opens a CSV file with the specified file name and returns its contents as a\n    list of dictionaries.\n\n    Args:\n        file_name (str): The name of the file to open. Should include the '.csv'\n        extension. delimiter (str, optional): The character used to separate\n        fields in the CSV file. Defaults to ','. quote_level (str, optional):\n        The quoting level used in the CSV file. Valid levels are \"none\",\n        \"minimal\", and \"all\". Defaults to \"minimal\". skip_initial_space (bool,\n        optional): Whether to skip initial whitespace in the CSV file. Defaults\n        to True.\n\n    Returns:\n        list: The contents of the CSV file as a list of dictionaries. Each\n        dictionary represents a row in the CSV file, where the keys are column\n        names and the values are the data for those columns.\n\n    Raises:\n        TypeError: If `file_name` is not a string. ValueError: If `quote_level`\n        is not a valid level. FileNotFoundError: If the file does not exist.\n\n    Example: ```python from dsg_lib import file_functions data =\n    file_functions.open_csv(\"test.csv\", delimiter=\";\", quote_level=\"all\",\n    skip_initial_space=False)  # Returns: [{'column1': 'value1', 'column2':\n    'value2'}] ```\n    \"\"\"\n    # A dictionary that maps quote levels to csv quoting constants\n    quote_levels = {\n        \"none\": csv.QUOTE_NONE,\n        \"minimal\": csv.QUOTE_MINIMAL,\n        \"all\": csv.QUOTE_ALL,\n    }\n\n    # Check that file name is a string\n    if not isinstance(file_name, str):\n        error = f\"{file_name} is not a valid string\"\n        logger.error(error)\n        raise TypeError(error)\n\n    # Check that quote level is valid\n    quote_level = quote_level.lower()\n    if quote_level not in quote_levels:\n        error = f\"Invalid quote level: {quote_level}. Valid levels are: {', '.join(quote_levels)}\"\n        logger.error(error)\n        raise ValueError(error)\n    quoting = quote_levels[quote_level]\n\n    # Add extension to file name and create file path\n    file_name = f\"{file_name}.csv\"\n    file_directory = Path.cwd().joinpath(directory_to_files).joinpath(\"csv\")\n    file_path = file_directory.joinpath(file_name)\n\n    # Check that file exists\n    if not file_path.is_file():\n        error = f\"File not found: {file_path}\"\n        logger.error(error)\n        raise FileNotFoundError(error)\n\n    # Read CSV file\n    data = []\n    with file_path.open(encoding=\"utf-8\") as f:\n        reader = csv.DictReader(\n            f,\n            delimiter=delimiter,\n            quoting=quoting,\n            skipinitialspace=skip_initial_space,\n        )\n        for row in reader:\n            data.append(dict(row))\n\n    logger.info(f\"File opened: {file_name}\")\n    return data\n</code></pre>"},{"location":"functions/file_functions/#dsg_lib.file_functions.open_json","title":"<code>open_json(file_name)</code>","text":"<p>Open a JSON file and load its contents into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The name of the JSON file to open.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The contents of the JSON file as a dictionary.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the file name is not a string. FileNotFoundError: If the</p> Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def open_json(file_name: str) -&gt; dict:\n    \"\"\"\n    Open a JSON file and load its contents into a dictionary.\n\n    Args:\n        file_name (str): The name of the JSON file to open.\n\n    Returns:\n        dict: The contents of the JSON file as a dictionary.\n\n    Raises:\n        TypeError: If the file name is not a string. FileNotFoundError: If the\n        file does not exist.\n    \"\"\"\n    # Check if file name is a string\n    if not isinstance(file_name, str):\n        error = f\"{file_name} is not a valid string\"\n        logger.error(error)\n        raise TypeError(error)\n\n    file_directory = Path(directory_to_files) / directory_map[\".json\"]\n    file_save = file_directory / file_name\n\n    # Check if path correct\n    if not file_save.is_file():\n        error = f\"file not found error: {file_save}\"\n        logger.exception(error)\n        raise FileNotFoundError(error)\n\n    # open file\n    with open(file_save) as read_file:\n        # load file into data variable\n        result = json.load(read_file)\n\n    logger.info(f\"File Opened: {file_name}\")\n    return result\n</code></pre>"},{"location":"functions/file_functions/#dsg_lib.file_functions.open_text","title":"<code>open_text(file_name)</code>","text":"<p>Opens a text file with the specified file name and returns its contents as a string.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The name of the file to open. Should include the '.txt'</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The contents of the text file as a string.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the <code>file_name</code> parameter is not a string or contains a</p> <code>forward slash. FileNotFoundError</code> <p>If the file does not exist.</p> <p>Example: <code>python from dsg_lib import file_functions data = file_functions.open_text(\"test.txt\")  # Returns: 'This is a test text file.'</code></p> Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def open_text(file_name: str) -&gt; str:\n    \"\"\"\n    Opens a text file with the specified file name and returns its contents as a\n    string.\n\n    Args:\n        file_name (str): The name of the file to open. Should include the '.txt'\n        extension.\n\n    Returns:\n        str: The contents of the text file as a string.\n\n    Raises:\n        TypeError: If the `file_name` parameter is not a string or contains a\n        forward slash. FileNotFoundError: If the file does not exist.\n\n    Example: ```python from dsg_lib import file_functions data =\n    file_functions.open_text(\"test.txt\")  # Returns: 'This is a test text file.'\n    ```\n    \"\"\"\n    # Replace backslashes with forward slashes in the file name\n    if \"\\\\\" in file_name:  # pragma: no cover\n        file_name = file_name.replace(\"\\\\\", \"/\")  # pragma: no cover\n\n    # Check that file_name does not contain invalid characters\n    if \"/\" in file_name:\n        logger.error(f\"{file_name} cannot contain /\")\n        raise TypeError(f\"{file_name} cannot contain /\")\n\n    # Get the path to the text directory and the file path\n    file_directory = os.path.join(directory_to_files, \"text\")\n    file_path = Path.cwd().joinpath(file_directory, file_name)\n\n    # Check if the file exists\n    if not file_path.is_file():\n        raise FileNotFoundError(f\"file not found error: {file_path}\")\n\n    # Open the file and read the data\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        data = file.read()\n\n    logger.info(f\"File opened: {file_path}\")\n    return data\n</code></pre>"},{"location":"functions/file_functions/#dsg_lib.file_functions.save_csv","title":"<code>save_csv(file_name, data, root_folder=None, delimiter=',', quotechar='\"')</code>","text":"<p>Saves a list of dictionaries as a CSV file with the specified file name in the specified directory. Each dictionary in the list should represent a row in the CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The name of the file to save the data in. Should</p> required <code>include</code> <code>the '.csv' extension. data (list</code> <p>The data to be saved. Each</p> required <code>optional)</code> <p>The root directory where the file will be saved. If None, the</p> required <code>(str,</code> <code>optional</code> <p>The character used to separate fields in the CSV file.</p> required <code>Defaults</code> <code>to ','. quotechar (str</code> <p>The character used to quote</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A message indicating whether the file has been saved successfully</p> <code>str</code> <p>or an error occurred.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the data is not a list, or the file name, delimiter, or</p> <code>quotechar is not a string. ValueError</code> <p>If the file name does not end</p> <p>Example: <code>python from dsg_lib import file_functions data = [{\"column1\": \"value1\", \"column2\": \"value2\"}] file_functions.save_csv(\"test.csv\", data, \"/path/to/directory\", delimiter=\";\", quotechar=\"'\")  # Saves data to '/path/to/directory/test.csv'</code></p> Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def save_csv(\n    file_name: str,\n    data: list,\n    root_folder: str = None,\n    delimiter: str = \",\",\n    quotechar: str = '\"',\n) -&gt; str:\n    \"\"\"\n    Saves a list of dictionaries as a CSV file with the specified file name in\n    the specified directory. Each dictionary in the list should represent a row\n    in the CSV file.\n\n    Args:\n        file_name (str): The name of the file to save the data in. Should\n        include the '.csv' extension. data (list): The data to be saved. Each\n        element of the list should be a dictionary where the keys are column\n        names and the values are the data for those columns. root_folder (str,\n        optional): The root directory where the file will be saved. If None, the\n        file will be saved in the current directory. Defaults to None. delimiter\n        (str, optional): The character used to separate fields in the CSV file.\n        Defaults to ','. quotechar (str, optional): The character used to quote\n        fields in the CSV file. Defaults to '\"'.\n\n    Returns:\n        str: A message indicating whether the file has been saved successfully\n        or an error occurred.\n\n    Raises:\n        TypeError: If the data is not a list, or the file name, delimiter, or\n        quotechar is not a string. ValueError: If the file name does not end\n        with '.csv'.\n\n    Example: ```python from dsg_lib import file_functions data = [{\"column1\":\n    \"value1\", \"column2\": \"value2\"}] file_functions.save_csv(\"test.csv\", data,\n    \"/path/to/directory\", delimiter=\";\", quotechar=\"'\")  # Saves data to\n    '/path/to/directory/test.csv' ```\n    \"\"\"\n    # Set the root folder to directory_to_files if None\n    if root_folder is None:\n        root_folder = directory_to_files\n\n    # Create the csv directory if it does not exist\n    csv_directory = Path(root_folder) / \"csv\"\n    csv_directory.mkdir(parents=True, exist_ok=True)\n\n    # Check that delimiter and quotechar are single characters\n    if len(delimiter) != 1:\n        raise TypeError(f\"{delimiter} can only be a single character\")\n    if len(quotechar) != 1:\n        raise TypeError(f\"{quotechar} can only be a single character\")\n\n    # Check that data is a list\n    if not isinstance(data, list):\n        raise TypeError(f\"{data} is not a valid list\")\n\n    # Check that file_name is a string and does not contain invalid characters\n    if not isinstance(file_name, str) or \"/\" in file_name or \"\\\\\" in file_name:\n        raise TypeError(f\"{file_name} is not a valid file name\")\n\n    # Add extension to file_name if needed\n    if not file_name.endswith(\".csv\"):\n        file_name += \".csv\"\n\n    # Create the file path\n    file_path = csv_directory / file_name\n\n    # Write data to file\n    with open(file_path, \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n        csv_writer = csv.writer(csv_file, delimiter=delimiter, quotechar=quotechar)\n        csv_writer.writerows(data)\n\n    logger.info(f\"File Create: {file_name}\")\n    return \"complete\"\n</code></pre>"},{"location":"functions/file_functions/#dsg_lib.file_functions.save_json","title":"<code>save_json(file_name, data, root_folder=None)</code>","text":"<p>Saves a dictionary or a list as a JSON file with the specified file name in the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The name of the file to save the data in. Should</p> required <code>include</code> <code>the '.json' extension. data (list or dict</code> <p>The data to be</p> required <code>saved.</code> <code>root_folder (str</code> <p>The root directory where the file</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A message indicating whether the file has been saved successfully</p> <code>str</code> <p>or an error occurred.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the data is not a list or a dictionary, or the file name</p> <code>or directory is not a string. ValueError</code> <p>If the file name contains a</p> <p>Example: ```python from dsg_lib import file_functions data = {\"key\": \"value\"} file_functions.save_json(\"test.json\", data, \"/path/to/directory\")</p>"},{"location":"functions/file_functions/#dsg_lib.file_functions.save_json--saves-data-to-pathtodirectorytestjson","title":"Saves data to '/path/to/directory/test.json' ```","text":"Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def save_json(file_name: str, data, root_folder: str = None) -&gt; str:\n    \"\"\"\n    Saves a dictionary or a list as a JSON file with the specified file name in\n    the specified directory.\n\n    Args:\n        file_name (str): The name of the file to save the data in. Should\n        include the '.json' extension. data (list or dict): The data to be\n        saved. root_folder (str, optional): The root directory where the file\n        will be saved. Defaults to None, which means the file will be saved in\n        the 'data' directory.\n\n    Returns:\n        str: A message indicating whether the file has been saved successfully\n        or an error occurred.\n\n    Raises:\n        TypeError: If the data is not a list or a dictionary, or the file name\n        or directory is not a string. ValueError: If the file name contains a\n        forward slash or backslash, or if the file name does not end with\n        '.json'.\n\n    Example: ```python from dsg_lib import file_functions data = {\"key\":\n    \"value\"} file_functions.save_json(\"test.json\", data, \"/path/to/directory\")\n    # Saves data to '/path/to/directory/test.json' ```\n    \"\"\"\n    try:\n        # Validate inputs\n        if not isinstance(data, (list, dict)):\n            raise TypeError(\n                f\"data must be a list or a dictionary instead of type {type(data)}\"\n            )\n        if \"/\" in file_name or \"\\\\\" in file_name:\n            raise ValueError(f\"{file_name} cannot contain / or \\\\\")\n\n        # Add extension if not present in file_name\n        if not file_name.endswith(\".json\"):  # pragma: no cover\n            file_name += \".json\"  # pragma: no cover\n\n        if root_folder is None:\n            root_folder = directory_to_files\n\n        # Determine directory\n        json_directory = Path(root_folder) / \"json\"\n\n        # Construct file path\n        file_path = json_directory / file_name\n\n        # Create the json directory if it does not exist\n        json_directory.mkdir(parents=True, exist_ok=True)\n\n        # Write data to file\n        with open(file_path, \"w\") as write_file:\n            json.dump(data, write_file)\n\n        # Log success message\n        logger.info(f\"File created: {file_path}\")\n\n        return \"File saved successfully\"\n\n    except (TypeError, ValueError) as e:\n        logger.error(f\"Error creating file {file_name}: {e}\")\n        raise\n</code></pre>"},{"location":"functions/file_functions/#dsg_lib.file_functions.save_text","title":"<code>save_text(file_name, data, root_folder=None)</code>","text":"<p>Saves a string of text to a file with the specified file name in the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The name of the file to save the data in. Should not</p> required <code>include</code> <code>the '.txt' extension. data (str</code> <p>The text data to be saved.</p> required <code>root_folder</code> <code>str</code> <p>The root directory where the file will be</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A message indicating whether the file has been saved successfully</p> <code>str</code> <p>or an error occurred.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the <code>data</code> parameter is not a string, or the <code>file_name</code></p> <code>contains a forward slash or backslash. FileNotFoundError</code> <p>If the</p> <p>Example: <code>python from dsg_lib import file_functions file_functions.save_text(\"test\", \"This is a test text file.\", \"/path/to/directory\")  # Saves data to '/path/to/directory/test.txt'</code></p> Source code in <code>dsg_lib/file_functions.py</code> <pre><code>def save_text(file_name: str, data: str, root_folder: str = None) -&gt; str:\n    \"\"\"\n    Saves a string of text to a file with the specified file name in the\n    specified directory.\n\n    Args:\n        file_name (str): The name of the file to save the data in. Should not\n        include the '.txt' extension. data (str): The text data to be saved.\n        root_folder (str, optional): The root directory where the file will be\n        saved. If None, the file will be saved in the current directory.\n        Defaults to None.\n\n    Returns:\n        str: A message indicating whether the file has been saved successfully\n        or an error occurred.\n\n    Raises:\n        TypeError: If the `data` parameter is not a string, or the `file_name`\n        contains a forward slash or backslash. FileNotFoundError: If the\n        directory does not exist.\n\n    Example: ```python from dsg_lib import file_functions\n    file_functions.save_text(\"test\", \"This is a test text file.\",\n    \"/path/to/directory\")  # Saves data to '/path/to/directory/test.txt' ```\n    \"\"\"\n    # If no root folder is provided, use the default directory\n    if root_folder is None:  # pragma: no cover\n        root_folder = directory_to_files  # pragma: no cover\n\n    # Determine the directory for text files\n    text_directory = Path(root_folder) / \"text\"\n\n    # Construct the file path for text files\n    file_path = text_directory / f\"{file_name}.txt\"\n\n    # Create the text directory if it does not exist\n    text_directory.mkdir(parents=True, exist_ok=True)\n\n    # Check that data is a string and that file_name does not contain invalid\n    # characters\n    if not isinstance(data, str):\n        logger.error(f\"{file_name} is not a valid string\")\n        raise TypeError(f\"{file_name} is not a valid string\")\n    elif \"/\" in file_name or \"\\\\\" in file_name:\n        logger.error(f\"{file_name} cannot contain \\\\ or /\")\n        raise ValueError(f\"{file_name} cannot contain \\\\ or /\")\n\n    # Open or create the file and write the data\n    with open(file_path, \"w+\", encoding=\"utf-8\") as file:\n        file.write(data)\n\n    logger.info(f\"File created: {file_path}\")\n    return \"complete\"\n</code></pre>"},{"location":"functions/folder_functions/","title":"Reference","text":""},{"location":"functions/folder_functions/#dsg_lib.folder_functions","title":"<code>dsg_lib.folder_functions</code>","text":"<p>This module contains functions for working with directories and files.</p> <p>Functions:</p> Name Description <code>last_data_files_changed</code> <p>Get the last modified file in a</p> <code>get_directory_list</code> <p>Get a list of directories in the</p> <code>specified directory. make_folder</code> <p>Make a folder in a</p> <code>specific directory. remove_folder</code> <p>Remove a folder from the</p> <p>Example: ```python from dsg_lib import folder_functions</p>"},{"location":"functions/folder_functions/#dsg_lib.folder_functions--get-the-last-modified-file-in-a-directory-time_stamp-file_path","title":"Get the last modified file in a directory time_stamp, file_path =","text":"<p>folder_functions.last_data_files_changed(\"/path/to/directory\")  # Returns: (datetime.datetime(2022, 1, 1, 12, 0, 0), '/path/to/directory/test.txt')</p>"},{"location":"functions/folder_functions/#dsg_lib.folder_functions--get-a-list-of-directories-in-the-specified-directory-directories","title":"Get a list of directories in the specified directory directories =","text":"<p>folder_functions.get_directory_list(\"/path/to/directory\")  # Returns: ['/path/to/directory/dir1', '/path/to/directory/dir2']</p>"},{"location":"functions/folder_functions/#dsg_lib.folder_functions--make-a-folder-in-a-specific-directory","title":"Make a folder in a specific directory","text":"<p>folder_functions.make_folder(\"/path/to/directory/new_folder\")  # Creates a new folder at '/path/to/directory/new_folder'</p>"},{"location":"functions/folder_functions/#dsg_lib.folder_functions--remove-a-folder-from-the-specified-directory","title":"Remove a folder from the specified directory","text":"<p>folder_functions.remove_folder(\"/path/to/directory/old_folder\")  # Removes the folder at '/path/to/directory/old_folder' ```</p>"},{"location":"functions/folder_functions/#dsg_lib.folder_functions.get_directory_list","title":"<code>get_directory_list(file_directory)</code>","text":"<p>Get a list of directories in the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>file_directory</code> <code>str</code> <p>The path of the directory to check.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of directories in the specified directory.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the directory does not exist.</p> <p>Example: <code>python from dsg_lib import file_functions directories = file_functions.get_directory_list(\"/path/to/directory\")  # Returns: ['/path/to/directory/dir1', '/path/to/directory/dir2']</code></p> Source code in <code>dsg_lib/folder_functions.py</code> <pre><code>def get_directory_list(file_directory: str) -&gt; List[str]:\n    \"\"\"\n    Get a list of directories in the specified directory.\n\n    Args:\n        file_directory (str): The path of the directory to check.\n\n    Returns:\n        List[str]: A list of directories in the specified directory.\n\n    Raises:\n        FileNotFoundError: If the directory does not exist.\n\n    Example: ```python from dsg_lib import file_functions directories =\n    file_functions.get_directory_list(\"/path/to/directory\")  # Returns:\n    ['/path/to/directory/dir1', '/path/to/directory/dir2'] ```\n    \"\"\"\n    # Create a Path object for the specified directory\n    file_path = Path.cwd().joinpath(file_directory)\n\n    try:\n        # Use a list comprehension to create a list of directories in the\n        # specified directory\n        direct_list = [x for x in file_path.iterdir() if x.is_dir()]\n\n        # Log a message indicating that the list of directories was retrieved\n        logger.info(f\"Retrieved list of directories: {file_directory}\")\n\n        # Return the list of directories\n        return direct_list\n\n    except FileNotFoundError as err:\n        # Log an error message if the specified directory does not exist\n        logger.error(err)\n</code></pre>"},{"location":"functions/folder_functions/#dsg_lib.folder_functions.last_data_files_changed","title":"<code>last_data_files_changed(directory_path)</code>","text":"<p>Get the last modified file in a directory and return its modification time and path.</p> <p>Parameters:</p> Name Type Description Default <code>directory_path</code> <code>str</code> <p>The path of the directory to check.</p> required <p>Returns:</p> Type Description <code>datetime</code> <p>Tuple[datetime, str]: A tuple containing the modification time and path</p> <code>str</code> <p>of the last modified file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the directory does not exist.</p> <p>Example: <code>python from dsg_lib import file_functions time_stamp, file_path = file_functions.last_data_files_changed(\"/path/to/directory\")  # Returns: (datetime.datetime(2022, 1, 1, 12, 0, 0), '/path/to/directory/test.txt')</code></p> Source code in <code>dsg_lib/folder_functions.py</code> <pre><code>def last_data_files_changed(directory_path: str) -&gt; Tuple[datetime, str]:\n    \"\"\"\n    Get the last modified file in a directory and return its modification time\n    and path.\n\n    Args:\n        directory_path (str): The path of the directory to check.\n\n    Returns:\n        Tuple[datetime, str]: A tuple containing the modification time and path\n        of the last modified file.\n\n    Raises:\n        FileNotFoundError: If the directory does not exist.\n\n    Example: ```python from dsg_lib import file_functions time_stamp, file_path\n    = file_functions.last_data_files_changed(\"/path/to/directory\")  # Returns:\n    (datetime.datetime(2022, 1, 1, 12, 0, 0), '/path/to/directory/test.txt') ```\n    \"\"\"\n    try:\n        # Use a generator expression to find the last modified file in the\n        # directory\n        time, file_path = max((f.stat().st_mtime, f) for f in directory_path.iterdir())\n\n        # Convert the modification time to a datetime object\n        time_stamp = datetime.fromtimestamp(time)\n\n        # Log a message to indicate that the directory was checked for the last\n        # modified file\n        logger.info(f\"Directory checked for last change: {directory_path}\")\n\n        # Return the modification time and path of the last modified file\n        return time_stamp, file_path\n\n    except Exception as err:\n        # Log an error message if an exception occurs, and return a default\n        # value to indicate an error\n        logger.error(err)\n        return None, None\n</code></pre>"},{"location":"functions/folder_functions/#dsg_lib.folder_functions.remove_folder","title":"<code>remove_folder(file_directory)</code>","text":"<p>Remove a folder from the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>file_directory</code> <code>str</code> <p>The directory containing the folder to be removed.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified directory does not exist. OSError:</p> <p>Example: <code>python from dsg_lib import file_functions file_functions.remove_folder(\"/path/to/directory/old_folder\")  # Removes the folder at '/path/to/directory/old_folder'</code></p> Source code in <code>dsg_lib/folder_functions.py</code> <pre><code>def remove_folder(file_directory: str) -&gt; None:\n    \"\"\"\n    Remove a folder from the specified directory.\n\n    Args:\n        file_directory (str): The directory containing the folder to be removed.\n\n    Returns:\n        None.\n\n    Raises:\n        FileNotFoundError: If the specified directory does not exist. OSError:\n        If the specified folder could not be removed.\n\n    Example: ```python from dsg_lib import file_functions\n    file_functions.remove_folder(\"/path/to/directory/old_folder\")  # Removes the\n    folder at '/path/to/directory/old_folder' ```\n    \"\"\"\n    try:\n        # Create a Path object for the specified directory\n        path = Path(file_directory)\n\n        # Use the rmdir method of the Path object to remove the folder\n        path.rmdir()\n\n        # Log a message indicating that the folder was removed\n        logger.info(f\"Folder removed: {file_directory}\")\n\n    except FileNotFoundError as err:\n        # Log an error message if the specified directory does not exist\n        logger.error(err)\n\n        # Raise the FileNotFoundError exception to be handled by the calling\n        # code\n        raise\n\n    except OSError as err:\n        # Log an error message if the folder could not be removed\n        logger.error(err)\n\n        # Raise the OSError exception to be handled by the calling code\n        raise\n</code></pre>"},{"location":"functions/logging/","title":"Reference","text":""},{"location":"functions/logging/#dsg_lib.logging_config","title":"<code>dsg_lib.logging_config</code>","text":"<p>Configuration of loguru logging Includes interceptor for standard python logging All configuration values are optional and have defaults</p> <p>Usage Example: ```python from logging_config import config_log</p> <p>config_log(     logging_directory='logs',  # Directory where logs will be stored     log_name='app.log',  # Name of the log file logging_level='DEBUG',  #     Logging level log_rotation='100 MB',  # Log rotation size log_retention='30     days',  # Log retention period log_backtrace=True,  # Enable backtrace     log_format=\"{time:YYYY-MM-DD HH:mm:ss.SSSSSS} |     {level: &lt;8} |     {name}:{function}:{line} -     {message}\",  # Log format log_serializer=False,  # Disable     log serialization log_diagnose=True,  # Enable diagnose app_name='my_app',     # Application name append_app_name=True  # Append application name to the     log file name )</p> <p>logger.debug(\"This is a debug message\") logger.info(\"This is an info message\") logger.error(\"This is an error message\") logger.warning(\"This is a warning message\") logger.critical(\"This is a critical message\") ```</p>"},{"location":"functions/logging/#dsg_lib.logging_config.config_log","title":"<code>config_log(logging_directory='log', log_name='log.json', logging_level='INFO', log_rotation='100 MB', log_retention='30 days', log_backtrace=False, log_format=None, log_serializer=False, log_diagnose=False, app_name=None, append_app_name=False)</code>","text":"<p>Configure and set up a logger using the loguru package.</p> <p>Usage Example: ```python from logging_config import config_log</p>"},{"location":"functions/logging/#dsg_lib.logging_config.config_log--configure-the-logger-config_log","title":"Configure the logger config_log(","text":"<pre><code>logging_directory='logs',  # Directory where logs will be stored\nlog_name='app.log',  # Name of the log file logging_level='DEBUG',  #\nLogging level log_rotation='500 MB',  # Log rotation size\nlog_retention='10 days',  # Log retention period log_backtrace=True,  #\nEnable backtrace log_format=\"&lt;green&gt;{time:YYYY-MM-DD\nHH:mm:ss.SSSSSS}&lt;/green&gt; | &lt;level&gt;{level: &lt;8}&lt;/level&gt; |\n&lt;cyan&gt;{name}&lt;/cyan&gt;:&lt;cyan&gt;{function}&lt;/cyan&gt;:&lt;cyan&gt;{line}&lt;/cyan&gt; -\n&lt;level&gt;{message}&lt;/level&gt;\",  # Log format log_serializer=False,  #\nDisable log serialization log_diagnose=True,  # Enable diagnose\napp_name='my_app',  # Application name append_app_name=True  # Append\napplication name to the log file name\n</code></pre> <p>)</p>"},{"location":"functions/logging/#dsg_lib.logging_config.config_log--now-you-can-use-the-logger-in-your-application-loggerdebugthis-is-a","title":"Now you can use the logger in your application logger.debug(\"This is a","text":"<p>debug message\") logger.info(\"This is an info message\") logger.error(\"This is an error message\") This will configure the logger to log all messages with level DEBUG or higher to a file named 'debug.log'. ```</p> Source code in <code>dsg_lib/logging_config.py</code> <pre><code>def config_log(\n    logging_directory: str = \"log\",\n    log_name: str = \"log.json\",\n    logging_level: str = \"INFO\",\n    log_rotation: str = \"100 MB\",\n    log_retention: str = \"30 days\",\n    log_backtrace: bool = False,\n    log_format: str = None,\n    log_serializer: bool = False,\n    log_diagnose: bool = False,\n    app_name: str = None,\n    append_app_name: bool = False,\n):\n    \"\"\"\n    Configure and set up a logger using the loguru package.\n\n    Usage Example: ```python from logging_config import config_log\n\n    # Configure the logger config_log(\n        logging_directory='logs',  # Directory where logs will be stored\n        log_name='app.log',  # Name of the log file logging_level='DEBUG',  #\n        Logging level log_rotation='500 MB',  # Log rotation size\n        log_retention='10 days',  # Log retention period log_backtrace=True,  #\n        Enable backtrace log_format=\"&lt;green&gt;{time:YYYY-MM-DD\n        HH:mm:ss.SSSSSS}&lt;/green&gt; | &lt;level&gt;{level: &lt;8}&lt;/level&gt; |\n        &lt;cyan&gt;{name}&lt;/cyan&gt;:&lt;cyan&gt;{function}&lt;/cyan&gt;:&lt;cyan&gt;{line}&lt;/cyan&gt; -\n        &lt;level&gt;{message}&lt;/level&gt;\",  # Log format log_serializer=False,  #\n        Disable log serialization log_diagnose=True,  # Enable diagnose\n        app_name='my_app',  # Application name append_app_name=True  # Append\n        application name to the log file name\n    )\n\n    # Now you can use the logger in your application logger.debug(\"This is a\n    debug message\") logger.info(\"This is an info message\") logger.error(\"This is\n    an error message\") This will configure the logger to log all messages with\n    level DEBUG or higher to a file named 'debug.log'. ```\n    \"\"\"\n    # Set default log format if not provided\n    if log_format is None:  # pragma: no cover\n        if log_serializer:  # pragma: no cover\n            log_format = \"'time': '{time:YYYY-MM-DD HH:mm:ss.SSSSSS}', 'level': '{level: &lt;8}', 'name': '{name}', \\\n                'function': '{function}', 'line': '{line}', 'message': '{message}',\"  # pragma: no cover\n        else:  # pragma: no cover\n            log_format = \"&lt;green&gt;{time:YYYY-MM-DD HH:mm:ss.SSSSSS}&lt;/green&gt; | &lt;level&gt;{level: &lt;8}&lt;/level&gt; | &lt;cyan&gt;\\\n                {name}&lt;/cyan&gt;:&lt;cyan&gt;{function}&lt;/cyan&gt;:&lt;cyan&gt;{line}&lt;/cyan&gt; - &lt;level&gt;{message}&lt;/level&gt;\"  # pragma: no cover\n\n    # Validate logging level\n    log_levels: list = [\"DEBUG\", \"INFO\", \"ERROR\", \"WARNING\", \"CRITICAL\"]\n    if logging_level.upper() not in log_levels:\n        raise ValueError(\n            f\"Invalid logging level: {logging_level}. Valid levels are: {log_levels}\"\n        )\n\n    # Generate unique trace ID\n    trace_id: str = str(uuid4())\n    logger.configure(extra={\"app_name\": app_name, \"trace_id\": trace_id})\n\n    # Append app name to log format if provided\n    if app_name is not None:\n        log_format = \"app_name: {extra[app_name]}\"\n\n    # Remove any previously added sinks\n    logger.remove()\n\n    # Validate log file extension\n    if not log_name.endswith((\".log\", \".json\")):\n        error_message = f\"log_name must end with .log or .json - {log_name}\"\n        logging.error(error_message)\n        raise ValueError(error_message)\n\n    # Append app name to log file name if required\n    if append_app_name is True and app_name is not None:\n        log_name = log_name.replace(\".\", f\"_{app_name}.\")\n\n    # Construct log file path\n    log_path = Path.cwd().joinpath(logging_directory).joinpath(log_name)\n\n    # Add loguru logger with specified configuration\n    logger.add(\n        log_path,\n        level=logging_level.upper(),\n        format=log_format,\n        enqueue=True,\n        backtrace=log_backtrace,\n        rotation=log_rotation,\n        retention=log_retention,\n        compression=\"zip\",\n        serialize=log_serializer,\n        diagnose=log_diagnose,\n    )\n\n    class InterceptHandler(logging.Handler):\n        \"\"\"\n        Interceptor for standard logging.\n\n        This class intercepts standard Python logging messages and redirects\n        them to the Loguru logger. It is used as a handler for the standard\n        Python logger.\n\n        Attributes:\n            level (str): The minimum severity level of messages that this\n            handler should handle.\n\n        Usage Example: ```python from dsg_lib.logging_config import\n        InterceptHandler import logging\n\n        # Create a standard Python logger logger =\n        logging.getLogger('my_logger')\n\n        # Create an InterceptHandler handler = InterceptHandler()\n\n        # Add the InterceptHandler to the logger logger.addHandler(handler)\n\n        # Now, when you log a message using the standard Python logger, it will\n        be intercepted and redirected to the Loguru logger logger.info('This is\n        an info message') ```\n        \"\"\"\n\n        def emit(self, record):\n            # Get corresponding Loguru level if it exists\n            try:\n                level = logger.level(record.levelname).name\n            except ValueError:  # pragma: no cover\n                level = record.levelno  # pragma: no cover\n\n            # Find caller from where originated the logged message\n            frame, depth = logging.currentframe(), 2\n            while frame.f_code.co_filename == logging.__file__:  # pragma: no cover\n                frame = frame.f_back  # pragma: no cover\n                depth += 1  # pragma: no cover\n\n            # Log the message using loguru\n            logger.opt(depth=depth, exception=record.exc_info).log(\n                level, record.getMessage()\n            )  # pragma: no cover\n\n    # Configure standard logging to use interceptor handler\n    logging.basicConfig(handlers=[InterceptHandler()], level=logging_level.upper())\n\n    # Add interceptor handler to all existing loggers\n    for name in logging.root.manager.loggerDict:\n        logging.getLogger(name).addHandler(InterceptHandler())\n\n    # Set the root logger's level to the lowest level possible\n    logging.getLogger().setLevel(logging.NOTSET)\n</code></pre>"},{"location":"functions/regex/","title":"Reference","text":""},{"location":"functions/regex/#dsg_lib.patterns","title":"<code>dsg_lib.patterns</code>","text":"<p>This module contains functions for pattern searching in text using regular expressions.</p> <p>The main function in this module is <code>pattern_between_two_char</code>, which searches for all patterns between two characters in a given string. The function uses Python's built-in <code>re</code> module for regex searching and the <code>loguru</code> module for logging.</p> <p>Functions:</p> Name Description <code>pattern_between_two_char</code> <p>str, left_characters: str,</p> <code>right_characters</code> <p>str) -&gt; dict: Searches for all patterns between two characters (left and right) in a given string using regular expressions.</p> Example <p>```python from dsg_lib import patterns</p> <p>text = \"Hello, my name is 'John Doe' and I live in 'New York'.\" left_char = \"'\" right_char = \"'\"</p> <p>results = patterns.pattern_between_two_char(text, left_char, right_char)</p> <p>print(results) <code>This will output:</code>python {     'found': ['John Doe', 'New York'], 'matched_found': 2,     'pattern_parameters': {         'left_character': \"'\", 'right_character': \"'\", 'regex_pattern':         \"'(.+?)'\", 'text_string': \"Hello, my name is 'John Doe' and I live         in 'New York'.\"     } } ```</p>"},{"location":"functions/regex/#dsg_lib.patterns.pattern_between_two_char","title":"<code>pattern_between_two_char(text_string, left_characters, right_characters)</code>","text":"<p>Searches for all patterns between two characters (left and right) in a given string using regular expressions.</p> <p>This function takes a string and two characters as input, and returns a dictionary containing all patterns found between the two characters in the string. The dictionary also includes the number of matches found and the regex pattern used for searching.</p> <p>The function uses Python's built-in <code>re</code> module for regex searching and the <code>loguru</code> module for logging.</p> <p>Parameters:</p> Name Type Description Default <code>text_string</code> <code>str</code> <p>The string in which to search for patterns.</p> required <code>left_characters</code> <code>str</code> <p>The character(s) that appear(s) immediately to</p> required <code>the</code> <code>left of the desired pattern. right_characters (str</code> <p>The</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary with the following keys: - \"found\": a list of strings containing all patterns found. - \"matched_found\": the number of patterns found. - \"pattern_parameters\": a dictionary with the following keys:     - \"left_character\": the escaped left character string used to       build the regex pattern.     - \"right_character\": the escaped right character string used to       build the regex pattern.     - \"regex_pattern\": the final regex pattern used for searching.     - \"text_string\": the escaped input string used for searching.</p> Example <p>```python from dsg_lib import patterns</p> <p>text = \"Hello, my name is 'John Doe' and I live in 'New York'.\" left_char = \"'\" right_char = \"'\"</p> <p>results = patterns.pattern_between_two_char(text, left_char, right_char)</p> <p>print(results) <code>This will output:</code>python {     'found': ['John Doe', 'New York'], 'matched_found': 2,     'pattern_parameters': {         'left_character': \"'\", 'right_character': \"'\", 'regex_pattern':         \"'(.+?)'\", 'text_string': \"Hello, my name is 'John Doe' and I         live in 'New York'.\"     } } ```</p> Source code in <code>dsg_lib/patterns.py</code> <pre><code>def pattern_between_two_char(\n    text_string: str, left_characters: str, right_characters: str\n) -&gt; dict:\n    \"\"\"\n    Searches for all patterns between two characters (left and right) in a given\n    string using regular expressions.\n\n    This function takes a string and two characters as input, and returns a\n    dictionary containing all patterns found between the two characters in the\n    string. The dictionary also includes the number of matches found and the\n    regex pattern used for searching.\n\n    The function uses Python's built-in `re` module for regex searching and the\n    `loguru` module for logging.\n\n    Args:\n        text_string (str): The string in which to search for patterns.\n        left_characters (str): The character(s) that appear(s) immediately to\n        the left of the desired pattern. right_characters (str): The\n        character(s) that appear(s) immediately to the right of the desired\n        pattern.\n\n    Returns:\n        dict: A dictionary with the following keys:\n            - \"found\": a list of strings containing all patterns found.\n            - \"matched_found\": the number of patterns found.\n            - \"pattern_parameters\": a dictionary with the following keys:\n                - \"left_character\": the escaped left character string used to\n                  build the regex pattern.\n                - \"right_character\": the escaped right character string used to\n                  build the regex pattern.\n                - \"regex_pattern\": the final regex pattern used for searching.\n                - \"text_string\": the escaped input string used for searching.\n\n    Example:\n        ```python from dsg_lib import patterns\n\n        text = \"Hello, my name is 'John Doe' and I live in 'New York'.\"\n        left_char = \"'\" right_char = \"'\"\n\n        results = patterns.pattern_between_two_char(text, left_char, right_char)\n\n        print(results) ``` This will output: ```python {\n            'found': ['John Doe', 'New York'], 'matched_found': 2,\n            'pattern_parameters': {\n                'left_character': \"'\", 'right_character': \"'\", 'regex_pattern':\n                \"'(.+?)'\", 'text_string': \"Hello, my name is 'John Doe' and I\n                live in 'New York'.\"\n            }\n        }\n        ```\n    \"\"\"\n\n    if not left_characters or not right_characters:\n        raise ValueError(\n            f\"Left '{left_characters}' and/or Right '{right_characters}' characters must not be None or empty\"\n        )\n\n    try:\n        # Escape input strings to safely use them in regex pattern\n        esc_text = re.escape(text_string)\n        esc_left_char = re.escape(left_characters)\n        esc_right_char = re.escape(right_characters)\n\n        # Create a regex pattern that matches all substrings between target\n        # characters\n        pattern = f\"{esc_left_char}(.+?){esc_right_char}\"\n\n        # Replace \\w with . to match any printable UTF-8 character\n        pattern = pattern.replace(r\"\\w\", r\".\")\n\n        # Search for all patterns and store them in pattern_list variable\n        pattern_list = re.findall(pattern, esc_text)\n\n        # Create a dictionary to store match details\n        results: dict = {\n            \"found\": pattern_list,\n            \"matched_found\": len(pattern_list),\n            \"pattern_parameters\": {\n                \"left_character\": esc_left_char,\n                \"right_character\": esc_right_char,\n                \"regex_pattern\": pattern,\n                \"text_string\": esc_text,\n            },\n        }\n\n        # Log matched pattern(s) found using 'debug' log level\n        if len(pattern_list) &gt; 0:\n            logger.debug(f\"Matched pattern(s): {pattern_list}\")\n\n        # Log successful function execution using 'info' log level\n        logger.info(\"Successfully executed 'pattern_between_two_char' function\")\n        return results\n\n    except ValueError as e:  # pragma: no cover\n        # capture exception and return error in case of invalid input parameters\n        results: dict = {\n            \"error\": str(e),\n            \"matched_found\": 0,\n            \"pattern_parameters\": {\n                \"left_character\": left_characters,\n                \"right_character\": right_characters,\n                \"regex_pattern\": None,\n                \"text_string\": text_string,\n            },\n        }\n        # logger of regex error using 'critical' log level\n        logger.critical(f\"Failed to generate regex pattern with error: {e}\")\n        return results\n</code></pre>"},{"location":"recipes/asyncDatabase/","title":"Examples","text":"<p>Here are a few examples of how to use the database functions</p>"},{"location":"recipes/asyncDatabase/#asyncio-script-example","title":"Asyncio Script Example","text":"<p>Example of how to use in a script</p> <pre><code>import asyncio\nfrom sqlalchemy import select\nfrom dsg_lib import database_config, async_database, database_operations\n\n# Configuration\nconfig = {\n    \"database_uri\": \"sqlite+aiosqlite:///:memory:?cache=shared\",\n    \"echo\": False,\n    \"future\": True,\n    \"pool_recycle\": 3600,\n}\n\n# Create a DBConfig instance\ndb_config = database_config.DBConfig(config)\n\n# Create an AsyncDatabase instance\nasync_db = async_database.AsyncDatabase(db_config)\n\n# Create a DatabaseOperations instance\ndb_ops = database_operations.DatabaseOperations(async_db)\n\n# User class\nclass User(async_db.Base):\n    __tablename__ = \"users\"\n    first_name = Column(String, unique=False, index=True)\n    last_name = Column(String, unique=False, index=True)\n    email = Column(String, unique=True, index=True, nullable=True)\n\n# Async function to get all users\nasync def get_all_users():\n    # Create a select query\n    query = select(User)\n\n    # Execute the query and fetch all results\n    users = await db_ops.read_query(query)\n\n    # Print the users\n    for user in users:\n        print(f\"User: {user.first_name} {user.last_name}, Email: {user.email}\")\n\n# Run the async function\nasyncio.run(get_all_users())\n</code></pre>"},{"location":"recipes/asyncDatabase/#fastapi-example","title":"FastAPI Example","text":"<pre><code># -*- coding: utf-8 -*-\n\nfrom contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom fastapi.responses import RedirectResponse\nfrom loguru import logger\nfrom tqdm import tqdm\n\nfrom dsg_lib import logging_config\n\nlogging_config.config_log(\n    logging_level=\"Debug\", log_serializer=False, log_name=\"log.log\"\n)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    logger.info(\"starting up\")\n    # Create the tables in the database\n    await async_db.create_tables()\n\n    create_users = True\n    if create_users:\n        await create_a_bunch_of_users(single_entry=23, many_entries=100)\n    yield\n    logger.info(\"shutting down\")\n\n\n# Create an instance of the FastAPI class\napp = FastAPI(\n    title=\"FastAPI Example\",  # The title of the API\n    description=\"This is an example of a FastAPI application using the DevSetGo Toolkit.\",  # A brief description of the API\n    version=\"0.1.0\",  # The version of the API\n    docs_url=\"/docs\",  # The URL where the API documentation will be served\n    redoc_url=\"/redoc\",  # The URL where the ReDoc documentation will be served\n    openapi_url=\"/openapi.json\",  # The URL where the OpenAPI schema will be served\n    debug=True,  # Enable debug mode\n    middleware=[],  # A list of middleware to include in the application\n    routes=[],  # A list of routes to include in the application\n    lifespan=lifespan,\n)\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"\n    Root endpoint of API\n    Returns:\n        Redrects to openapi document\n    \"\"\"\n    # redirect to openapi docs\n    logger.info(\"Redirecting to OpenAPI docs\")\n    response = RedirectResponse(url=\"/docs\")\n    return response\n\nfrom sqlalchemy import Column, Delete, Select, String, Update\n\nfrom dsg_lib import (\n    async_database,\n    base_schema,\n    database_config,\n    database_operations,\n)\n\n# Create a DBConfig instance\nconfig = {\n    # \"database_uri\": \"postgresql+asyncpg://postgres:postgres@postgresdb/postgres\",\n    \"database_uri\": \"sqlite+aiosqlite:///:memory:?cache=shared\",\n    \"echo\": False,\n    \"future\": True,\n    # \"pool_pre_ping\": True,\n    # \"pool_size\": 10,\n    # \"max_overflow\": 10,\n    \"pool_recycle\": 3600,\n    # \"pool_timeout\": 30,\n}\n\ndb_config = database_config.DBConfig(config)\n# Create an AsyncDatabase instance\nasync_db = async_database.AsyncDatabase(db_config)\n\n# Create a DatabaseOperations instance\ndb_ops = database_operations.DatabaseOperations(async_db)\n\n\n# User class inherits from SchemaBase and async_db.Base\n# This class represents the User table in the database\nclass User(base_schema.SchemaBase, async_db.Base):\n    __tablename__ = \"users\"  # Name of the table in the database\n\n    # Define the columns of the table\n    first_name = Column(String, unique=False, index=True)  # First name of the user\n    last_name = Column(String, unique=False, index=True)  # Last name of the user\n    email = Column(\n        String, unique=True, index=True, nullable=True\n    )  # Email of the user, must be unique\n\nasync def create_a_bunch_of_users(single_entry=0, many_entries=0):\n    logger.info(f\"single_entry: {single_entry}\")\n    await async_db.create_tables()\n    # Create a list to hold the user data\n\n    # Create a loop to generate user data\n\n    for i in tqdm(range(single_entry), desc=\"executing one\"):\n        value = secrets.token_hex(16)\n        user = User(\n            first_name=f\"First{value}\",\n            last_name=f\"Last{value}\",\n            email=f\"user{value}@example.com\",\n        )\n        logger.info(f\"created_users: {user}\")\n        await db_ops.create_one(user)\n\n    users = []\n    # Create a loop to generate user data\n    for i in tqdm(range(many_entries), desc=\"executing many\"):\n        value_one = secrets.token_hex(4)\n        value_two = secrets.token_hex(8)\n        user = User(\n            first_name=f\"First{value_one}{i}{value_two}\",\n            last_name=f\"Last{value_one}{i}{value_two}\",\n            email=f\"user{value_one}{i}{value_two}@example.com\",\n        )\n        logger.info(f\"created_users: {user.first_name}\")\n        users.append(user)\n\n    # Use db_ops to add the users to the database\n    await db_ops.create_many(users)\n\n\n@app.get(\"/database/get-count\")\nasync def get_count():\n    count = await db_ops.count_query(Select(User))\n    return {\"count\": count}\n\n\n# endpoint to get list of user\n@app.get(\"/database/get-all\")\nasync def get_all(offset: int = 0, limit: int = 100):\n    records = await db_ops.read_query(Select(User).offset(offset).limit(limit))\n    return {\"records\": records}\n\n\n@app.get(\"/database/get-primary-key\")\nasync def table_primary_key():\n    pk = await db_ops.get_primary_keys(User)\n    return {\"pk\": pk}\n\n\n@app.get(\"/database/get-column-details\")\nasync def table_column_details():\n    columns = await db_ops.get_columns_details(User)\n    return {\"columns\": columns}\n\n\n@app.get(\"/database/get-tables\")\nasync def table_table_details():\n    tables = await db_ops.get_table_names()\n    return {\"table_names\": tables}\n\n\n@app.get(\"/database/get-one-record\")\nasync def get_one_record(record_id: str):\n    record = await db_ops.get_one_record(Select(User).where(User.pkid == record_id))\n    return {\"record\": record}\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"127.0.0.1\", port=5000)\n</code></pre>"},{"location":"recipes/fastapi/","title":"Full Example of FastAPI with Aync Database and Endpoints","text":""},{"location":"recipes/fastapi/#install-dependencies","title":"Install dependencies","text":"<pre><code>pip install dsg_lib[all] tqdm\n</code></pre>"},{"location":"recipes/fastapi/#make-app","title":"Make App","text":"<p>Copy the fastapi code below after installing. (assumption is main.py)</p> <pre><code># -*- coding: utf-8 -*-\n\nimport logging\nimport secrets\nfrom contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom fastapi.responses import RedirectResponse\nfrom loguru import logger\nfrom sqlalchemy import Column, Delete, ForeignKey, Integer, Select, String, Update\nfrom sqlalchemy.orm import relationship\nfrom tqdm import tqdm\n\nfrom dsg_lib import (\n    async_database,\n    base_schema,\n    database_config,\n    database_operations,\n    logging_config,\n)\n\nlogging_config.config_log(\n    logging_level=\"INFO\", log_serializer=False, log_name=\"log.log\"\n)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    logger.info(\"starting up\")\n    # Create the tables in the database\n    await async_db.create_tables()\n\n    # create_users = True\n    # if create_users:\n    #     await create_a_bunch_of_users(single_entry=23, many_entries=2000)\n    yield\n    logger.info(\"shutting down\")\n\n\n# Create an instance of the FastAPI class\napp = FastAPI(\n    title=\"FastAPI Example\",  # The title of the API\n    description=\"This is an example of a FastAPI application using the DevSetGo Toolkit.\",  # A brief description of the API\n    version=\"0.1.0\",  # The version of the API\n    docs_url=\"/docs\",  # The URL where the API documentation will be served\n    redoc_url=\"/redoc\",  # The URL where the ReDoc documentation will be served\n    openapi_url=\"/openapi.json\",  # The URL where the OpenAPI schema will be served\n    debug=True,  # Enable debug mode\n    middleware=[],  # A list of middleware to include in the application\n    routes=[],  # A list of routes to include in the application\n    lifespan=lifespan,\n)\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"\n    Root endpoint of API\n    Returns:\n        Redrects to openapi document\n    \"\"\"\n    # redirect to openapi docs\n    logger.info(\"Redirecting to OpenAPI docs\")\n    response = RedirectResponse(url=\"/docs\")\n    return response\n\n\nfrom dsg_lib import system_health_endpoints  # , system_tools_endpoints\n\nconfig_health = {\n    \"enable_status_endpoint\": True,\n    \"enable_uptime_endpoint\": True,\n    \"enable_heapdump_endpoint\": True,\n}\napp.include_router(\n    system_health_endpoints.create_health_router(config=config_health),\n    prefix=\"/api/health\",\n    tags=[\"system-health\"],\n)\n\n# Create a DBConfig instance\nconfig = {\n    # \"database_uri\": \"postgresql+asyncpg://postgres:postgres@postgresdb/postgres\",\n    \"database_uri\": \"sqlite+aiosqlite:///:memory:?cache=shared\",\n    \"echo\": False,\n    \"future\": True,\n    # \"pool_pre_ping\": True,\n    # \"pool_size\": 10,\n    # \"max_overflow\": 10,\n    \"pool_recycle\": 3600,\n    # \"pool_timeout\": 30,\n}\n\ndb_config = database_config.DBConfig(config)\n# Create an AsyncDatabase instance\nasync_db = async_database.AsyncDatabase(db_config)\n\n# Create a DatabaseOperations instance\ndb_ops = database_operations.DatabaseOperations(async_db)\n\n\n# User class inherits from SchemaBase and async_db.Base\n# This class represents the User table in the database\nclass User(base_schema.SchemaBase, async_db.Base):\n    __tablename__ = \"users\"  # Name of the table in the database\n\n    # Define the columns of the table\n    first_name = Column(String, unique=False, index=True)  # First name of the user\n    last_name = Column(String, unique=False, index=True)  # Last name of the user\n    email = Column(\n        String, unique=True, index=True, nullable=True\n    )  # Email of the user, must be unique\n\n\nclass Address(base_schema.SchemaBase, async_db.Base):\n    __tablename__ = \"addresses\"  # Name of the table in the database\n\n    # Define the columns of the table\n    street = Column(String, unique=False, index=True)  # Street of the address\n    city = Column(String, unique=False, index=True)  # City of the address\n    zip = Column(String, unique=False, index=True)  # Zip code of the address\n\n    # Define the parent relationship to the User class\n    user_id = Column(Integer, ForeignKey(\"users.pkid\"))  # Foreign key to the User table\n    user = relationship(\n        \"User\", back_populates=\"addresses\"\n    )  # Relationship to the User class\n\n\n# Update the User class to include the child relationship to the Address class\nUser.addresses = relationship(\"Address\", order_by=Address.pkid, back_populates=\"user\")\n\n\nasync def create_a_bunch_of_users(single_entry=0, many_entries=0):\n    logger.info(f\"single_entry: {single_entry}\")\n    await async_db.create_tables()\n    # Create a list to hold the user data\n\n    # Create a loop to generate user data\n\n    for i in tqdm(range(single_entry), desc=\"executing one\"):\n        value = secrets.token_hex(16)\n        user = User(\n            first_name=f\"First{value}\",\n            last_name=f\"Last{value}\",\n            email=f\"user{value}@example.com\",\n        )\n        logger.info(f\"created_users: {user}\")\n        await db_ops.create_one(user)\n\n    users = []\n    # Create a loop to generate user data\n    for i in tqdm(range(many_entries), desc=\"executing many\"):\n        value_one = secrets.token_hex(4)\n        value_two = secrets.token_hex(8)\n        user = User(\n            first_name=f\"First{value_one}{i}{value_two}\",\n            last_name=f\"Last{value_one}{i}{value_two}\",\n            email=f\"user{value_one}{i}{value_two}@example.com\",\n        )\n        logger.info(f\"created_users: {user.first_name}\")\n        users.append(user)\n\n    # Use db_ops to add the users to the database\n    await db_ops.create_many(users)\n\n\n@app.get(\"/database/get-count\")\nasync def get_count():\n    count = await db_ops.count_query(Select(User))\n    return {\"count\": count}\n\n\n# endpoint to get list of user\n@app.get(\"/database/get-all\")\nasync def get_all(offset: int = 0, limit: int = 100):\n    records = await db_ops.read_query(Select(User).offset(offset).limit(limit))\n    return {\"records\": records}\n\n\n@app.get(\"/database/get-primary-key\")\nasync def table_primary_key():\n    pk = await db_ops.get_primary_keys(User)\n    return {\"pk\": pk}\n\n\n@app.get(\"/database/get-column-details\")\nasync def table_column_details():\n    columns = await db_ops.get_columns_details(User)\n    return {\"columns\": columns}\n\n\n@app.get(\"/database/get-tables\")\nasync def table_table_details():\n    tables = await db_ops.get_table_names()\n    return {\"table_names\": tables}\n\n\n@app.get(\"/database/get-one-record\")\nasync def get_one_record(record_id: str):\n    record = await db_ops.get_one_record(Select(User).where(User.pkid == record_id))\n    return record\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"127.0.0.1\", port=5000)\n</code></pre>"},{"location":"recipes/fastapi/#run-code","title":"Run Code","text":"<p>In the console (linux) run the code below. Open browser to http://127.0.0.1:5000 to see app.</p> <pre><code>python3 main.py\n</code></pre>"},{"location":"recipes/loggingExample/","title":"Logging Example","text":"<pre><code># -*- coding: utf-8 -*-\nimport logging\nimport secrets\nfrom uuid import uuid4\n\nfrom loguru import logger\nfrom tqdm import tqdm\n\nfrom dsg_lib import logging_config\n\nlogging_config.config_log(\n    logging_directory=\"log\",\n    # or None and defaults to logging\n    # log_name=\"log.json\",\n    # or None and defaults to \"log.log\"\n    logging_level=\"debug\",\n    # or \"info\" or \"debug\" or \"warning\" or \"error\" or \"critical\"\n    # or None and defaults to \"info\"\n    log_rotation=\"10 MB\",\n    # or None and default is 10 MB\n    log_retention=\"1 Day\",\n    # or None and defaults to \"14 Days\"\n    log_backtrace=True,\n    # or None and defaults to False\n    app_name=\"my_app\",\n    # app name is used to identify the application\n    # this is an optional field\n    enable_trace_id=True,\n    # service id is used to identify the service\n    # this is an optional field\n    append_app_name=True,\n    # append app name to log file name defaults to false\n    append_trace_id=True,\n    # append app name and service name to log file name defaults to false\n)\n\n# after configuring logging\n# user loguru to log messages\nlogger.debug(\"This is a debug message\")\nlogger.info(\"This is an info message\")\nlogger.error(\"This is an error message\")\nlogger.warning(\"This is a warning message\")\nlogger.critical(\"This is a critical message\")\n\n# will intercept all standard logging messages also\nlogging.debug(\"This is a debug message\")\nlogging.info(\"This is an info message\")\nlogging.error(\"This is an error message\")\nlogging.warning(\"This is a warning message\")\nlogging.critical(\"This is a critical message\")\n\n\ndef div_zero(x, y):\n    try:\n        return x / y\n    except ZeroDivisionError as e:\n        logger.error(f\"{e}\")\n        logging.error(f\"{e}\")\n\n\n@logger.catch\ndef div_zero_two(x, y):\n    return x / y\n\n\na = div_zero(x=1, y=0)\nb = div_zero_two(x=1, y=0)\n\nfor _ in tqdm(range(5), ascii=True):\n    # log a lot of data\n    logging.debug(f\"Lets make this a big message {secrets.token_urlsafe(32)}\")\n</code></pre>"},{"location":"recipes/patterns/","title":"Patterns","text":"<pre><code># -*- coding: utf-8 -*-\nimport pprint\nfrom random import randint\n\nfrom dsg_lib.patterns import pattern_between_two_char\n\nASCII_LIST = [\n    \" \",\n    \"!\",\n    '\"\"',\n    \"#\",\n    \"$\",\n    \"%\",\n    \"&amp;\",\n    \"'\",\n    \"(\",\n    \")\",\n    \"*\",\n    \"+\",\n    \",\",\n    \"-\",\n    \".\",\n    \"/\",\n    \"0\",\n    \"1\",\n    \"2\",\n    \"3\",\n    \"4\",\n    \"5\",\n    \"6\",\n    \"7\",\n    \"8\",\n    \"9\",\n    \":\",\n    \";\",\n    \"&lt;\",\n    \"=\",\n    \"&gt;\",\n    \"?\",\n    \"@\",\n    \"A\",\n    \"B\",\n    \"C\",\n    \"D\",\n    \"E\",\n    \"F\",\n    \"G\",\n    \"H\",\n    \"I\",\n    \"J\",\n    \"K\",\n    \"L\",\n    \"M\",\n    \"N\",\n    \"O\",\n    \"P\",\n    \"Q\",\n    \"R\",\n    \"S\",\n    \"T\",\n    \"U\",\n    \"V\",\n    \"W\",\n    \"X\",\n    \"Y\",\n    \"Z\",\n    \"[\",\n    \"\\\\\",\n    \"]\",\n    \"^\",\n    \"_\",\n    \"`\",\n    \"a\",\n    \"b\",\n    \"c\",\n    \"d\",\n    \"e\",\n    \"f\",\n    \"g\",\n    \"h\",\n    \"i\",\n    \"j\",\n    \"k\",\n    \"l\",\n    \"m\",\n    \"n\",\n    \"o\",\n    \"p\",\n    \"q\",\n    \"r\",\n    \"s\",\n    \"t\",\n    \"u\",\n    \"v\",\n    \"w\",\n    \"x\",\n    \"y\",\n    \"z\",\n    \"{\",\n    \"|\",\n    \"}\",\n    \"~\",\n    \"\u20ac\",\n    \"\u201a\",\n    \"\u0192\",\n    \"\u201e\",\n    \"\u2026\",\n    \"\u2020\",\n    \"\u2021\",\n    \"\u02c6\",\n    \"\u2030\",\n    \"\u0160\",\n    \"\u2039\",\n    \"\u0152\",\n    \"\u017d\",\n    \"\u2018\",\n    \"\u2019\",\n    \"\u201c\",\n    \"\u201d\",\n    \"\u2022\",\n    \"\u2013\",\n    \"\u2014\",\n    \"\u02dc\",\n    \"\u2122\",\n    \"\u0161\",\n    \"\u203a\",\n    \"\u0153\",\n    \"\u017e\",\n    \"\u0178\",\n    \"\u00a1\",\n    \"\u00a2\",\n    \"\u00a3\",\n    \"\u00a4\",\n    \"\u00a5\",\n    \"\u00a6\",\n    \"\u00a7\",\n    \"\u00a8\",\n    \"\u00a9\",\n    \"\u00aa\",\n    \"\u00ab\",\n    \"\u00ac\",\n    \"\u00ae\",\n    \"\u00af\",\n    \"\u00b0\",\n    \"\u00b1\",\n    \"\u00b2\",\n    \"\u00b3\",\n    \"\u00b4\",\n    \"\u00b5\",\n    \"\u00b6\",\n    \"\u00b7\",\n    \"\u00b8\",\n    \"\u00b9\",\n    \"\u00ba\",\n    \"\u00bb\",\n    \"\u00bc\",\n    \"\u00bd\",\n    \"\u00be\",\n    \"\u00bf\",\n    \"\u00c0\",\n    \"\u00c1\",\n    \"\u00c2\",\n    \"\u00c3\",\n    \"\u00c4\",\n    \"\u00c5\",\n    \"\u00c6\",\n    \"\u00c7\",\n    \"\u00c8\",\n    \"\u00c9\",\n    \"\u00ca\",\n    \"\u00cb\",\n    \"\u00cc\",\n    \"\u00cd\",\n    \"\u00ce\",\n    \"\u00cf\",\n    \"\u00d0\",\n    \"\u00d1\",\n    \"\u00d2\",\n    \"\u00d3\",\n    \"\u00d4\",\n    \"\u00d5\",\n    \"\u00d6\",\n    \"\u00d7\",\n    \"\u00d8\",\n    \"\u00d9\",\n    \"\u00da\",\n    \"\u00db\",\n    \"\u00dc\",\n    \"\u00dd\",\n    \"\u00de\",\n    \"\u00df\",\n    \"\u00e0\",\n    \"\u00e1\",\n    \"\u00e2\",\n    \"\u00e3\",\n    \"\u00e4\",\n    \"\u00e5\",\n    \"\u00e6\",\n    \"\u00e7\",\n    \"\u00e8\",\n    \"\u00e9\",\n    \"\u00ea\",\n    \"\u00eb\",\n    \"\u00ec\",\n    \"\u00ed\",\n    \"\u00ee\",\n    \"\u00ef\",\n    \"\u00f0\",\n    \"\u00f1\",\n    \"\u00f2\",\n    \"\u00f3\",\n    \"\u00f4\",\n    \"\u00f5\",\n    \"\u00f6\",\n    \"\u00f7\",\n    \"\u00f8\",\n    \"\u00f9\",\n    \"\u00fa\",\n    \"\u00fb\",\n    \"\u00fc\",\n    \"\u00fd\",\n    \"\u00fe\",\n    \"\u00ff\",\n]\n\npp = pprint.PrettyPrinter(indent=4)\n\n\ndef pattern_find(left_char: str, right_char: str, text_block: str):\n    data = pattern_between_two_char(text_block, left_char, right_char)\n    pp.pprint(data)\n\n\ndef run_examples():\n    text_block = \"Lfound oneR Lfound twoR\"\n    left_char = \"L\"\n    right_char = \"R\"\n    pattern_find(left_char=left_char, right_char=right_char, text_block=text_block)\n\n    for _ in range(100):\n        long_input = \"xyz\" * randint(100, 100000)\n        long_text = f\"{long_input}abc&lt;one&gt;123&lt;two&gt;456&lt;three&gt;{long_input}\"\n\n        result = pattern_between_two_char(\n            text_string=long_text, left_characters=\"&lt;\", right_characters=\"&gt;\"\n        )\n        print(result[\"found\"])\n\n\nif __name__ == \"__main__\":\n    run_examples()\n</code></pre>"}]}